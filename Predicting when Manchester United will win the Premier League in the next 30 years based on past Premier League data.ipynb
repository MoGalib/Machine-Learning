{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset have been taken from https://en.wikipedia.org/wiki/List_of_Manchester_United_F.C._seasons. It has 10 columns in total. Season, Division, P = Total Matches played, W = No. of matches won, D = No. of matches drawn, L = No. of matches lost, F = No. of goals scored for Manchester United, A = No. of goals conceded by Manchester United, Pts = Total points earned, Pos = The final position earned by Manchester United."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have tried to predict the season in the next 30 years when Manchester United is going to lift the Premier League trophy. I have used several algorithms for training and testing and have chosen the best algorithm for predicting. The dataset comprises of each of the relevant data related to Manchester United since the Premier League started in 1992. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import preprocessing\n",
    "import operator\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#warnings.filterwarnings(action='once')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Division</th>\n",
       "      <th>P</th>\n",
       "      <th>W</th>\n",
       "      <th>D</th>\n",
       "      <th>L</th>\n",
       "      <th>F</th>\n",
       "      <th>A</th>\n",
       "      <th>Pts</th>\n",
       "      <th>Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992</td>\n",
       "      <td>Prem</td>\n",
       "      <td>42</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>67</td>\n",
       "      <td>31</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1993</td>\n",
       "      <td>Prem</td>\n",
       "      <td>42</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>38</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1994</td>\n",
       "      <td>Prem</td>\n",
       "      <td>42</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>77</td>\n",
       "      <td>28</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995</td>\n",
       "      <td>Prem</td>\n",
       "      <td>38</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>73</td>\n",
       "      <td>35</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1996</td>\n",
       "      <td>Prem</td>\n",
       "      <td>38</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>44</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season Division   P   W   D  L   F   A  Pts  Pos\n",
       "0    1992     Prem  42  24  12  6  67  31   84    1\n",
       "1    1993     Prem  42  27  11  4  80  38   92    1\n",
       "2    1994     Prem  42  26  10  6  77  28   88    2\n",
       "3    1995     Prem  38  25   7  6  73  35   82    1\n",
       "4    1996     Prem  38  21  12  5  76  44   75    1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'E:\\Datasets\\Manchester_United_prediction\\PL data\\Man_Utd.csv', encoding = 'unicode_escape')   \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Season      0\n",
       "Division    0\n",
       "P           0\n",
       "W           0\n",
       "D           0\n",
       "L           0\n",
       "F           0\n",
       "A           0\n",
       "Pts         0\n",
       "Pos         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>P</th>\n",
       "      <th>W</th>\n",
       "      <th>D</th>\n",
       "      <th>L</th>\n",
       "      <th>F</th>\n",
       "      <th>A</th>\n",
       "      <th>Pts</th>\n",
       "      <th>Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992</td>\n",
       "      <td>42</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>67</td>\n",
       "      <td>31</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1993</td>\n",
       "      <td>42</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>38</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1994</td>\n",
       "      <td>42</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>77</td>\n",
       "      <td>28</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995</td>\n",
       "      <td>38</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>73</td>\n",
       "      <td>35</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1996</td>\n",
       "      <td>38</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>44</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season   P   W   D  L   F   A  Pts  Pos\n",
       "0    1992  42  24  12  6  67  31   84    1\n",
       "1    1993  42  27  11  4  80  38   92    1\n",
       "2    1994  42  26  10  6  77  28   88    2\n",
       "3    1995  38  25   7  6  73  35   82    1\n",
       "4    1996  38  21  12  5  76  44   75    1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['Division'], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x22d7648e848>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.relplot(x=\"Season\", y=\"Pos\", ci=None, kind=\"line\",dashes = False, markers=True, data=df, height = 5, aspect = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Season', 'P', 'W', 'D', 'L', 'F', 'A', 'Pts']]\n",
    "y = df[['Pos']]\n",
    "X1 = df[['Season', 'P', 'W', 'D', 'L', 'F', 'A', 'Pts']]\n",
    "y1 = df[['Pos']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.57961346],\n",
       "       [1.62222552],\n",
       "       [2.13701125],\n",
       "       [5.25463421],\n",
       "       [2.27083551]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "lin_df = LinearRegression()  \n",
    "lin_df.fit(X_train, y_train)\n",
    "lr_pred = lin_df.predict(X_test)   \n",
    "lr_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Score for Test set:  0.9971829796882571\n",
      "R2 Score:  0.7597485891323608\n"
     ]
    }
   ],
   "source": [
    "linrgr_rmse = np.sqrt(mean_squared_error(y_test, lr_pred))\n",
    "linrgr_r2 = r2_score(y_test, lr_pred)\n",
    "print(\"RMSE Score for Test set: \",linrgr_rmse)\n",
    "print(\"R2 Score: \",linrgr_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficients after ridge regression is : [[ 0.09260154  0.27926509 -0.05393454  0.1078445   0.22535513 -0.00558186\n",
      "  -0.00117116 -0.05395912]]\n",
      "The intercept after ridge regression is : [-190.36194644]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.57966431],\n",
       "       [1.63706457],\n",
       "       [2.12562397],\n",
       "       [5.23046331],\n",
       "       [2.23843626]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.Ridge()\n",
    "reg.fit(X_train, y_train)\n",
    "rdg_pred = reg.predict(X_test)\n",
    "print(\"The coefficients after ridge regression is :\", reg.coef_)\n",
    "print(\"The intercept after ridge regression is :\", reg.intercept_)\n",
    "rdg_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Score for Test set:  0.997939929397257\n",
      "R2 Score:  0.7593837067337283\n"
     ]
    }
   ],
   "source": [
    "rdgrgr_rmse = np.sqrt(mean_squared_error(y_test, rdg_pred))\n",
    "rdgrgr_r2 = r2_score(y_test, rdg_pred)\n",
    "print(\"RMSE Score for Test set: \",rdgrgr_rmse)\n",
    "print(\"R2 Score: \",rdgrgr_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0769854933649836\n"
     ]
    }
   ],
   "source": [
    "# Finding the best value of alpha using cross validation\n",
    "from sklearn.linear_model import LassoCV\n",
    "regr = LassoCV()\n",
    "regr.fit(X, y)\n",
    "print(regr.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficients after lasso regression is : [ 0.05105031  0.         -0.          0.          0.         -0.03419514\n",
      "  0.0023105  -0.08535248]\n",
      "The intercept after lasso regression is : [-90.86651577]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.77610982, 2.02160138, 1.84200343, 4.34605655, 1.4366391 ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.Lasso(alpha=regr.alpha_)\n",
    "clf.fit(X_train, y_train)\n",
    "las_pred = clf.predict(X_test)\n",
    "print(\"The coefficients after lasso regression is :\", clf.coef_)\n",
    "print(\"The intercept after lasso regression is :\", clf.intercept_)\n",
    "las_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Score for Test set:  1.2377853766262539\n",
      "R2 Score:  0.6298251343004516\n"
     ]
    }
   ],
   "source": [
    "lasrgr_rmse = np.sqrt(mean_squared_error(y_test, las_pred))\n",
    "lasrgr_r2 = r2_score(y_test, las_pred)\n",
    "print(\"RMSE Score for Test set: \",lasrgr_rmse)\n",
    "print(\"R2 Score: \",lasrgr_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.265551610784285\n"
     ]
    }
   ],
   "source": [
    "# Finding the best value of alpha using cross validation\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "regr = ElasticNetCV()\n",
    "regr.fit(X, y)\n",
    "print(regr.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficients after elasticnet regression is : [ 0.07810538  0.26707061 -0.          0.          0.02802889 -0.02075427\n",
      "  0.00655679 -0.11100914]\n",
      "The intercept after elasticnet regression is : [-154.5981932]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.61236069, 1.80678154, 2.0333411 , 4.96204577, 1.86081479])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "# Actual regression on test set\n",
    "from sklearn.linear_model import ElasticNet\n",
    "reg = ElasticNet(alpha=regr.alpha_)\n",
    "reg.fit(X_train, y_train)\n",
    "en_pred = reg.predict(X_test)\n",
    "print(\"The coefficients after elasticnet regression is :\", reg.coef_)\n",
    "print(\"The intercept after elasticnet regression is :\", reg.intercept_)\n",
    "en_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Score for Test set:  1.022432805079632\n",
      "R2 Score:  0.7474276626006162\n"
     ]
    }
   ],
   "source": [
    "enrgr_rmse = np.sqrt(mean_squared_error(y_test, en_pred))\n",
    "enrgr_r2 = r2_score(y_test, en_pred)\n",
    "print(\"RMSE Score for Test set: \",enrgr_rmse)\n",
    "print(\"R2 Score: \",enrgr_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LassoLars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007179227436123559\n"
     ]
    }
   ],
   "source": [
    "# Finding the best value of alpha using cross validation\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "regr = LassoLarsCV()\n",
    "regr.fit(X, y)\n",
    "print(regr.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficients after elasticnet regression is : [ 0.08549218  0.28475096 -0.25599251  0.          0.17511703 -0.00697308\n",
      "  0.          0.        ]\n",
      "The intercept after elasticnet regression is : [-174.53399145]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.62690447, 1.67206735, 2.18196311, 5.17356367, 2.16564783])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LassoLars(alpha=regr.alpha_)\n",
    "reg.fit(X_train, y_train)\n",
    "lslr_pred = reg.predict(X_test)\n",
    "print(\"The coefficients after elasticnet regression is :\", reg.coef_)\n",
    "print(\"The intercept after elasticnet regression is :\", reg.intercept_)\n",
    "lslr_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Score for Test set:  0.9931054701197409\n",
      "R2 Score:  0.7617093617976975\n"
     ]
    }
   ],
   "source": [
    "lslrrgr_rmse = np.sqrt(mean_squared_error(y_test, lslr_pred))\n",
    "lslrrgr_r2 = r2_score(y_test, lslr_pred)\n",
    "print(\"RMSE Score for Test set: \",lslrrgr_rmse)\n",
    "print(\"R2 Score: \",lslrrgr_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The predicted values with degree =  1  is \n",
      " [[1.57961346]\n",
      " [1.62222552]\n",
      " [2.13701125]\n",
      " [5.25463421]\n",
      " [2.27083551]]\n",
      "\n",
      "RMSE Score of Test set for degree  1  is:  0.9971829796882489\n",
      "R2 RMSE Score of Test set for degree  1  is:  0.7597485891323648\n",
      "\n",
      "The predicted values with degree =  2  is \n",
      " [[  3.18304056]\n",
      " [  1.00857042]\n",
      " [  6.49935203]\n",
      " [  2.0819222 ]\n",
      " [-16.2944064 ]]\n",
      "\n",
      "RMSE Score of Test set for degree  2  is:  7.593309047167244\n",
      "R2 RMSE Score of Test set for degree  2  is:  -12.930874646231604\n",
      "\n",
      "The predicted values with degree =  3  is \n",
      " [[ 2.42572235]\n",
      " [ 1.10233701]\n",
      " [ 5.78914181]\n",
      " [ 5.38446535]\n",
      " [-5.04573979]]\n",
      "\n",
      "RMSE Score of Test set for degree  3  is:  2.8991863376294242\n",
      "R2 RMSE Score of Test set for degree  3  is:  -1.0308062491993026\n",
      "\n",
      "The predicted values with degree =  4  is \n",
      " [[ 2.41091948]\n",
      " [ 1.10060426]\n",
      " [ 5.76018235]\n",
      " [ 5.43329408]\n",
      " [-4.76494992]]\n",
      "\n",
      "RMSE Score of Test set for degree  4  is:  2.791231001774916\n",
      "R2 RMSE Score of Test set for degree  4  is:  -0.8823821355013317\n",
      "\n",
      "The predicted values with degree =  5  is \n",
      " [[ 2.40192621]\n",
      " [ 1.09799895]\n",
      " [ 5.75109867]\n",
      " [ 5.4758688 ]\n",
      " [-4.57359648]]\n",
      "\n",
      "RMSE Score of Test set for degree  5  is:  2.7193040297799067\n",
      "R2 RMSE Score of Test set for degree  5  is:  -0.7866182458361117\n",
      "\n",
      "The predicted values with degree =  6  is \n",
      " [[ 2.39286391]\n",
      " [ 1.09540979]\n",
      " [ 5.74213858]\n",
      " [ 5.51961204]\n",
      " [-4.38281541]]\n",
      "\n",
      "RMSE Score of Test set for degree  6  is:  2.6479389570357283\n",
      "R2 RMSE Score of Test set for degree  6  is:  -0.6940731941392522\n",
      "\n",
      "The predicted values with degree =  7  is \n",
      " [[ 2.38392668]\n",
      " [ 1.09282193]\n",
      " [ 5.73232888]\n",
      " [ 5.56208318]\n",
      " [-4.19533057]]\n",
      "\n",
      "RMSE Score of Test set for degree  7  is:  2.5781983904519987\n",
      "R2 RMSE Score of Test set for degree  7  is:  -0.6060124151614363\n",
      "\n",
      "The predicted values with degree =  8  is \n",
      " [[ 2.37509109]\n",
      " [ 1.09022151]\n",
      " [ 5.72505773]\n",
      " [ 5.60803407]\n",
      " [-4.01164229]]\n",
      "\n",
      "RMSE Score of Test set for degree  8  is:  2.5103541797296955\n",
      "R2 RMSE Score of Test set for degree  8  is:  -0.5226014219913335\n",
      "\n",
      "The predicted values with degree =  9  is \n",
      " [[ 2.36631769]\n",
      " [ 1.0876314 ]\n",
      " [ 5.71671228]\n",
      " [ 5.6527707 ]\n",
      " [-3.83024627]]\n",
      "\n",
      "RMSE Score of Test set for degree  9  is:  2.443778717084691\n",
      "R2 RMSE Score of Test set for degree  9  is:  -0.442912476850601\n",
      "\n",
      "The best RMSE score of Test Set is  0.9971829796882489  with degree =  1\n",
      "The max R2 score of Test Set is  0.7597485891323648  with degree =  1\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "plrgr_rmse = np.zeros(9)\n",
    "plrgr_r2 = np.zeros(9)\n",
    "\n",
    "for i in range(1,10):\n",
    "    poly_df = PolynomialFeatures(degree = i)\n",
    "    transform_poly = poly_df.fit_transform(X_train)\n",
    "    clf = linear_model.LinearRegression()\n",
    "    clf.fit(transform_poly,y_train)\n",
    "    polynomial_predict = clf.predict(poly_df.fit_transform(X_test))\n",
    "    plrgr_rmse[i-1] = np.sqrt(mean_squared_error(y_test,polynomial_predict))\n",
    "    plrgr_r2[i-1] = r2_score(y_test,polynomial_predict)\n",
    "    print(\"\\nThe predicted values with degree = \",i,\" is \\n\",polynomial_predict[0:5])\n",
    "    print(\"\\nRMSE Score of Test set for degree \", i,\" is: \",plrgr_rmse[i-1])\n",
    "    print(\"R2 RMSE Score of Test set for degree \", i,\" is: \",plrgr_r2[i-1]) \n",
    "\n",
    "print(\"\\nThe best RMSE score of Test Set is \", plrgr_rmse.min(), \" with degree = \",plrgr_rmse.argmin()+1)\n",
    "print(\"The max R2 score of Test Set is \", plrgr_r2.max(), \" with degree = \",plrgr_r2.argmax()+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The predicted values for Test Set using criterion =  mse  is:  [2. 1. 2. 5. 2.]\n",
      "\n",
      "The RMSE score for Test Set using criterion =  mse  is:  1.224744871391589\n",
      "The R2 score for Test Set using criterion =  mse  is:  0.6375838926174496\n",
      "\n",
      "The predicted values for Test Set using criterion =  friedman_mse  is:  [2. 1. 2. 4. 2.]\n",
      "\n",
      "The RMSE score for Test Set using criterion =  friedman_mse  is:  1.5275252316519468\n",
      "The R2 score for Test Set using criterion =  friedman_mse  is:  0.43624161073825496\n",
      "\n",
      "The predicted values for Test Set using criterion =  mae  is:  [2. 1. 1. 6. 2.]\n",
      "\n",
      "The RMSE score for Test Set using criterion =  mae  is:  1.4142135623730951\n",
      "The R2 score for Test Set using criterion =  mae  is:  0.5167785234899329\n",
      "\n",
      "The best RMSE score for Test Set is  1.224744871391589\n",
      "The max R2 score of Test Set is  0.6375838926174496\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "k = ['mse', 'friedman_mse', 'mae']\n",
    "dt_rmse = np.zeros(3)\n",
    "dt_r2 = np.zeros(3)\n",
    "n = 0\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "for i in k:\n",
    "    dt_reg = DecisionTreeRegressor(criterion = i)          # create  DecisionTreeReg with sklearn\n",
    "    dt_reg.fit(X_train,y_train)\n",
    "    dt_predict = dt_reg.predict(X_test)\n",
    "    dt_rmse[n] = np.sqrt(mean_squared_error(y_test,dt_predict))\n",
    "    dt_r2[n] = r2_score(y_test,dt_predict)\n",
    "    print(\"\\nThe predicted values for Test Set using criterion = \",i,\" is: \",dt_predict[0:5])\n",
    "    print(\"\\nThe RMSE score for Test Set using criterion = \",i,\" is: \",dt_rmse[n])\n",
    "    print(\"The R2 score for Test Set using criterion = \",i,\" is: \",dt_r2[n])\n",
    "    n += 1   \n",
    "print(\"\\nThe best RMSE score for Test Set is \", dt_rmse.min())\n",
    "print(\"The max R2 score of Test Set is \", dt_r2.max())   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The predicted values for Test Set using criterion =  mse  is:  [1.68 1.1  1.68 4.67 1.86]\n",
      "\n",
      "The RMSE score for Test Set using criterion =  mse  is:  1.2735056602413146\n",
      "The R2 score for Test Set using criterion =  mse  is:  0.5167785234899329\n",
      "\n",
      "The predicted values for Test Set using criterion =  mae  is:  [1.65 1.15 1.84 4.78 1.94]\n",
      "\n",
      "The RMSE score for Test Set using criterion =  mae  is:  1.1854816180214125\n",
      "The R2 score for Test Set using criterion =  mae  is:  0.5167785234899329\n",
      "\n",
      "The best RMSE score for Test Set is  1.1854816180214125\n",
      "The max R2 score of Test Set is  0.5167785234899329\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "k = ['mse', 'mae']\n",
    "n = 0\n",
    "rf_rmse = np.zeros(2)\n",
    "rf_r2 = np.zeros(2)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "for i in k:\n",
    "    rf_reg = RandomForestRegressor(criterion = i)\n",
    "    rf_reg.fit(X_train,y_train)\n",
    "    rf_pred = rf_reg.predict(X_test)\n",
    "    rf_rmse[n] = np.sqrt(mean_squared_error(y_test,rf_pred))\n",
    "    rf_r2[n] = r2_score(y_test,dt_predict)\n",
    "    print(\"\\nThe predicted values for Test Set using criterion = \",i,\" is: \",rf_pred[0:5])\n",
    "    print(\"\\nThe RMSE score for Test Set using criterion = \",i,\" is: \",rf_rmse[n])\n",
    "    print(\"The R2 score for Test Set using criterion = \",i,\" is: \",rf_r2[n])\n",
    "    n += 1   \n",
    "    \n",
    "print(\"\\nThe best RMSE score for Test Set is \", rf_rmse.min())\n",
    "print(\"The max R2 score of Test Set is \", rf_r2.max())       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADABoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The predicted values for Test Set using loss =  linear  is:  [1.63636364 1.         1.         5.         2.        ]\n",
      "\n",
      "The RMSE score for Test Set using loss =  linear  is:  1.378704626191191\n",
      "The R2 score for Test Set using loss =  linear  is:  0.5407399190193577\n",
      "\n",
      "The predicted values for Test Set using loss =  square  is:  [1.  1.  2.  5.  1.8]\n",
      "\n",
      "The RMSE score for Test Set using loss =  square  is:  1.1284207253207172\n",
      "The R2 score for Test Set using loss =  square  is:  0.6923489932885906\n",
      "\n",
      "The predicted values for Test Set using loss =  exponential  is:  [1.83333333 1.         1.09090909 5.         2.        ]\n",
      "\n",
      "The RMSE score for Test Set using loss =  exponential  is:  1.3747164885664\n",
      "The R2 score for Test Set using loss =  exponential  is:  0.5433930519348457\n",
      "\n",
      "The best RMSE score for Test Set is  1.1284207253207172\n",
      "The max R2 score of Test Set is  0.6923489932885906\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "k = ['linear', 'square', 'exponential']\n",
    "n = 0\n",
    "adb_rmse = np.zeros(3)\n",
    "adb_r2 = np.zeros(3)\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "for i in k:\n",
    "    ada_regr = AdaBoostRegressor(loss = i)\n",
    "    ada_regr.fit(X_train,y_train)\n",
    "    ada_pred = ada_regr.predict(X_test)\n",
    "    adb_rmse[n] = np.sqrt(mean_squared_error(y_test,ada_pred))\n",
    "    adb_r2[n] = r2_score(y_test,ada_pred)\n",
    "    print(\"\\nThe predicted values for Test Set using loss = \",i,\" is: \",ada_pred[0:5])\n",
    "    print(\"\\nThe RMSE score for Test Set using loss = \",i,\" is: \",adb_rmse[n])\n",
    "    print(\"The R2 score for Test Set using loss = \",i,\" is: \",adb_r2[n])\n",
    "    n += 1   \n",
    "print(\"\\nThe best RMSE score for Test Set is \", adb_rmse.min())\n",
    "print(\"The max R2 score of Test Set is \", adb_r2.max())           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The predicted values for Test Set using loss =  ls  is:  [2.10055404 1.01620884 1.192849   4.86760217 2.09243619]\n",
      "\n",
      "The RMSE score for Test Set using loss =  ls  is:  1.3733375716082044\n",
      "The R2 score for Test Set using loss =  ls  is:  0.5443085967700274\n",
      "\n",
      "The predicted values for Test Set using loss =  lad  is:  [1.         1.         1.99997344 1.99997344 1.        ]\n",
      "\n",
      "The RMSE score for Test Set using loss =  lad  is:  2.1602612442982037\n",
      "The R2 score for Test Set using loss =  lad  is:  -0.12753175282017226\n",
      "\n",
      "The predicted values for Test Set using loss =  huber  is:  [2.02634184 1.00366966 1.09260654 4.79340164 2.02772353]\n",
      "\n",
      "The RMSE score for Test Set using loss =  huber  is:  1.3924784469601623\n",
      "The R2 score for Test Set using loss =  huber  is:  0.531517690543966\n",
      "\n",
      "The predicted values for Test Set using loss =  quantile  is:  [3.70529375 3.70529375 3.70529375 5.03247213 3.70529375]\n",
      "\n",
      "The RMSE score for Test Set using loss =  quantile  is:  1.932670852831446\n",
      "The R2 score for Test Set using loss =  quantile  is:  0.09753155359844135\n",
      "\n",
      "The best RMSE score for Test Set is  1.3733375716082044\n",
      "The max R2 score of Test Set is  0.5443085967700274\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "k = ['ls', 'lad', 'huber', 'quantile']\n",
    "n = 0\n",
    "gdb_rmse = np.zeros(4)\n",
    "gdb_r2 = np.zeros(4)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "for i in k:\n",
    "    reg = GradientBoostingRegressor(loss = i)\n",
    "    reg.fit(X_train, y_train)\n",
    "    grdbst_pred = reg.predict(X_test)\n",
    "    gdb_rmse[n] = np.sqrt(mean_squared_error(y_test,grdbst_pred))\n",
    "    gdb_r2[n] = r2_score(y_test,grdbst_pred)\n",
    "    print(\"\\nThe predicted values for Test Set using loss = \",i,\" is: \",grdbst_pred[0:5])\n",
    "    print(\"\\nThe RMSE score for Test Set using loss = \",i,\" is: \",gdb_rmse[n])\n",
    "    print(\"The R2 score for Test Set using loss = \",i,\" is: \",gdb_r2[n])\n",
    "    n += 1   \n",
    "print(\"\\nThe best RMSE score for Test Set is \", gdb_rmse.min())\n",
    "print(\"The max R2 score of Test Set is \", gdb_r2.max())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNearestNeighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The predicted values for Test Set with neighbor k =  1  is: \n",
      " [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [4.]\n",
      " [1.]]\n",
      "\n",
      "The RMSE score for Test Set with neighbor k =  1  is:  1.5275252316519468\n",
      "The R2 score for Test Set with neighbor k =  1  is:  0.43624161073825496\n",
      "\n",
      "The predicted values for Test Set with neighbor k =  2  is: \n",
      " [[1. ]\n",
      " [1. ]\n",
      " [1. ]\n",
      " [5. ]\n",
      " [1.5]]\n",
      "\n",
      "The RMSE score for Test Set with neighbor k =  2  is:  1.2583057392117916\n",
      "The R2 score for Test Set with neighbor k =  2  is:  0.6174496644295302\n",
      "\n",
      "The predicted values for Test Set with neighbor k =  3  is: \n",
      " [[1.33333333]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [5.        ]\n",
      " [1.66666667]]\n",
      "\n",
      "The RMSE score for Test Set with neighbor k =  3  is:  1.2692955176439846\n",
      "The R2 score for Test Set with neighbor k =  3  is:  0.610738255033557\n",
      "\n",
      "The predicted values for Test Set with neighbor k =  4  is: \n",
      " [[1.25]\n",
      " [1.25]\n",
      " [1.  ]\n",
      " [5.25]\n",
      " [1.5 ]]\n",
      "\n",
      "The RMSE score for Test Set with neighbor k =  4  is:  1.1902380714238083\n",
      "The R2 score for Test Set with neighbor k =  4  is:  0.6577181208053691\n",
      "\n",
      "The predicted values for Test Set with neighbor k =  5  is: \n",
      " [[1.4]\n",
      " [1.2]\n",
      " [1. ]\n",
      " [4.4]\n",
      " [1.4]]\n",
      "\n",
      "The RMSE score for Test Set with neighbor k =  5  is:  1.4352700094407325\n",
      "The R2 score for Test Set with neighbor k =  5  is:  0.5022818791946309\n",
      "\n",
      "The predicted values for Test Set with neighbor k =  6  is: \n",
      " [[1.33333333]\n",
      " [1.16666667]\n",
      " [1.        ]\n",
      " [4.        ]\n",
      " [1.33333333]]\n",
      "\n",
      "The RMSE score for Test Set with neighbor k =  6  is:  1.5605079894653489\n",
      "The R2 score for Test Set with neighbor k =  6  is:  0.4116331096196868\n",
      "\n",
      "The predicted values for Test Set with neighbor k =  7  is: \n",
      " [[1.28571429]\n",
      " [1.28571429]\n",
      " [1.        ]\n",
      " [3.57142857]\n",
      " [1.57142857]]\n",
      "\n",
      "The RMSE score for Test Set with neighbor k =  7  is:  1.7162686943752476\n",
      "The R2 score for Test Set with neighbor k =  7  is:  0.28831666894945895\n",
      "\n",
      "The predicted values for Test Set with neighbor k =  8  is: \n",
      " [[1.375]\n",
      " [1.25 ]\n",
      " [1.125]\n",
      " [3.5  ]\n",
      " [1.5  ]]\n",
      "\n",
      "The RMSE score for Test Set with neighbor k =  8  is:  1.731298886193061\n",
      "The R2 score for Test Set with neighbor k =  8  is:  0.2757969798657718\n",
      "\n",
      "The predicted values for Test Set with neighbor k =  9  is: \n",
      " [[1.33333333]\n",
      " [1.33333333]\n",
      " [1.22222222]\n",
      " [3.22222222]\n",
      " [1.44444444]]\n",
      "\n",
      "The RMSE score for Test Set with neighbor k =  9  is:  1.811031581984837\n",
      "The R2 score for Test Set with neighbor k =  9  is:  0.20755654983842908\n",
      "\n",
      "The best RMSE score for Test Set is  1.1902380714238083  with neighbor k =  4\n",
      "The max R2 score of Test Set is  0.6577181208053691  with neighbor k =  4\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "n = 0\n",
    "knn_rmse = np.zeros(9)\n",
    "knn_r2 = np.zeros(9)\n",
    "\n",
    "for i in range(1,10):\n",
    "    neigh = KNeighborsRegressor(n_neighbors=i)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    knn_pred = neigh.predict(X_test)\n",
    "    knn_rmse[n] = np.sqrt(mean_squared_error(y_test,knn_pred))\n",
    "    knn_r2[n] = r2_score(y_test,knn_pred)\n",
    "    print(\"\\nThe predicted values for Test Set with neighbor k = \",i,\" is: \\n\",knn_pred[0:5])\n",
    "    print(\"\\nThe RMSE score for Test Set with neighbor k = \",i,\" is: \",knn_rmse[n])\n",
    "    print(\"The R2 score for Test Set with neighbor k = \",i,\" is: \",knn_r2[n])\n",
    "    n += 1   \n",
    "print(\"\\nThe best RMSE score for Test Set is \", knn_rmse.min(), \" with neighbor k = \", knn_rmse.argmin()+1)\n",
    "print(\"The max R2 score of Test Set is \", knn_r2.max(), \" with neighbor k = \", knn_r2.argmax()+1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.36683989, 1.70131832, 1.65879737, 4.69130018, 1.96084502])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "reg = SGDRegressor()\n",
    "reg.fit(X_train, y_train)\n",
    "sgd_pred = reg.predict(X_test)\n",
    "sgd_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Score for Test set:  1.188136206245974\n",
      "R2 Score for Test set:  0.6589259382192434\n"
     ]
    }
   ],
   "source": [
    "sgd_rmse = np.sqrt(mean_squared_error(y_test,sgd_pred))\n",
    "sgd_r2 = r2_score(y_test,sgd_pred)\n",
    "print(\"RMSE Score for Test set: \",sgd_rmse)\n",
    "print(\"R2 Score for Test set: \",sgd_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The predicted values for Test Set with kernel =  linear  is:  [1.54398721 1.44360768 2.23734096 5.26736291 2.19228195]\n",
      "\n",
      "The RMSE score for Test Set with kernel =  linear  is:  0.9685241151876802\n",
      "The R2 score for Test Set with kernel =  linear  is:  0.7733597139516588\n",
      "\n",
      "The predicted values for Test Set with kernel =  poly  is:  [1.65047787 1.64945446 1.37405485 5.04581271 2.11618651]\n",
      "\n",
      "The RMSE score for Test Set with kernel =  poly  is:  1.2760816007488038\n",
      "The R2 score for Test Set with kernel =  poly  is:  0.6065648787670693\n",
      "\n",
      "The predicted values for Test Set with kernel =  rbf  is:  [1.20421134 1.03344859 1.89487548 3.66746999 2.03868186]\n",
      "\n",
      "The RMSE score for Test Set with kernel =  rbf  is:  1.5569739481545886\n",
      "The R2 score for Test Set with kernel =  rbf  is:  0.4142950100110393\n",
      "\n",
      "The predicted values for Test Set with kernel =  sigmoid  is:  [1.61233885 1.57518346 2.66090568 4.53493766 2.10052948]\n",
      "\n",
      "The RMSE score for Test Set with kernel =  sigmoid  is:  1.1615607669534436\n",
      "The R2 score for Test Set with kernel =  sigmoid  is:  0.6740131345522349\n",
      "\n",
      "The best RMSE score for Test Set is  0.9685241151876802\n",
      "The max R2 score of Test Set is  0.7733597139516588\n"
     ]
    }
   ],
   "source": [
    "#X= preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "k = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "n = 0\n",
    "svr_rmse = np.zeros(4)\n",
    "svr_r2 = np.zeros(4)\n",
    "\n",
    "for i in k:\n",
    "    reg = SVR(kernel = i)\n",
    "    reg.fit(X_train, y_train)\n",
    "    svr_pred = reg.predict(X_test)\n",
    "    svr_rmse[n] = np.sqrt(mean_squared_error(y_test,svr_pred))\n",
    "    svr_r2[n] = r2_score(y_test,svr_pred)\n",
    "    print(\"\\nThe predicted values for Test Set with kernel = \",i,\" is: \",svr_pred[0:5])\n",
    "    print(\"\\nThe RMSE score for Test Set with kernel = \",i,\" is: \",svr_rmse[n])\n",
    "    print(\"The R2 score for Test Set with kernel = \",i,\" is: \",svr_r2[n])\n",
    "    n += 1   \n",
    "print(\"\\nThe best RMSE score for Test Set is \", svr_rmse.min())\n",
    "print(\"The max R2 score of Test Set is \", svr_r2.max())         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NuSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The predicted values for Test Set with kernel =  linear  is:  [1.45739436 1.69701344 1.65806374 4.87838965 2.08367994]\n",
      "\n",
      "The RMSE score for Test Set with kernel =  linear  is:  1.1519512054038563\n",
      "The R2 score for Test Set with kernel =  linear  is:  0.6793845847870448\n",
      "\n",
      "The predicted values for Test Set with kernel =  poly  is:  [1.61265089 1.61892594 1.31835325 4.57007705 1.92228673]\n",
      "\n",
      "The RMSE score for Test Set with kernel =  poly  is:  1.3991703355575917\n",
      "The R2 score for Test Set with kernel =  poly  is:  0.5270040630566686\n",
      "\n",
      "The predicted values for Test Set with kernel =  rbf  is:  [1.31434575 1.17461074 1.92496727 3.56239909 1.85281946]\n",
      "\n",
      "The RMSE score for Test Set with kernel =  rbf  is:  1.5653457309570915\n",
      "The R2 score for Test Set with kernel =  rbf  is:  0.40797945458173634\n",
      "\n",
      "The predicted values for Test Set with kernel =  sigmoid  is:  [1.73808887 1.83846981 2.54292789 3.95632297 1.80682178]\n",
      "\n",
      "The RMSE score for Test Set with kernel =  sigmoid  is:  1.337053520396863\n",
      "The R2 score for Test Set with kernel =  sigmoid  is:  0.5680695557677637\n",
      "\n",
      "The best RMSE score for Test Set is  1.1519512054038563\n",
      "The max R2 score of Test Set is  0.6793845847870448\n"
     ]
    }
   ],
   "source": [
    "#X= preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.svm import NuSVR\n",
    "k = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "n = 0\n",
    "nusvr_rmse = np.zeros(4)\n",
    "nusvr_r2 = np.zeros(4)\n",
    "\n",
    "for i in k:\n",
    "    reg = NuSVR(kernel = i)\n",
    "    reg.fit(X_train, y_train)\n",
    "    nusvr_pred = reg.predict(X_test)\n",
    "    nusvr_rmse[n] = np.sqrt(mean_squared_error(y_test,nusvr_pred))\n",
    "    nusvr_r2[n] = r2_score(y_test,nusvr_pred)\n",
    "    print(\"\\nThe predicted values for Test Set with kernel = \",i,\" is: \",nusvr_pred[0:5])\n",
    "    print(\"\\nThe RMSE score for Test Set with kernel = \",i,\" is: \",nusvr_rmse[n])\n",
    "    print(\"The R2 score for Test Set with kernel = \",i,\" is: \",nusvr_r2[n])\n",
    "    n += 1   \n",
    "print(\"\\nThe best RMSE score for Test Set is \", nusvr_rmse.min())\n",
    "print(\"The max R2 score of Test Set is \", nusvr_r2.max())         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The predicted values for Test Set is:  [1.58262906 1.4801285  2.07500242 5.05749503 2.36061874]\n",
      "\n",
      "The RMSE score for Test Set is:  1.088551498566798\n",
      "The R2 score for Test Set is:  0.7137047171734714\n"
     ]
    }
   ],
   "source": [
    "#X= preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "reg = LinearSVR()\n",
    "reg.fit(X_train, y_train)\n",
    "linsvr_pred = reg.predict(X_test)\n",
    "linsvr_rmse = np.sqrt(mean_squared_error(y_test,linsvr_pred))\n",
    "linsvr_r2 = r2_score(y_test,linsvr_pred)\n",
    "print(\"\\nThe predicted values for Test Set is: \",linsvr_pred[0:5])\n",
    "print(\"\\nThe RMSE score for Test Set is: \",linsvr_rmse)\n",
    "print(\"The R2 score for Test Set is: \",linsvr_r2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report on accuracy of different algorithms using RMSE value and R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse = root mean squared score.......r2 = R2-Score\n",
    "# 1.Linear Models\n",
    "# 1.1. Linear Regression\n",
    "linrgr_rmse\n",
    "linrgr_r2\n",
    "\n",
    "# 1.2. Ridge Regression\n",
    "rdgrgr_rmse\n",
    "rdgrgr_r2\n",
    "\n",
    "# 1.3. Lasso\n",
    "lasrgr_rmse\n",
    "lasrgr_r2\n",
    "\n",
    "# 1.4. ElasticNet\n",
    "enrgr_rmse\n",
    "enrgr_r2\n",
    "\n",
    "# 1.5. LarsLasso\n",
    "lslrrgr_rmse\n",
    "lslrrgr_r2\n",
    "\n",
    "# 2.Polynomial Regression\n",
    "plrgr_rmse = plrgr_rmse.min()\n",
    "plrgr_r2 = plrgr_r2.max()\n",
    "\n",
    "# 3.Decision Tree\n",
    "dt_rmse = dt_rmse.min()\n",
    "dt_r2 = dt_r2.max()\n",
    "\n",
    "# 4.Ensemble Methods\n",
    "# 4.1. Random Forest\n",
    "rf_rmse = rf_rmse.min()\n",
    "rf_r2 = rf_r2.max()\n",
    "\n",
    "# 4.2. AdaBoost\n",
    "adb_rmse = adb_rmse.min()\n",
    "adb_r2 = adb_r2.max()\n",
    "\n",
    "# 4.3. GradientBoost\n",
    "gdb_rmse = gdb_rmse.min()\n",
    "gdb_r2 = gdb_r2.max()\n",
    "\n",
    "# 5.KNearestNeighbor\n",
    "knn_rmse = knn_rmse.min()\n",
    "knn_r2 = knn_r2.max()\n",
    "\n",
    "# 6.Stochastic Gradient Descent\n",
    "sgd_rmse\n",
    "sgd_r2\n",
    "\n",
    "# 7.Support Vector Machines\n",
    "# 7.1. SVR\n",
    "svr_rmse = svr_rmse.min()\n",
    "svr_r2 = svr_r2.max()\n",
    "\n",
    "# 7.2. NuSVR\n",
    "nusvr_rmse = nusvr_rmse.min()\n",
    "nusvr_r2 = nusvr_r2.max()\n",
    "# 7.3. LinearSVR\n",
    "linsvr_rmse = linsvr_rmse\n",
    "linsvr_r2 = linsvr_r2\n",
    "\n",
    "#max of all\n",
    "min_rmse = [linrgr_rmse,rdgrgr_rmse,lasrgr_rmse,enrgr_rmse,lslrrgr_rmse,plrgr_rmse,dt_rmse,rf_rmse,adb_rmse,gdb_rmse,knn_rmse,sgd_rmse,svr_rmse,nusvr_rmse,linsvr_rmse]\n",
    "max_r2 = [linrgr_r2,rdgrgr_r2,lasrgr_r2,enrgr_r2,lslrrgr_r2,plrgr_r2,dt_r2,rf_r2,adb_r2,gdb_r2,knn_r2,sgd_r2,svr_r2,nusvr_r2,linsvr_r2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>R2-Sore</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.759749</td>\n",
       "      <td>0.997183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>0.759384</td>\n",
       "      <td>0.997940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>0.629825</td>\n",
       "      <td>1.237785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ElasticNet Regression</td>\n",
       "      <td>0.747428</td>\n",
       "      <td>1.022433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LarsLasso Regression</td>\n",
       "      <td>0.761709</td>\n",
       "      <td>0.993105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>0.759749</td>\n",
       "      <td>0.997183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree Regression</td>\n",
       "      <td>0.637584</td>\n",
       "      <td>1.224745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest Regression</td>\n",
       "      <td>0.516779</td>\n",
       "      <td>1.185482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaBoost Regression</td>\n",
       "      <td>0.692349</td>\n",
       "      <td>1.128421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gradient Boosting Regression</td>\n",
       "      <td>0.544309</td>\n",
       "      <td>1.373338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNearest Neighbor Regression</td>\n",
       "      <td>0.657718</td>\n",
       "      <td>1.190238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Stochastic Gradient Regression</td>\n",
       "      <td>0.658926</td>\n",
       "      <td>1.188136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Support Vector Regression</td>\n",
       "      <td>0.773360</td>\n",
       "      <td>0.968524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Nu Support Vector Regression</td>\n",
       "      <td>0.679385</td>\n",
       "      <td>1.151951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Linear Support Vector Regression</td>\n",
       "      <td>0.713705</td>\n",
       "      <td>1.088551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Algorithm   R2-Sore  Root Mean Squared Error\n",
       "1                  Linear Regression  0.759749                 0.997183\n",
       "2                   Ridge Regression  0.759384                 0.997940\n",
       "3                   Lasso Regression  0.629825                 1.237785\n",
       "4              ElasticNet Regression  0.747428                 1.022433\n",
       "5               LarsLasso Regression  0.761709                 0.993105\n",
       "6              Polynomial Regression  0.759749                 0.997183\n",
       "7           Decision Tree Regression  0.637584                 1.224745\n",
       "8           Random Forest Regression  0.516779                 1.185482\n",
       "9                AdaBoost Regression  0.692349                 1.128421\n",
       "10      Gradient Boosting Regression  0.544309                 1.373338\n",
       "11      KNearest Neighbor Regression  0.657718                 1.190238\n",
       "12    Stochastic Gradient Regression  0.658926                 1.188136\n",
       "13         Support Vector Regression  0.773360                 0.968524\n",
       "14      Nu Support Vector Regression  0.679385                 1.151951\n",
       "15  Linear Support Vector Regression  0.713705                 1.088551"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Algorithm':['Linear Regression', 'Ridge Regression', 'Lasso Regression', 'ElasticNet Regression', 'LarsLasso Regression', 'Polynomial Regression','Decision Tree Regression','Random Forest Regression','AdaBoost Regression','Gradient Boosting Regression','KNearest Neighbor Regression','Stochastic Gradient Regression','Support Vector Regression','Nu Support Vector Regression','Linear Support Vector Regression'], \n",
    "        'R2-Sore':max_r2, 'Root Mean Squared Error':min_rmse}\n",
    "s = pd.DataFrame(data, index = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best R-squared score is shown by Linear Regression\n",
      "\n",
      "R2 Score =  0.7597485891323608\n"
     ]
    }
   ],
   "source": [
    "print(\"The best R-squared score is shown by Linear Regression\")\n",
    "print(\"\\nR2 Score = \",linrgr_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a test set for the next 30 years and predicting Manchester United's League Standing using the best algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Division</th>\n",
       "      <th>P</th>\n",
       "      <th>W</th>\n",
       "      <th>D</th>\n",
       "      <th>L</th>\n",
       "      <th>F</th>\n",
       "      <th>A</th>\n",
       "      <th>Pts</th>\n",
       "      <th>Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992</td>\n",
       "      <td>Prem</td>\n",
       "      <td>42</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>67</td>\n",
       "      <td>31</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1993</td>\n",
       "      <td>Prem</td>\n",
       "      <td>42</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>38</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1994</td>\n",
       "      <td>Prem</td>\n",
       "      <td>42</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>77</td>\n",
       "      <td>28</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995</td>\n",
       "      <td>Prem</td>\n",
       "      <td>38</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>73</td>\n",
       "      <td>35</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1996</td>\n",
       "      <td>Prem</td>\n",
       "      <td>38</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>44</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season Division   P   W   D  L   F   A  Pts  Pos\n",
       "0    1992     Prem  42  24  12  6  67  31   84    1\n",
       "1    1993     Prem  42  27  11  4  80  38   92    1\n",
       "2    1994     Prem  42  26  10  6  77  28   88    2\n",
       "3    1995     Prem  38  25   7  6  73  35   82    1\n",
       "4    1996     Prem  38  21  12  5  76  44   75    1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd = pd.read_csv(r'E:\\Datasets\\Manchester_United_prediction\\PL data\\Man_Utd.csv', encoding = 'unicode_escape')   \n",
    "fd.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = fd.drop(['Division'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of W =  24\n",
      "std of W =  3\n",
      "The random value which we require is between  21  and  27\n"
     ]
    }
   ],
   "source": [
    "print(\"mean of W = \",round(fd.W.mean()))\n",
    "print(\"std of W = \",round(fd.W.std()))\n",
    "min1 = round(fd.W.mean())-round(fd.W.std())\n",
    "max1 = round(fd.W.mean())+round(fd.W.std())\n",
    "print(\"The random value which we require is between \",min1,\" and \",max1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.zeros(30)\n",
    "for i in range(0,30):\n",
    "    w[i] = random.randint(21,27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of D =  8\n",
      "std of D =  3\n",
      "The random value which we require is between  5  and  11\n"
     ]
    }
   ],
   "source": [
    "print(\"mean of D = \",round(fd.D.mean()))\n",
    "print(\"std of D = \",round(fd.D.std()))\n",
    "min2 = round(fd.D.mean())-round(fd.D.std())\n",
    "max2 = round(fd.D.mean())+round(fd.D.std())\n",
    "print(\"The random value which we require is between \",min2,\" and \",max2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.zeros(30)\n",
    "for i in range(0,30):\n",
    "    d[i] = random.randint(5,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.zeros(30)\n",
    "for i in range(0,30):\n",
    "    l[i] = (38 - (w[i]+d[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of F =  74\n",
      "std of F =  11\n",
      "The random value which we require is between  63  and  85\n"
     ]
    }
   ],
   "source": [
    "print(\"mean of F = \",round(fd.F.mean()))\n",
    "print(\"std of F = \",round(fd.F.std()))\n",
    "min4 = round(fd.F.mean())-round(fd.F.std())\n",
    "max4 = round(fd.F.mean())+round(fd.F.std())\n",
    "print(\"The random value which we require is between \",min4,\" and \",max4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.zeros(30)\n",
    "for i in range(0,30):\n",
    "    f[i] = random.randint(63,85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of A =  34\n",
      "std of A =  8\n",
      "The random value which we require is between  26  and  42\n"
     ]
    }
   ],
   "source": [
    "print(\"mean of A = \",round(fd.A.mean()))\n",
    "print(\"std of A = \",round(fd.A.std()))\n",
    "min5 = round(fd.A.mean())-round(fd.A.std())\n",
    "max5 = round(fd.A.mean())+round(fd.A.std())\n",
    "print(\"The random value which we require is between \",min5,\" and \",max5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(30)\n",
    "for i in range(0,30):\n",
    "    a[i] = random.randint(26,42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.zeros(30)\n",
    "for i in range(0,30):\n",
    "    p[i] = (3*w[i]+d[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "test_set = np.zeros((30,8))\n",
    "s = 38\n",
    "for i in range(2019,2049):\n",
    "    test_set[n] = [i, s, w[n], d[n], l[n], f[n], a[n], p[n]]\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2019.,   38.,   24.,    6.,    8.,   70.,   27.,   78.],\n",
       "       [2020.,   38.,   22.,    5.,   11.,   71.,   34.,   71.],\n",
       "       [2021.,   38.,   21.,    9.,    8.,   68.,   27.,   72.],\n",
       "       [2022.,   38.,   22.,    9.,    7.,   67.,   30.,   75.],\n",
       "       [2023.,   38.,   26.,    6.,    6.,   81.,   37.,   84.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.98300657],\n",
       "       [5.50802077],\n",
       "       [4.99358512],\n",
       "       [4.53774963],\n",
       "       [3.34742227]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_df = LinearRegression()  \n",
    "lin_df.fit(X1, y1)\n",
    "lr_pred = lin_df.predict(test_set)   \n",
    "lr_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [3.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plpred = np.floor(lr_pred)\n",
    "plpred[0:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
