{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<h1 align=\"center\"><font size=\"5\">Predicting Type Of Drug</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data From CSV File  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Na_to_K</th>\n",
       "      <th>Drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>25.355</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>13.093</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>10.114</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>F</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>7.798</td>\n",
       "      <td>drugX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>18.043</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>36</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>11.424</td>\n",
       "      <td>drugX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>58</td>\n",
       "      <td>F</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>38.247</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>56</td>\n",
       "      <td>F</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>25.395</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>35.639</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>15</td>\n",
       "      <td>F</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>16.725</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Sex      BP Cholesterol  Na_to_K   Drug\n",
       "0    23   F    HIGH        HIGH   25.355  drugY\n",
       "1    47   M     LOW        HIGH   13.093  drugC\n",
       "2    47   M     LOW        HIGH   10.114  drugC\n",
       "3    28   F  NORMAL        HIGH    7.798  drugX\n",
       "4    61   F     LOW        HIGH   18.043  drugY\n",
       "..  ...  ..     ...         ...      ...    ...\n",
       "95   36   M     LOW      NORMAL   11.424  drugX\n",
       "96   58   F     LOW        HIGH   38.247  drugY\n",
       "97   56   F    HIGH        HIGH   25.395  drugY\n",
       "98   20   M    HIGH      NORMAL   35.639  drugY\n",
       "99   15   F    HIGH      NORMAL   16.725  drugY\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv ('E:\\Datasets\\drug200.csv')   \n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Na_to_K</th>\n",
       "      <th>Drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age    Sex     BP  Cholesterol  Na_to_K   Drug\n",
       "0    False  False  False        False    False  False\n",
       "1    False  False  False        False    False  False\n",
       "2    False  False  False        False    False  False\n",
       "3    False  False  False        False    False  False\n",
       "4    False  False  False        False    False  False\n",
       "..     ...    ...    ...          ...      ...    ...\n",
       "195  False  False  False        False    False  False\n",
       "196  False  False  False        False    False  False\n",
       "197  False  False  False        False    False  False\n",
       "198  False  False  False        False    False  False\n",
       "199  False  False  False        False    False  False\n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Na_to_K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>44.315000</td>\n",
       "      <td>16.084485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.544315</td>\n",
       "      <td>7.223956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>6.269000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>10.445500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>13.936500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>19.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>38.247000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age     Na_to_K\n",
       "count  200.000000  200.000000\n",
       "mean    44.315000   16.084485\n",
       "std     16.544315    7.223956\n",
       "min     15.000000    6.269000\n",
       "25%     31.000000   10.445500\n",
       "50%     45.000000   13.936500\n",
       "75%     58.000000   19.380000\n",
       "max     74.000000   38.247000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23, 'F', 'HIGH', 'HIGH', 25.355],\n",
       "       [47, 'M', 'LOW', 'HIGH', 13.093],\n",
       "       [47, 'M', 'LOW', 'HIGH', 10.113999999999999],\n",
       "       [28, 'F', 'NORMAL', 'HIGH', 7.797999999999999],\n",
       "       [61, 'F', 'LOW', 'HIGH', 18.043]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K']].values\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may figure out, some features in this dataset are categorical such as __Sex__ or __BP__. Unfortunately, Sklearn Decision Trees do not handle categorical variables. But still we can convert these features to numerical values. __pandas.get_dummies()__\n",
    "Convert categorical variable into dummy/indicator variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing:  Feature selection/extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23, 0, 0, 0, 25.355],\n",
       "       [47, 1, 1, 0, 13.093],\n",
       "       [47, 1, 1, 0, 10.113999999999999],\n",
       "       [28, 0, 2, 0, 7.797999999999999],\n",
       "       [61, 0, 1, 0, 18.043]], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le_sex = preprocessing.LabelEncoder()\n",
    "le_sex.fit(['F','M'])\n",
    "X[:,1] = le_sex.transform(X[:,1]) \n",
    "\n",
    "\n",
    "le_BP = preprocessing.LabelEncoder()\n",
    "le_BP.fit([ 'LOW', 'NORMAL', 'HIGH'])\n",
    "X[:,2] = le_BP.transform(X[:,2])\n",
    "\n",
    "\n",
    "le_Chol = preprocessing.LabelEncoder()\n",
    "le_Chol.fit([ 'NORMAL', 'HIGH'])\n",
    "X[:,3] = le_Chol.transform(X[:,3]) \n",
    "\n",
    "X[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    drugY\n",
       "1    drugC\n",
       "2    drugC\n",
       "3    drugX\n",
       "4    drugY\n",
       "Name: Drug, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[\"Drug\"]\n",
    "y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Normalize Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.29159102, -1.040833  , -1.11016894, -0.97043679,  1.28652212],\n",
       "       [ 0.16269866,  0.96076892,  0.10979693, -0.97043679, -0.4151454 ],\n",
       "       [ 0.16269866,  0.96076892,  0.10979693, -0.97043679, -0.82855818],\n",
       "       [-0.988614  , -1.040833  ,  1.32976279, -0.97043679, -1.14996267],\n",
       "       [ 1.0110343 , -1.040833  ,  0.10979693, -0.97043679,  0.27179427]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "- K Nearest Neighbor(KNN)\n",
    "- Decision Tree\n",
    "- Support Vector Machine\n",
    "- Logistic Regression\n",
    "- Naive Bayes\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide the dataset into Training and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbor(KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted values using K =  1 is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugC']\n",
      "The predicted values using K =  2 is  ['drugY' 'drugY' 'drugY' 'drugB' 'drugC']\n",
      "The predicted values using K =  3 is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugY']\n",
      "The predicted values using K =  4 is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugY']\n",
      "The predicted values using K =  5 is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugY']\n",
      "The predicted values using K =  6 is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugY']\n",
      "The predicted values using K =  7 is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugY']\n",
      "The predicted values using K =  8 is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugY']\n",
      "The predicted values using K =  9 is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugY']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "Ks = 10\n",
    "for n in range(1,Ks):\n",
    "    #Train Model and Predict  \n",
    "    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n",
    "    yhat_KNN=neigh.predict(X_test)\n",
    "    print(\"The predicted values using K = \", n, \"is \", yhat_KNN[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values predicted by Decision Tree using criterion =  entropy  is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugC']\n",
      "The values predicted by Decision Tree using criterion =  gini  is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugC']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree_criterions = ['entropy', 'gini']\n",
    "for i in dtree_criterions:\n",
    "    drugTree = DecisionTreeClassifier(criterion=i)\n",
    "    drugTree.fit(X_train, y_train)\n",
    "    predTree = drugTree.predict(X_test)\n",
    "    print (\"The values predicted by Decision Tree using criterion = \",i,\" is \", predTree [0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values predicted by SVM using kernels =  rbf  is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugY']\n",
      "The values predicted by SVM using kernels =  linear  is  ['drugY' 'drugY' 'drugY' 'drugB' 'drugY']\n",
      "The values predicted by SVM using kernels =  poly  is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugY']\n",
      "The values predicted by SVM using kernels =  sigmoid  is  ['drugY' 'drugA' 'drugY' 'drugB' 'drugC']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_kernels = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "for i in svm_kernels:\n",
    "    clf = svm.SVC(kernel=i)\n",
    "    clf.fit(X_train, y_train) \n",
    "    yhat_SVM = clf.predict(X_test)\n",
    "    print(\"The values predicted by SVM using kernels = \", i, \" is \", yhat_SVM [0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values predicted by Logistic Regression using c =  0.001  and solver =  liblinear  is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugX']\n",
      "The values predicted by Logistic Regression using c =  0.01  and solver =  liblinear  is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugX']\n",
      "The values predicted by Logistic Regression using c =  0.1  and solver =  liblinear  is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugY']\n",
      "The values predicted by Logistic Regression using c =  0.001  and solver =  newton-cg  is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugY']\n",
      "The values predicted by Logistic Regression using c =  0.01  and solver =  newton-cg  is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugY']\n",
      "The values predicted by Logistic Regression using c =  0.1  and solver =  newton-cg  is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugY']\n",
      "The values predicted by Logistic Regression using c =  0.001  and solver =  lbfgs  is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugY']\n",
      "The values predicted by Logistic Regression using c =  0.01  and solver =  lbfgs  is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugY']\n",
      "The values predicted by Logistic Regression using c =  0.1  and solver =  lbfgs  is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugY']\n",
      "The values predicted by Logistic Regression using c =  0.001  and solver =  sag  is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugY']\n",
      "The values predicted by Logistic Regression using c =  0.01  and solver =  sag  is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugY']\n",
      "The values predicted by Logistic Regression using c =  0.1  and solver =  sag  is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugY']\n",
      "The values predicted by Logistic Regression using c =  0.001  and solver =  saga  is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugY']\n",
      "The values predicted by Logistic Regression using c =  0.01  and solver =  saga  is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugY']\n",
      "The values predicted by Logistic Regression using c =  0.1  and solver =  saga  is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugY']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "c_param_range=[0.001,0.01,0.1]\n",
    "lr_solvers=['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "for i in lr_solvers:\n",
    "    for f in c_param_range:\n",
    "        LR = LogisticRegression(C=f, solver=i).fit(X_train,y_train)\n",
    "        yhat_LR = LR.predict(X_test)\n",
    "        print(\"The values predicted by Logistic Regression using c = \",f,\" and solver = \",i, \" is \",yhat_LR[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values predicted by Naive Bayes is  ['drugA' 'drugA' 'drugY' 'drugB' 'drugC']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred_NB = gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"The values predicted by Naive Bayes is \", y_pred_NB[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values predicted by Random Forest using criterion =  entropy  is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugC']\n",
      "The values predicted by Random Forest using criterion =  gini  is  ['drugY' 'drugY' 'drugY' 'drugY' 'drugC']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_criterion=['entropy', 'gini']\n",
    "for i in rf_criterion:\n",
    "    clf=RandomForestClassifier(criterion=i)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred_RF=clf.predict(X_test)\n",
    "    print(\"The values predicted by Random Forest using criterion = \", i,\" is \",y_pred_RF[0:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation using Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score with k =  1 is  0.8833333333333333\n",
      "The f1 score with k =  1 is  0.8844955300127714\n",
      "The accuracy score with k =  2 is  0.8333333333333334\n",
      "The f1 score with k =  2 is  0.8335500033346671\n",
      "The accuracy score with k =  3 is  0.8333333333333334\n",
      "The f1 score with k =  3 is  0.8335819019689988\n",
      "The accuracy score with k =  4 is  0.7166666666666667\n",
      "The f1 score with k =  4 is  0.7164793092212448\n",
      "The accuracy score with k =  5 is  0.6833333333333333\n",
      "The f1 score with k =  5 is  0.6881845752813495\n",
      "The accuracy score with k =  6 is  0.6833333333333333\n",
      "The f1 score with k =  6 is  0.6892581927876047\n",
      "The accuracy score with k =  7 is  0.7166666666666667\n",
      "The f1 score with k =  7 is  0.7207855650097028\n",
      "The accuracy score with k =  8 is  0.65\n",
      "The f1 score with k =  8 is  0.6488748137108793\n",
      "The accuracy score with k =  9 is  0.6666666666666666\n",
      "The f1 score with k =  9 is  0.6611744687013504\n",
      "\n",
      "The best accuracy score for KNN was  0.8833333333333333 with k= 1\n",
      "The best f1 score for KNN was  0.8844955300127714 with k= 1\n"
     ]
    }
   ],
   "source": [
    "Ks = 10\n",
    "accuracy_scor = np.zeros((Ks-1))\n",
    "f1_scor = np.zeros((Ks-1))\n",
    "\n",
    "\n",
    "for n in range(1,Ks):\n",
    "    \n",
    "    #Train Model and Predict  \n",
    "    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n",
    "    yhat_KNN=neigh.predict(X_test)\n",
    "    accuracy_scor[n-1] = accuracy_score(y_test, yhat_KNN)\n",
    "    f1_scor[n-1] = f1_score(y_test, yhat_KNN, average = 'weighted')\n",
    "    print(\"The accuracy score with k = \",n, \"is \",accuracy_scor[n-1])\n",
    "    print(\"The f1 score with k = \",n, \"is \",f1_scor[n-1])\n",
    "    \n",
    "\n",
    "print( \"\\nThe best accuracy score for KNN was \", accuracy_scor.max(), \"with k=\", accuracy_scor.argmax()+1) \n",
    "print( \"The best f1 score for KNN was \", f1_scor.max(), \"with k=\", f1_scor.argmax()+1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report of KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.88      1.00      0.93         7\n",
      "       drugB       0.67      0.67      0.67         3\n",
      "       drugC       1.00      1.00      1.00         8\n",
      "       drugX       0.75      0.92      0.83        13\n",
      "       drugY       0.96      0.83      0.89        29\n",
      "\n",
      "    accuracy                           0.88        60\n",
      "   macro avg       0.85      0.88      0.86        60\n",
      "weighted avg       0.90      0.88      0.88        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors = accuracy_scor.argmax()+1).fit(X_train,y_train)\n",
    "yhat_KNN=neigh.predict(X_test)\n",
    "print (classification_report(y_test, yhat_KNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTrees's Accuracy with criterion =  entropy  using Accuracy Score:  0.9666666666666667\n",
      "DecisionTrees's Accuracy with criterion =  entropy  using F1 Score:  0.9653634651600753\n",
      "DecisionTrees's Accuracy with criterion =  gini  using Accuracy Score:  0.9666666666666667\n",
      "DecisionTrees's Accuracy with criterion =  gini  using F1 Score:  0.9653634651600753\n",
      "\n",
      "The best accuracy score using Decision Tree is  0.9666666666666667\n",
      "The best f1 score using Decision Tree is  0.9653634651600753\n"
     ]
    }
   ],
   "source": [
    "f = 0\n",
    "ascore_dtree = np.zeros(2)\n",
    "fscore_dtree = np.zeros(2)\n",
    "dtree_criterions = ['entropy', 'gini']\n",
    "for i in dtree_criterions:\n",
    "    drugTree = DecisionTreeClassifier(criterion=i)\n",
    "    drugTree.fit(X_train, y_train)\n",
    "    predTree = drugTree.predict(X_test)\n",
    "    ascore_dtree[f] = accuracy_score(y_test, predTree)\n",
    "    fscore_dtree[f] = f1_score(y_test, predTree, average = 'weighted')\n",
    "    print(\"DecisionTrees's Accuracy with criterion = \", i,\" using Accuracy Score: \", accuracy_score(y_test, predTree))\n",
    "    print(\"DecisionTrees's Accuracy with criterion = \", i,\" using F1 Score: \", f1_score(y_test, predTree, average = 'weighted'))\n",
    "    f += 1\n",
    "print(\"\\nThe best accuracy score using Decision Tree is \",ascore_dtree.max())\n",
    "print(\"The best f1 score using Decision Tree is \",fscore_dtree.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for criterion =  entropy \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.88      1.00      0.93         7\n",
      "       drugB       1.00      0.67      0.80         3\n",
      "       drugC       1.00      1.00      1.00         8\n",
      "       drugX       1.00      0.92      0.96        13\n",
      "       drugY       0.97      1.00      0.98        29\n",
      "\n",
      "    accuracy                           0.97        60\n",
      "   macro avg       0.97      0.92      0.94        60\n",
      "weighted avg       0.97      0.97      0.97        60\n",
      "\n",
      "Classification report for criterion =  gini \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.88      1.00      0.93         7\n",
      "       drugB       1.00      0.67      0.80         3\n",
      "       drugC       1.00      1.00      1.00         8\n",
      "       drugX       1.00      0.92      0.96        13\n",
      "       drugY       0.97      1.00      0.98        29\n",
      "\n",
      "    accuracy                           0.97        60\n",
      "   macro avg       0.97      0.92      0.94        60\n",
      "weighted avg       0.97      0.97      0.97        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = ['entropy','gini']\n",
    "for i in k:\n",
    "    drugTree = DecisionTreeClassifier(criterion=i)\n",
    "    drugTree.fit(X_train, y_train)\n",
    "    predTree = drugTree.predict(X_test)\n",
    "    print(\"Classification report for criterion = \",i,\"\\n\\n\",classification_report(y_test, predTree))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for SVM with kernel =  rbf  is :  0.8833333333333333\n",
      "The f1 score for SVM with kernel =  rbf  is:  0.8826190476190476\n",
      "The accuracy score for SVM with kernel =  linear  is :  0.9333333333333333\n",
      "The f1 score for SVM with kernel =  linear  is:  0.936466165413534\n",
      "The accuracy score for SVM with kernel =  poly  is :  0.7666666666666667\n",
      "The f1 score for SVM with kernel =  poly  is:  0.7256016215220195\n",
      "The accuracy score for SVM with kernel =  sigmoid  is :  0.85\n",
      "The f1 score for SVM with kernel =  sigmoid  is:  0.8566363919305096\n",
      "\n",
      "The best accuracy score using SVM is  0.9333333333333333\n",
      "The best f1 score using SVM is  0.936466165413534\n"
     ]
    }
   ],
   "source": [
    "f=0\n",
    "ascore_svm = np.zeros(4)\n",
    "fscore_svm = np.zeros(4)\n",
    "svm_kernels = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "\n",
    "for i in svm_kernels:\n",
    "    clf = svm.SVC(kernel=i)\n",
    "    clf.fit(X_train, y_train) \n",
    "    yhat_SVM = clf.predict(X_test)\n",
    "    ascore_svm[f] = accuracy_score(y_test, yhat_SVM)\n",
    "    fscore_svm[f] = f1_score(y_test, yhat_SVM, average='weighted')\n",
    "    print(\"The accuracy score for SVM with kernel = \", i,\" is : \", accuracy_score(y_test, yhat_SVM))\n",
    "    print(\"The f1 score for SVM with kernel = \", i,\" is: \", f1_score(y_test, yhat_SVM, average='weighted'))\n",
    "    f += 1\n",
    "print(\"\\nThe best accuracy score using SVM is \",ascore_svm.max())\n",
    "print(\"The best f1 score using SVM is \",fscore_svm.max())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report of SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for kernel =  rbf  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.86      0.86      0.86         7\n",
      "       drugB       0.67      0.67      0.67         3\n",
      "       drugC       1.00      0.75      0.86         8\n",
      "       drugX       0.92      0.92      0.92        13\n",
      "       drugY       0.87      0.93      0.90        29\n",
      "\n",
      "    accuracy                           0.88        60\n",
      "   macro avg       0.86      0.83      0.84        60\n",
      "weighted avg       0.89      0.88      0.88        60\n",
      "\n",
      "Classification report for kernel =  linear  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.88      1.00      0.93         7\n",
      "       drugB       0.50      0.67      0.57         3\n",
      "       drugC       1.00      0.88      0.93         8\n",
      "       drugX       1.00      1.00      1.00        13\n",
      "       drugY       0.96      0.93      0.95        29\n",
      "\n",
      "    accuracy                           0.93        60\n",
      "   macro avg       0.87      0.89      0.88        60\n",
      "weighted avg       0.94      0.93      0.94        60\n",
      "\n",
      "Classification report for kernel =  poly  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.80      0.57      0.67         7\n",
      "       drugB       0.50      0.33      0.40         3\n",
      "       drugC       1.00      0.12      0.22         8\n",
      "       drugX       0.93      1.00      0.96        13\n",
      "       drugY       0.71      0.93      0.81        29\n",
      "\n",
      "    accuracy                           0.77        60\n",
      "   macro avg       0.79      0.59      0.61        60\n",
      "weighted avg       0.80      0.77      0.73        60\n",
      "\n",
      "Classification report for kernel =  sigmoid  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.70      1.00      0.82         7\n",
      "       drugB       0.25      0.33      0.29         3\n",
      "       drugC       1.00      0.75      0.86         8\n",
      "       drugX       0.86      0.92      0.89        13\n",
      "       drugY       0.96      0.86      0.91        29\n",
      "\n",
      "    accuracy                           0.85        60\n",
      "   macro avg       0.75      0.77      0.75        60\n",
      "weighted avg       0.88      0.85      0.86        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "for i in k:\n",
    "    clf = svm.SVC(kernel=i)\n",
    "    clf.fit(X_train, y_train) \n",
    "    yhat_SVM = clf.predict(X_test)\n",
    "    print (\"Classification report for kernel = \",i,\" \\n\\n\",classification_report(y_test, yhat_SVM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for Logistic Regression with solver =  0.001  and kernel =  liblinear  is :  0.7666666666666667\n",
      "The f1 score for Logistic Regression with solver =  0.001  and kernel =  liblinear  is :  0.7282407407407407\n",
      "The accuracy score for Logistic Regression with solver =  0.01  and kernel =  liblinear  is :  0.7833333333333333\n",
      "The f1 score for Logistic Regression with solver =  0.01  and kernel =  liblinear  is :  0.7421320346320345\n",
      "The accuracy score for Logistic Regression with solver =  0.1  and kernel =  liblinear  is :  0.7833333333333333\n",
      "The f1 score for Logistic Regression with solver =  0.1  and kernel =  liblinear  is :  0.7386554621848741\n",
      "The accuracy score for Logistic Regression with solver =  0.001  and kernel =  newton-cg  is :  0.48333333333333334\n",
      "The f1 score for Logistic Regression with solver =  0.001  and kernel =  newton-cg  is :  0.31498127340823967\n",
      "The accuracy score for Logistic Regression with solver =  0.01  and kernel =  newton-cg  is :  0.6166666666666667\n",
      "The f1 score for Logistic Regression with solver =  0.01  and kernel =  newton-cg  is :  0.5079924242424243\n",
      "The accuracy score for Logistic Regression with solver =  0.1  and kernel =  newton-cg  is :  0.7833333333333333\n",
      "The f1 score for Logistic Regression with solver =  0.1  and kernel =  newton-cg  is :  0.7131899641577061\n",
      "The accuracy score for Logistic Regression with solver =  0.001  and kernel =  lbfgs  is :  0.48333333333333334\n",
      "The f1 score for Logistic Regression with solver =  0.001  and kernel =  lbfgs  is :  0.31498127340823967\n",
      "The accuracy score for Logistic Regression with solver =  0.01  and kernel =  lbfgs  is :  0.6166666666666667\n",
      "The f1 score for Logistic Regression with solver =  0.01  and kernel =  lbfgs  is :  0.5079924242424243\n",
      "The accuracy score for Logistic Regression with solver =  0.1  and kernel =  lbfgs  is :  0.7833333333333333\n",
      "The f1 score for Logistic Regression with solver =  0.1  and kernel =  lbfgs  is :  0.7131899641577061\n",
      "The accuracy score for Logistic Regression with solver =  0.001  and kernel =  sag  is :  0.48333333333333334\n",
      "The f1 score for Logistic Regression with solver =  0.001  and kernel =  sag  is :  0.31498127340823967\n",
      "The accuracy score for Logistic Regression with solver =  0.01  and kernel =  sag  is :  0.6166666666666667\n",
      "The f1 score for Logistic Regression with solver =  0.01  and kernel =  sag  is :  0.5079924242424243\n",
      "The accuracy score for Logistic Regression with solver =  0.1  and kernel =  sag  is :  0.7833333333333333\n",
      "The f1 score for Logistic Regression with solver =  0.1  and kernel =  sag  is :  0.7131899641577061\n",
      "The accuracy score for Logistic Regression with solver =  0.001  and kernel =  saga  is :  0.48333333333333334\n",
      "The f1 score for Logistic Regression with solver =  0.001  and kernel =  saga  is :  0.31498127340823967\n",
      "The accuracy score for Logistic Regression with solver =  0.01  and kernel =  saga  is :  0.6166666666666667\n",
      "The f1 score for Logistic Regression with solver =  0.01  and kernel =  saga  is :  0.5079924242424243\n",
      "The accuracy score for Logistic Regression with solver =  0.1  and kernel =  saga  is :  0.7833333333333333\n",
      "The f1 score for Logistic Regression with solver =  0.1  and kernel =  saga  is :  0.7131899641577061\n",
      "\n",
      "The best accuracy score using Logistic Regression is  0.7833333333333333\n",
      "The best f1 score using Logistic Regression is  0.7421320346320345\n"
     ]
    }
   ],
   "source": [
    "g = 0\n",
    "ascore_lr = np.zeros(15)\n",
    "fscore_lr = np.zeros(15)\n",
    "c_param_range=[0.001,0.01,0.1]\n",
    "lr_solvers=['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "for i in lr_solvers:\n",
    "    for f in c_param_range:\n",
    "        LR = LogisticRegression(C=f, solver=i).fit(X_train,y_train)\n",
    "        yhat_LR = LR.predict(X_test)\n",
    "        ascore_lr[g] = accuracy_score(y_test, yhat_LR)\n",
    "        fscore_lr[g] = f1_score(y_test, yhat_LR, average='weighted')\n",
    "        print(\"The accuracy score for Logistic Regression with solver = \", f, \" and kernel = \", i,\" is : \", accuracy_score(y_test, yhat_LR))\n",
    "        print(\"The f1 score for Logistic Regression with solver = \", f, \" and kernel = \", i,\" is : \", f1_score(y_test, yhat_LR, average='weighted'))\n",
    "        g += 1\n",
    "print(\"\\nThe best accuracy score using Logistic Regression is \",ascore_lr.max())\n",
    "print(\"The best f1 score using Logistic Regression is \",fscore_lr.max())              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for solver =  liblinear  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       drugA       1.00      1.00      1.00         7\n",
      "       drugB       0.60      1.00      0.75         3\n",
      "       drugC       0.00      0.00      0.00         8\n",
      "       drugX       0.55      0.92      0.69        13\n",
      "       drugY       0.96      0.86      0.91        29\n",
      "\n",
      "    accuracy                           0.78        60\n",
      "   macro avg       0.62      0.76      0.67        60\n",
      "weighted avg       0.73      0.78      0.74        60\n",
      "\n",
      "Classification report for solver =  newton-cg  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.00      0.00      0.00         7\n",
      "       drugB       0.00      0.00      0.00         3\n",
      "       drugC       0.00      0.00      0.00         8\n",
      "       drugX       0.89      0.62      0.73        13\n",
      "       drugY       0.57      1.00      0.72        29\n",
      "\n",
      "    accuracy                           0.62        60\n",
      "   macro avg       0.29      0.32      0.29        60\n",
      "weighted avg       0.47      0.62      0.51        60\n",
      "\n",
      "Classification report for solver =  lbfgs  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.00      0.00      0.00         7\n",
      "       drugB       0.00      0.00      0.00         3\n",
      "       drugC       0.00      0.00      0.00         8\n",
      "       drugX       0.89      0.62      0.73        13\n",
      "       drugY       0.57      1.00      0.72        29\n",
      "\n",
      "    accuracy                           0.62        60\n",
      "   macro avg       0.29      0.32      0.29        60\n",
      "weighted avg       0.47      0.62      0.51        60\n",
      "\n",
      "Classification report for solver =  sag  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.00      0.00      0.00         7\n",
      "       drugB       0.00      0.00      0.00         3\n",
      "       drugC       0.00      0.00      0.00         8\n",
      "       drugX       0.89      0.62      0.73        13\n",
      "       drugY       0.57      1.00      0.72        29\n",
      "\n",
      "    accuracy                           0.62        60\n",
      "   macro avg       0.29      0.32      0.29        60\n",
      "weighted avg       0.47      0.62      0.51        60\n",
      "\n",
      "Classification report for solver =  sag  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.00      0.00      0.00         7\n",
      "       drugB       0.00      0.00      0.00         3\n",
      "       drugC       0.00      0.00      0.00         8\n",
      "       drugX       0.89      0.62      0.73        13\n",
      "       drugY       0.57      1.00      0.72        29\n",
      "\n",
      "    accuracy                           0.62        60\n",
      "   macro avg       0.29      0.32      0.29        60\n",
      "weighted avg       0.47      0.62      0.51        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "k = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'sag']\n",
    "for i in k:\n",
    "    LR = LogisticRegression(C=0.01, solver=i).fit(X_train,y_train)\n",
    "    yhat_LR = LR.predict(X_test)\n",
    "    print(\"Classification report for solver = \",i,\" \\n\\n\",classification_report(y_test, yhat_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for Naive Bayes is :  0.85\n",
      "The f1 score for Naive Bayes is:  0.8565713088654265\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred_NB = gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"The accuracy score for Naive Bayes is : \", accuracy_score(y_test, y_pred_NB))\n",
    "print(\"The f1 score for Naive Bayes is: \", f1_score(y_test, y_pred_NB, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report of Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.70      1.00      0.82         7\n",
      "       drugB       0.40      0.67      0.50         3\n",
      "       drugC       0.80      1.00      0.89         8\n",
      "       drugX       1.00      0.92      0.96        13\n",
      "       drugY       0.96      0.76      0.85        29\n",
      "\n",
      "    accuracy                           0.85        60\n",
      "   macro avg       0.77      0.87      0.80        60\n",
      "weighted avg       0.89      0.85      0.86        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_NB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for Random Forest with criterion =  entropy  is  0.9666666666666667\n",
      "The f1 score for Random Forest with criterion =  entropy  is  0.9653634651600753\n",
      "The accuracy score for Random Forest with criterion =  gini  is  0.9666666666666667\n",
      "The f1 score for Random Forest with criterion =  gini  is  0.9653634651600753\n",
      "\n",
      "The best accuracy score using Random Forest is  0.9666666666666667\n",
      "The best f1 score using Random Forest is  0.9653634651600753\n"
     ]
    }
   ],
   "source": [
    "f=0\n",
    "ascore_rf = np.zeros(2)\n",
    "fscore_rf = np.zeros(2)\n",
    "rf_criterion=['entropy', 'gini']\n",
    "for i in rf_criterion:\n",
    "    clf=RandomForestClassifier(criterion=i)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred_RF=clf.predict(X_test)\n",
    "    ascore_rf[f] = accuracy_score(y_test, y_pred_RF)\n",
    "    fscore_rf[f] = f1_score(y_test, y_pred_RF, average='weighted')\n",
    "    print(\"The accuracy score for Random Forest with criterion = \",i,\" is \", accuracy_score(y_test, y_pred_RF))\n",
    "    print(\"The f1 score for Random Forest with criterion = \",i,\" is \", f1_score(y_test, y_pred_RF, average='weighted'))\n",
    "    f += 1\n",
    "    \n",
    "print(\"\\nThe best accuracy score using Random Forest is \",ascore_rf.max())\n",
    "print(\"The best f1 score using Random Forest is \",fscore_rf.max())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report of Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for criterion =  entropy  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.88      1.00      0.93         7\n",
      "       drugB       1.00      0.67      0.80         3\n",
      "       drugC       1.00      1.00      1.00         8\n",
      "       drugX       1.00      0.92      0.96        13\n",
      "       drugY       0.97      1.00      0.98        29\n",
      "\n",
      "    accuracy                           0.97        60\n",
      "   macro avg       0.97      0.92      0.94        60\n",
      "weighted avg       0.97      0.97      0.97        60\n",
      "\n",
      "Classification report for criterion =  gini  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.88      1.00      0.93         7\n",
      "       drugB       1.00      0.67      0.80         3\n",
      "       drugC       1.00      1.00      1.00         8\n",
      "       drugX       1.00      0.92      0.96        13\n",
      "       drugY       0.97      1.00      0.98        29\n",
      "\n",
      "    accuracy                           0.97        60\n",
      "   macro avg       0.97      0.92      0.94        60\n",
      "weighted avg       0.97      0.97      0.97        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = ['entropy', 'gini']\n",
    "for i in k:\n",
    "    clf=RandomForestClassifier(criterion=i)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred_RF=clf.predict(X_test)\n",
    "    print(\"Classification report for criterion = \",i,\" \\n\\n\",classification_report(y_test, y_pred_RF))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report on accuracy of different algorithms using F1 score and Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# js = jaccard score.......fs = F1-Score\n",
    "# KNN\n",
    "knnas = accuracy_scor.max()\n",
    "knnfs = f1_scor.max()\n",
    "# DTree with max accuracy\n",
    "dtreeas = ascore_dtree.max()\n",
    "dtreefs = fscore_dtree.max()\n",
    "\n",
    "# SVM with max accuracy\n",
    "svmas = ascore_svm.max()\n",
    "svmfs = fscore_svm.max()\n",
    "\n",
    "# Logistic regression with max accuracy\n",
    "lras = ascore_lr.max()\n",
    "lrfs = fscore_lr.max()\n",
    "\n",
    "# Naive Bayes\n",
    "nbas = accuracy_score(y_test, y_pred_NB)\n",
    "nbfs = f1_score(y_test, y_pred_NB, average='weighted')\n",
    "\n",
    "# Random Forest\n",
    "rfas = ascore_rf.max()\n",
    "rffs = fscore_rf.max()\n",
    "\n",
    "#max of all\n",
    "max_as = [knnas,dtreeas,svmas,lras,nbas,rfas]\n",
    "max_fs = [knnfs,dtreefs,svmfs,lrfs,nbfs,rffs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy_Score</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-Nearest Neighor</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.884496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.965363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.936466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.742132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.856571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.965363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Algorithm  Accuracy_Score  F1-Score\n",
       "1       K-Nearest Neighor        0.883333  0.884496\n",
       "2           Decision tree        0.966667  0.965363\n",
       "3  Support Vector Machine        0.933333  0.936466\n",
       "4     Logistic regression        0.783333  0.742132\n",
       "5             Naive Bayes        0.850000  0.856571\n",
       "6           Random Forest        0.966667  0.965363"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Algorithm':['K-Nearest Neighor', 'Decision tree', 'Support Vector Machine', 'Logistic regression', 'Naive Bayes', 'Random Forest'], \n",
    "        'Accuracy_Score':max_as, 'F1-Score':max_fs}\n",
    "s = pd.DataFrame(data, index = [1,2,3,4,5,6])\n",
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
