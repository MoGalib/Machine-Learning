{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<h1 align=\"center\"><font size=\"5\">Predicting Iris flower Class</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data From CSV File  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal length in cm</th>\n",
       "      <th>Sepal width in cm</th>\n",
       "      <th>Petal length in cm</th>\n",
       "      <th>Petal width in cm</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sepal length in cm  Sepal width in cm  Petal length in cm  \\\n",
       "0                  5.1                3.5                 1.4   \n",
       "1                  4.9                3.0                 1.4   \n",
       "2                  4.7                3.2                 1.3   \n",
       "3                  4.6                3.1                 1.5   \n",
       "4                  5.0                3.6                 1.4   \n",
       "..                 ...                ...                 ...   \n",
       "95                 5.7                3.0                 4.2   \n",
       "96                 5.7                2.9                 4.2   \n",
       "97                 6.2                2.9                 4.3   \n",
       "98                 5.1                2.5                 3.0   \n",
       "99                 5.7                2.8                 4.1   \n",
       "\n",
       "    Petal width in cm            Class  \n",
       "0                 0.2      Iris-setosa  \n",
       "1                 0.2      Iris-setosa  \n",
       "2                 0.2      Iris-setosa  \n",
       "3                 0.2      Iris-setosa  \n",
       "4                 0.2      Iris-setosa  \n",
       "..                ...              ...  \n",
       "95                1.2  Iris-versicolor  \n",
       "96                1.3  Iris-versicolor  \n",
       "97                1.3  Iris-versicolor  \n",
       "98                1.1  Iris-versicolor  \n",
       "99                1.3  Iris-versicolor  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('E:\\Datasets\\Iris dataset.csv')   \n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal length in cm</th>\n",
       "      <th>Sepal width in cm</th>\n",
       "      <th>Petal length in cm</th>\n",
       "      <th>Petal width in cm</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sepal length in cm  Sepal width in cm  Petal length in cm  \\\n",
       "0                 False              False               False   \n",
       "1                 False              False               False   \n",
       "2                 False              False               False   \n",
       "3                 False              False               False   \n",
       "4                 False              False               False   \n",
       "..                  ...                ...                 ...   \n",
       "145               False              False               False   \n",
       "146               False              False               False   \n",
       "147               False              False               False   \n",
       "148               False              False               False   \n",
       "149               False              False               False   \n",
       "\n",
       "     Petal width in cm  Class  \n",
       "0                False  False  \n",
       "1                False  False  \n",
       "2                False  False  \n",
       "3                False  False  \n",
       "4                False  False  \n",
       "..                 ...    ...  \n",
       "145              False  False  \n",
       "146              False  False  \n",
       "147              False  False  \n",
       "148              False  False  \n",
       "149              False  False  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal length in cm</th>\n",
       "      <th>Sepal width in cm</th>\n",
       "      <th>Petal length in cm</th>\n",
       "      <th>Petal width in cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sepal length in cm  Sepal width in cm  Petal length in cm  \\\n",
       "count          150.000000         150.000000          150.000000   \n",
       "mean             5.843333           3.054000            3.758667   \n",
       "std              0.828066           0.433594            1.764420   \n",
       "min              4.300000           2.000000            1.000000   \n",
       "25%              5.100000           2.800000            1.600000   \n",
       "50%              5.800000           3.000000            4.350000   \n",
       "75%              6.400000           3.300000            5.100000   \n",
       "max              7.900000           4.400000            6.900000   \n",
       "\n",
       "       Petal width in cm  \n",
       "count         150.000000  \n",
       "mean            1.198667  \n",
       "std             0.763161  \n",
       "min             0.100000  \n",
       "25%             0.300000  \n",
       "50%             1.300000  \n",
       "75%             1.800000  \n",
       "max             2.500000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'scatter')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de3wU5b348c+XEEgUEIqxIlFCD0VQ7pcIYr0CrUq1PWDF4w2KL2ttsB5rS21P1WNP26O9aL30omK1XoIWrNL+vKBV6hFRSJCbBBFrKAGFGCQFDJeQ7++PmYRN2GRms7Ozs9nv21dem31m5tnvPsR9dmae5/uIqmKMMSZ7dUp3AMYYY9LLOgJjjMly1hEYY0yWs47AGGOynHUExhiT5awjMMaYLGcdgTHGZDnrCIwJiIjcKiKPtShbLCJXpSsmY/ywjsCYCBORnHTHYDo+6whMVhOROSKyRUR2ici7InKOiOSIyA9E5H23vFxEjnf3/7WIbBaRf7nlX3DLvwT8ALhYRHaLyCoR+QnwBeBet+xed99BIvKSiOxwX/NrMfE8LCK/FZHnRGQPcFbojWKyTud0B2BMuojIiUAJMFZVt4pIEZAD3ABcApwHbACGAZ+6hy0HbgNqgW8DfxKRIlV9QUR+CgxQ1ctiXmMC8JiqPug+PxJ4CbgZONete5GIvKOq77iH/Yf72lOALil6+8Y0sTMCk80OAl2Bk0QkV1UrVfV94Crgv1T1XXWsUtUaAFV9TFVrVLVeVX/pHn9iAq85BahU1T+4dawAFgDTYvZ5VlWXqGqDqu4N5J0a0wbrCEzWUtWNwPXArcB2EZknIscBxwPvxztGRL4jIhUiUisiO4GjgKMTeNl+wCkisrPxB7gUODZmn83teDvGtJt1BCarqeoTqnoazge0ArfjfBD/W8t93fsBc4CvAb1UtSfOJSJprC7eS7R4vhn4u6r2jPnppqrfbOMYY1LKOgKTtUTkRBE5W0S6AnuBOpzLRQ8CPxaRz4tjmIj0BroD9UA10FlEbgZ6xFS5DSgSkU4tyj4X8/yvwEARuVxEct2fsSIyOHXv1Ji2WUdgsllX4H+Bj4GPgGNwRv78CngKWAT8C5gL5AMvAs/j3EDehNN5xF7G+ZP7WCMiK9zffw1ME5FPRORuVd0FTAamA1vd173djcWYtBBbmMYYY7KbnREYY0yWs47AGGOynHUExhiT5awjMMaYLJfyFBNu0qwyYIuqTmmxbQbwc2CLW3Rv41T81hx99NFaVFSUgkiNMabjKi8v/1hVC+JtCyPX0LeBCpqPt471pKqW+K2sqKiIsrKyQAIzxphsISKbWtuW0ktDIlIInI8zQccYY0wEpfoewV3A94CGNvaZKiKrRWR+Y6rflkTkahEpE5Gy6urqlARqjDHZKmUdgYhMAbarankbu/0FKFLVYcDLwCPxdlLV+1V1jKqOKSiIe4nLGGNMO6XyHsEE4AIROQ/IA3qIyGOxudobU/u6HsCZam+MySIHDhygqqqKvXst43YQ8vLyKCwsJDc31/cxKesIVPUm4CYAETkTuDG2E3DL+6jqh+7TC3BuKhtjskhVVRXdu3enqKgIEfE+wLRKVampqaGqqor+/fv7Pi70eQQicpuIXOA+vU5E3hGRVcB1wIyw4zHGpNfevXvp3bu3dQIBEBF69+6d8NlVKEtVqupiYLH7+80x5U1nDca0S3U1VFZCURHY/aOMZZ1AcNrTljaz2GSu0lLo1w8mTXIeS0vTHZExGck6ApOZqqth1iyoq4PaWudx1iyn3JgUevjhh9m6dWu6wwiUdQQmM1VWQpcuzctyc51yY1LIOgJjoqKoCPbvb1524IBTbjq+6mpYvjywM8A9e/Zw/vnnM3z4cIYMGcKTTz5JeXk5Z5xxBqNHj+aLX/wiH374IfPnz6esrIxLL72UESNGUFdXx9/+9jdGjhzJ0KFD+frXv86+ffsA+P73v89JJ53EsGHDuPHGGwH4y1/+wimnnMLIkSOZOHEi27ZtCyT+pKlqRv2MHj1ajVFV1SeeUM3PV+3Rw3l84ol0R2TaYd26dYkd0PjvftRRgf27z58/X6+66qqm5zt37tTx48fr9u3bVVV13rx5OnPmTFVVPeOMM3T58uWqqlpXV6eFhYX67rvvqqrq5ZdfrnfeeafW1NTowIEDtaGhQVVVP/nkE1VV3bFjR1PZAw88oDfccEPSsccTr02BMm3lczWUUUPGpMQll8DEiTZqKJvE3huqq3PKZs1y/g6S+PcfOnQoN954I3PmzGHKlCn06tWLtWvXMmnSJAAOHjxInz59Djvu3XffpX///gwcOBCAK6+8kvvuu4+SkhLy8vK46qqrOP/885kyxUm8XFVVxcUXX8yHH37I/v37Exrrn0p2achktoICGDvWOoFskaJ7QwMHDqS8vJyhQ4dy0003sWDBAk4++WRWrlzJypUrWbNmDYsWLTrsOG1lzffOnTuzbNkypk6dyjPPPMOXvvQlAGbPnk1JSQlr1qzh97//fWRmU1tHYIzJHCm6N7R161aOOOIILrvsMm688UbeeustqqurWbp0qfsSB3jnnXcA6N69O7t27QJg0KBBVFZWsnHjRgAeffRRzjjjDHbv3k1tbS3nnXced911FytXrgSgtraWvn37AvDII3FTq6WFXRoyxmSOggKYO9e5HJSb63QCc+cmfUa4Zs0avvvd79KpUydyc3P57W9/S+fOnbnuuuuora2lvr6e66+/npNPPpkZM2ZwzTXXkJ+fz9KlS/nDH/7ARRddRH19PWPHjuWaa65hx44dXHjhhezduxdV5c477wTg1ltv5aKLLqJv376MGzeODz74IIhWSZq0dmoTVWPGjFFbmMaYjqOiooLBgwcndpDNKG9TvDYVkXJVHRNvfzsjMMZknoIC6wACZPcIjDEmy1lHYIwxWc46AmOMyXLWERhjTJazjsCkV8A5Y4wxibOOwKSPrSdgOrCbb76Zl19+OeHjFi9e3JSSIiw2fNSkR4pyxhgTpsakbZ06Hf6d+rbbbgslhvr6ejp3Tu6j3M4ITHrYegImCdV7qlm+ZTnVe4K5pDhnzhx+85vfND2/9dZb+eUvf8nPf/5zxo4dy7Bhw7jlllsAqKysZPDgwVx77bWMGjWKzZs3M2PGDIYMGcLQoUObZhHPmDGD+fPnA7B8+XJOPfVUhg8fTnFxMbt27WLv3r3MnDmToUOHMnLkSF599dXD4tqxYwdf+cpXGDZsGOPGjWP16tVN8V199dVMnjyZK664Iun3bx2BSQ9bT8C0U+maUvrd1Y9Jj06i3139KF2b/CXF6dOn8+STTzY9f+qppygoKOC9995j2bJlrFy5kvLycl577TXAyTp6xRVX8Pbbb/Pxxx+zZcsW1q5dy5o1a5g5c2azuvfv38/FF1/Mr3/9a1atWsXLL79Mfn4+9913H+CktygtLeXKK688LAndLbfcwsiRI1m9ejU//elPm33ol5eX8+yzz/LEE08k/f6tIzDp0ZgzJj8fevRwHgPIGWM6tuo91cxaOIu6+jpq99VSV1/HrGdnJX1mMHLkSLZv387WrVtZtWoVvXr1YvXq1SxatIiRI0cyatQo1q9fz3vvvQdAv379GDduHACf+9zn+Mc//sHs2bN54YUX6NGjR7O63333Xfr06cPYsWMB6NGjB507d+b111/n8ssvB5zkdf369WPDhg3Njo3d5+yzz6ampoba2loALrjgAvLz85N6343sHoFJH1tPwCSocmclXXK6UFdf11SWm5NL5c5KCo5M7u9n2rRpzJ8/n48++ojp06dTWVnJTTfdxDe+8Y3mMVRWcuSRRzY979WrF6tWreLFF1/kvvvu46mnnuKhhx5q2q6qiMhhr+cnz1u8fRrrio0hWXZGYNLL1hMwCSjqWcT+g80vKR44eICinkVJ1z19+nTmzZvH/PnzmTZtGl/84hd56KGH2L17NwBbtmxh+/bthx338ccf09DQwNSpU/nxj3/MihUrmm0fNGgQW7duZfny5QDs2rWL+vp6Tj/9dB5//HEANmzYwD//+U9OPPHEZsfG7rN48WKOPvrow844gmBnBKZ1luHRREzBkQXMvXAus56dRW5OLgcOHmDuhXOTPhsAOPnkk9m1axd9+/alT58+9OnTh4qKCsaPHw9At27deOyxx8jJyWl23JYtW5g5cyYNDQ0A/OxnP2u2vUuXLjz55JPMnj2buro68vPzefnll7n22mu55pprGDp0KJ07d+bhhx+ma9euzY699dZbmTlzJsOGDeOII45I2RoGlobaxFda6gzn7NLFuak7d65zKceYgLUnDXX1nmoqd1ZS1LMokE6go7E01CZ5NsbfRFzBkQXWAQTI7hGYw9kYf2OyinUE5nA2xt+YrGIdgTmcjfE3JqvYPQITn43xNyZrWEdgWmfrwhqTFVJ+aUhEckTkbRH5a5xtXUXkSRHZKCJviUhRquMxxhg/tm7dyrRp0xI+7qqrrmLdunVt7vO73/2OP/7xj+0NLXBhnBF8G6gA4k2HmwV8oqoDRGQ6cDtwcQgxmWxiE+NMOxx33HFN2UNjeaV9fvDBBz3rvuaaa5KKLWgpPSMQkULgfKC1lrkQaJwqNx84R+Il5TCmvWzxmw6pZvc+Vm3eSc3ufYHU11oa6iFDhgDw8MMPc9FFF/HlL3+ZyZMn09DQwLXXXsvJJ5/MlClTOO+885o6jTPPPJPGSa/dunXjhz/8IcOHD2fcuHFs27atqf5f/OIXAGzcuJGJEycyfPhwRo0axfvvv8/u3bs555xzGDVqFEOHDuXZZ58N5H22JtWXhu4Cvgc0tLK9L7AZQFXrgVqgd4pjMtkidmJcba3zOGuWLYuZ4Z5duYUJt7/CZQ++xYTbX2Hhyi1J1xkvDXVjttBGS5cu5ZFHHuGVV17h6aefprKykjVr1vDggw+ydOnSuPXu2bOHcePGsWrVKk4//XQeeOCBw/a59NJL+da3vsWqVat444036NOnD3l5efz5z39mxYoVvPrqq3znO9/xlaSuvVLWEYjIFGC7qpa3tVucssPerYhcLSJlIlJWbf8TG79sYlyHU7N7H3MWrGbvgQZ27atn74EGvrdgddJnBvHSUJ9wwgnN9pk0aRKf+cxnACc99EUXXUSnTp049thjOeuss+LW26VLl6ZlJ0ePHk1li7+9Xbt2sWXLFr761a8CkJeXxxFHHIGq8oMf/IBhw4YxceJEtmzZ0nQ2kQqpvEcwAbhARM4D8oAeIvKYql4Ws08VcDxQJSKdgaOAHS0rUtX7gfvByTWUwphNR2IT4zqcqk/qyO3Uib0xFxlyO3Wi6pM6enfr2saR3lqmoW4pNu2z32/nubm5TWmjc3JyqK+vb7a9tXoef/xxqqurKS8vJzc3l6KiosMWrQlSys4IVPUmVS1U1SJgOvBKi04AYCFwpfv7NHcf+6A3wbCJcR1OYa98DjQ0v9J8oKGBwl7JL9DSMg11W0477TQWLFhAQ0MD27ZtY/Hixe16zR49elBYWMgzzzwDwL59+/j000+pra3lmGOOITc3l1dffZVNmza1q36/Qp9ZLCK3icgF7tO5QG8R2QjcAHw/7HhMB3fJJbBpE7z8svNoGVQzWu9uXblj6jDycjvRvWtn8nI7ccfUYUmfDcDhaajbMnXqVAoLCxkyZAjf+MY3OOWUUzjqqKPa9bqPPvood999N8OGDePUU0/lo48+4tJLL6WsrIwxY8bw+OOPM2jQoHbV7ZeloTbGpFV70lDX7N5H1Sd1FPbKD6QTaI/du3fTrVs3ampqKC4uZsmSJRx77LFpiaUlS0NtoqOiApYtg+JiSPB/dGPa0rtb17R1AI2mTJnCzp072b9/Pz/60Y8i0wm0h3UEJjVmz4Z77z30vKQE7rknffEYE7D23heIIss+aoJXUdG8EwDneUVFeuIxkZdpl6ijrD1taR2BCd6yZYmVm6yWl5dHTU2NdQYBUFVqamrIy8tL6Di7NGSCV1ycWLnJaoWFhVRVVWGTRYORl5dHYWFhQsdYR2CCN3iwc0+g5T0Cu2Fs4sjNzaV///7pDiOrWUdgUuOee+Daa23UkDEZwDoCkzqDB1sHYEwGsJvF2WrJErjlFucxk1VXw/LlllHURFIQ6bKDTrkdj50RZKPJk+Gll5zfb7vNef7ii+mNqT1KS5200l26OMnl5s61FBImMp5duYU5C1aT26kTBxoauGPqMC4Y0Tf0OvywM4Jss2TJoU6g0aJFmXdmYGsNmAgLIl12qlJux2MdQbZZtCix8qiytQZMhDWmy47VmC47zDr8so4g20yenFh5VNlaAybCgkiXncqU2y1ZR5BtJkw4/EN/8mSnPJPYWgMmwoJIl53KlNstWRrqbLVkiXM5KBM7gVjV1c7loKIi6wRM5ASRLjuolNttpaG2jsAYY7JAWx2BXRrKVkGMv/eqw8b4G5MRfHUEItJLRIaJyKjGn1QHZlKotBT69YNJk5zH0tLg6wjiNYwxofC8NCQiPwZmAO8DjTurqp6d2tDis0tDSaqudj6Y62KGoOXnO+v5+r3G7lVHEK9hjAlUsktVfg34N1Xd77mnib7G8fexH9KN4+/9fkh71RHEaxhjQuPn0tBaoGeqAzEhCWL8vVcdNsbfmIzipyP4GfC2iLwoIgsbf1IdmEmRIMbfe9VhY/yNySh+7hG8A/weWAM0TXNT1b+nNrT47B5BQIIYf+9Vh43xNyYykr1H8LGq3h1wTCbdCgqS/3D2qiOI1zDGpJyfjqBcRH4GLASa0t6p6oqURZXJovItOCpxGJMCQc22NQ4/HcFI93FcTJkCaRk+GmlRyY8flTiMSYGwcvRnE0sxEZSojJ2PShzGpEDN7n1MuP0V9h44lJUzL7cTS+acbWcGHpJKMSEiPxWRnjHPe4nI/wQZYIcQlfz4UYnDmBQIM0d/NvEzfPRcVd3Z+ERVPwHOS11IGSoqY+ejEocxKRBmjv5s4qcjyBGRpnMuEckH7ByspaiMnY9KHMakQJg5+rOJn3kE3wMuAP6Ac5P468BCVb0j9eEdLrL3CBpFZbROVOIwJgVs1FDikppHoKp3iMhqYCIgwI9V9cWAY+w4ojJ2PipxGJMCvbt1tQ4gQH6Gj6KqLwAvJFKxiOQBr+FcRuoMzFfVW1rsMwP4ObDFLbpXVR9M5HVMKyoqYNkyKC6GwYMT3w7hnFXYmYsxaZfKhWn2AWer6nBgBPAlERkXZ78nVXWE+2OdQBBmz4aTToIZM5zH2bMT2w7hrCdgaxYYEwmhzCMQkSOA14FvqupbMeUzgDGqWuK3rsjfI0i3igrnw72ldeucb/5e2yGcuQg238GYUKVtqUoRyRGRlcB24KXYTiDGVBFZLSLzReT4Vuq5WkTKRKSs2pY9bNuyZW2Xe22HcOYi2HwHYyLDz4SyCSLykohsEJF/iMgHIvIPP5Wr6kFVHQEUAsUiMqTFLn8BilR1GPAy8Egr9dyvqmNUdUyBfVtsW3Fx2+Ve2yGcuQg238GYyPBzRjAX+BVwGjAWGOM++uZOSFsMfKlFeY2qNiayewAYnUi9Jo7Bg6GkxZW2kpJDl328tkM4cxFsvoMxkeFnHsFbqnpKwhWLFAAHVHWnOwltEXC7qv41Zp8+qvqh+/tXgTmqGu+GchO7R+CTjRoyxsRIdj2CV0Xk58DTJJaGug/wiIjk4Jx5PKWqfxWR24AyVV0IXCciFwD1wA5gho94jB+DB7f+Ae9nO4QzF8HmOxiTdn7OCF6NU6yqmpY01JE/IwjiG66fb+vJ1uEnzmTfSxDvIyKq91RTubOSop5FFByZeFv4mQlrs2VNKrV1RoCqZtTP6NGjNbKeeEI1P1/1qKOcxyeeSLyOkhJVOPRTUhJ8HX7iTPa9BPE+IuKJ1U9o/v/k61E/O0rz/ydfn1iTWFs883aVnvhfz+mQm1/QE//rOX327ap27WNMMnCuxMT9XG31jEBELlPVx0TkhlY6kF8F1lUlILJnBEGMi/czxj/ZOvzEmex7CeJ9RET1nmr63dWPuvpDbZHfOZ9N12/ydWbgJ3++5dg3YWjvPIIj3cfurfyYWEGMi/czxj/ZOvzEmex7CeJ9RETlzkq65DRvi9ycXCp3Vvo63k/+fMuxb9Kt1ZvFqvp79/G/wwsngwUxLt7PGP9k6/ATZ7LvJYj3ERFFPYvYf7B5Wxw4eICinkW+jveTP99y7Jt0S+nM4qwSxLh4P2P8k63DT5zJvpcg3kdEFBxZwNwL55LfOZ8eXXuQ3zmfuRfO9X3D2E/+fMuxb9LN1iwOmo0a8h9DBrFRQybTtXWPwDoCY4zJAklNKHOXqZwKFMXur6q3BRWgSQGvb/M2ozdyNmzfSnlVJaMLixh4zHFpiWHjtl2s3LyTEcf3ZMBnbUxItvAzs/hZoBYoJ2ZmsYmw0lKYNcsZ+bN/v3N9/5JL/G83oZuz8E/MeyMHOAh8xPQJB7n9yxeFGsPNz6zhj2/+s+n5FeNP4LYLh4Yag0kPPzOL16pqy6yhaWOXhjx4zQGwdQAiZ8P2rUz61ZsIh+4LKPt46YZxoZ0ZbNy2i4l3vnZY+cv/ebqdGXQQya5H8IaI2NeCTOE1B8DWAYic8qpKnDOBQ5SDbnk4Vm7emVC56VhavTQkImsAdfeZ6a5BsA9nAXtVZw0BEzVecwBsHYDIGV1YBHzUrEzIccvDMeL4ngmVm46lrTOCKcCXgXOBAcBk93ljuYkirzkAtg5A5Aw85jimTziIso8GPkXZx/QJB0O9YTzgs925YvwJzcquGH+CXRbKEn7uETyqqpd7lYXF7hH4ZKOGMo6NGjKplOx6BCe3qCwHW0ks+rzy/Ns6AJEz8Jjj0tYBNBrw2e7WAWShVi8NichNIrILGCYi/3J/duEsRP9saBEaY4xJqVY7AlX9map2B36uqj3cn+6q2ltVbwoxxvBUV8Py5c5jKuuoqIBHHnEeUyWI95IlqvdUs3zLcqr3RLutNmzfSumKN9iwfWur+9Ts3seqzTup2Z26KT9er+EnhmTbPIz3mU3aGjU0yv31TzG/N1HvpSozSxCTrPzUMXs23HvvoeclJXDPPcnHn2gcBoDSNaXMWjiLLjld2H9wP3MvnMslQ6LXVn4mnD27cgtzFqwmt1MnDjQ0cMfUYVwwom+gcXi9hp8Ykm3zMN5ntmlrYZrGJSrzgDHAKpyho8OAt1T1tFAibCElN4uDmGTlp44wFmyxCWO+JbvoTFj8TDgLY3Ebr9fwE0MYC/2Y+No1oUxVz1LVs4BNwChVHaOqo4GRwMbUhJomQUyy8lNHGAu22IQx35JddCYsfiachbG4jddr+IkhjIV+TOL8zCwepKprGp+o6lpgROpCSoMgJln5qSOMBVtswphvyS46ExZnYllOs7KWE87CWNzG6zX8xBDGQj8mcX46ggoReVBEzhSRM0TkASCFdznTIIhJVn7qCGPBFpsw5luyi86Exc+EszAWt/F6DT8xhLHQj0mcnwllecA3gdPdoteA36rq3hTHFldKJ5QFMcnKTx1hLNhiE8Z8S3bRmbD4mXAWxuI2Xq/hJ4YwFvoxzdnCNMYYk+XadbNYRJ5yH9eIyOqWP6kKNuOFMRdhyRK45Rbn0WSNMMbOL920lp/+7XGWblrb7jqWVW7ijpdfY1nlpgAjM6nU1vDRPqr6oYj0i7ddVdPyrxzpM4Iw5iJMngwvvdT8+YsvBhO/iawwxs7/+8M/oWz9IJwRSjmMGbSep2f8MKE6ps99mqXvHRoVNH7gfuZ9/d8DjdO0T3uHj37o/noO0EVVN8X+pCLQjFZd7XyA19VBba3zOGtWYmcGXnUsWdK8EwBYtMjODDq4mt37mLNgNXsPNLBrXz17DzTwvQWrAz0zWLppLWXrB9GJPDpxJJ3Io2z9oITODJZVbmLpe12QmP+WbuhiZwYZwM+ooSLg9yLyvog8JSKzRaRjDR8NQhhzERYtin9ca+WmQwhj7PyrG1fRcq4CHHTL/Vm8Mf4HfmvlJjo8OwJVvVlVzwaGAK8D38VZv9jECmMuwuTJ8Y9rrdx0CGGMnT9rwHBazlWAHLfcnzMHxL2K3Gq5iQ7PjkBE/ktEngcW4SxQcyNQmOrAMk4YcxEmTDj8Q3/yZKfcdFhhjJ0f328IYwatp4G9NLCHBvYyZtB6xvfzv1x5cVE/xg/cj8b8N37gfoqLrCOIOj/zCFYA9cD/A/4OvJmuOQQQ8ZvFEM5chCVLnMtB1glklTDGzi/dtJZXN67irAHDE+oEYi2r3MTijZs4c0A/6wQiJOl5BCLSHTjN/fkasK1DJZ0zxpgOrl2jhmIOHgJcBlwJXAxUAa/4OC5PRJaJyCoReUdE/jvOPl1F5EkR2Sgib4lIkVe9SfEanx+VHP5e6xX4iTMC7yWIPP8V1RU8svIRKqrjt0UQrxFEnn8/dYSh7IMafrXoXco+qIm73au9OtKaB2HIlDi9+Fmq8nacS0J3A8tV9YDPuvcBZ6vqbhHJBV4XkedV9c2YfWYBn6jqABGZ7r7WxQnE75/X+Pyo5PD3Wq/AT5wReC9B5Pmf/dxs7l1+qC1Kiku459xDbRHEawSR599PHWG47ME3eX2j0wHc/cpGvjCgN49eNa5pu1d7daQ1D8KQKXH6EUqKCRE5AmfE0TdV9a2Y8heBW1V1qYh0Bj4CCrSNoNp1acgrR39Ucvh7rVfgJ84IvJcg8vxXVFdw0m8Ob4t1165jcMHgQF4jiDz/fuoIQ9kHNUz7/ZuHlc//xjjG9O/t2V4dac2DMGRKnLGSujSU5AvniMhKnHWOX4rtBFx9gc0AqloP1AK949RztYiUiUhZdXsudXiNz49KDn+v9Qr8xBmB9xJEnv9lW+K3RWN5EK8RRJ5/P3WE4bX3Pm6z3Ku9OtKaB2HIlDj9SmlHoKoHVXUEznDTYvd+QyyJd1iceu53F8YZU9Ceb7Ve4/OjksPfa70CP3FG4L0Ekee/uG/8tmgsD+I1gsjz76eOMJz++aPbLPdqr4605kEYMiVOv1LaETRS1Z3AYuBLLTZVAccDuJeGjgJ2BB6A1/j8qOTw91qvwE+cEXgvQeT5H1wwmJLi5m1RUlzC4ILBgb1GEJLlEx8AABU5SURBVHn+/dQRhjH9e/OFAc1Ppr8woDdj+jtlXu3VkdY8CEOmxOlXW0nn/kKcb+eNVPWCNisWKQAOqOpOEcnHmZB2u6r+NWafbwFDVfUa92bxv6vq19qqN6nho17j86OSw99rvQI/cUbgvQSR57+iuoJlW5ZR3Le4qRMI+jWCyPPvp44wlH1Qw2vvfczpnz+6qROI5dVeHWnNgzBkSpzQznkEInJGW5Wq6t89XnQY8AjO+WYn4ClVvU1EbgPKVHWhu+jNozjrIO8ApqvqP9qq1+YRGGNM4trqCFodPur1Qe9FVVfjfMC3LL855ve9QPjj7FoTgW/Rpjmvb7BhrS6WbBx+4vT69hjEe82U1diCEKVv41HnOY9ARD4P/Aw4CchrLFfVz6UwrvBFYOy9ac5r3HsQ8wjCiMNPnF5jzoN4r2G1VxRk0hj+KPCTa+h14BbgTuDLwEz3uFtSH97hUnJpKAJj701zXuPeg5hHEEYcfuL0GnMexHsNq72iIIpj+KMg2XkE+ar6N5wP/02qeitwdpABpl0Ext6b5rzGvQcxjyCMOPzE6TXmPIj3GlZ7RUGmjeGPAj8pJvaKSCfgPREpAbYAx6Q2rJBFYOy9ac5r3HsQ8wjCiMNPnF5jzoN4r2G1VxRk2hj+KPBzRnA9cARwHTAauBwnAV3HEYGx96Y5r3HvQcwjCCMOP3F6jTkP4r2G1V5RkGlj+KPAd64hEekBqKruSm1IbUvp8FEbNRQ5NmoosTqSfR8diY0aai6p9QhEZAzwB6C7W1QLfF1V07Jcpc0jMMaYxCV7s/gh4FpVLVLVIuBbOB2DMSnnlc/da70CP3UEwSsOPzF47bNx2y7ml21m47bWT8qDWJ/BSxivEYYorKsQFX5uFu9S1f9rfKKqr4tIWi8PmezgNRbca70CP3UEwSsOPzF47XPzM2v445v/bHp+xfgTuO3Coc3qCGOeQEeZixCFdRWixM+loTtxbhaX4uQeuhj4BFgAoKorUhxjM3ZpKDt4jQX3Wq/ATx1B8IrDTwxe+2zctouJd7522Gu8/J+nM+CzzhXbMOYJdJS5CFFYVyEdkr00NAIYiDOp7FZgMHAq8EvgFwHFaEwzXmPBvdYr8FNHELzi8BOD1z4rN++M+xqx5WHME+gocxGisK5C1HheGlLVs8IIxJhYXmPBvdYr8FNHELzi8BOD1z4jju8Z9zViy8OYJ9BR5iJEYV2FqPGzeP1nRWSuiDzvPj9JRGalPjSTzbzGgnutV+CnjiB4xeEnBq99Bny2O1eMP6HZa1wx/oSmy0IQzjyBjjIXIQrrKkSNn3sEz+OMEvqhqg53F5B5W1WHtnlgitg9guziNRbca70CP3UEwSsOPzF47bNx2y5Wbt7JiON7NusEYoUxT6CjzEWIwroKYUp2HsFyVR0rIm+r6ki3bKW7BGXorCMwxpjEJXuzeI+I9MZdrUxExuFMKjMdXBTGiwcRw4vrV3H90/N4cf2qtMbhxWvMeaaMSTeZx888ghuAhcC/icgSoACYltKoTNpFYbx4EDGc+ev7+ODDfkA3/rxsM/37vM7ib38r9Di8eI05z6Qx6Sbz+Mo15N4XOBEQ4F1VPZDqwFpjl4ZSLwrjxYOI4cX1q7j64c0I0lSmKPfPOJ4vDhoeWhxevMacR3FMusk87bo0JCJjReRYAFWtx8k8+hPglyLymZREaiIhCuPFg4jh+XXx0z20Vp6qOLx4jTnPtDHpJvO0dY/g98B+ABE5Hfhf4I849wfuT31oJl2iMF48iBjOPSn+KKLWylMVhxevMeeZNibdZJ62OoIcVd3h/n4xcL+qLlDVHwEDUh+aSZcojBcPIoYvDhpO/z6b0Jj/+vfZ5PuyUFBxePEac55pY9JN5mn1HoGIrAVGqGq9iKwHrlbV1xq3qeqQEONsYvcIwhOF8eJBxPDi+lU8v66Cc08anFAnEHQcXrzGnEdpTLrJPO2aRyAiPwTOAz4GTgBGqaqKyADgEVWdkKqA22IdgTHGJK5dN4tV9SfAd4CHgdP0UI/RCZgddJAmOyU7Pt/P8VGYA2CyU6b8XbQ5j0BV34xTtiF14Zhskuz4fD/HR2EOgMlOmfR34XvN4qiwS0MdQ7Lj8/0cH4U5ACY7RfHvItkUE8YELtnx+X6Oj8IcAJOdMu3vwjoCkxbJjs/3c3wU5gCY7JRpfxfWEZi0SHZ8vp/jozAHwGSnTPu7sHsEJq2SHZ/v5/gozAEw2SlKfxdJrUcQNdYRGGNM4tJys1hEjheRV0WkQkTeEZFvx9nnTBGpFZGV7s/NqYqnIwlibHIU1hrwE4fX9kwZp+3Hhu1bKV3xBhu2b01bDB2pPY1/ftYjaK964DuqukJEugPlIvKSqq5rsd//qeqUFMbRoQQxNjkKaw34icNreyaN0/YyZ+GfmPdGDnAQ+IjpEw5y+5cvCjWGjtSeJjEpOyNQ1Q9VdYX7+y6gArC/qiTU7N7HnAWr2XuggV376tl7oIHvLVid0Le36j3VzFo4i7r6Omr31VJXX8esZ2eFfmbgFYfX9iDaIio2bN/KvDdyELoiHIHQlXlLckI9M+hI7WkSF8qoIREpAkYCb8XZPF5EVonI8yJycivHXy0iZSJSVl2d3ksZ6RTE2OQorDXgJw6v7Zk2Trst5VWVOGcChygH3fJwdKT2NIlLeUcgIt2ABcD1qvqvFptXAP1UdThwD/BMvDpU9X5VHaOqYwoK0pMFMwqCGJschbUG/MThtT3Txmm3ZXRhEZDTrEzIccvD0ZHa0yQupR2BiOTidAKPq+rTLber6r9Udbf7+3NArogcncqYMlkQY5OjsNaAnzi8tmfaOO22DDzmOKZPOIiyjwY+RdnH9AkHGXjMcaHF0JHa0yQuZcNHRUSAR4Adqnp9K/scC2xz01sXA/NxzhBaDcqGjwYzNjkKaw34icNre5TGaSdrw/atlFdVMrqwKNROIFZHak/TXFrmEYjIacD/AWuAxnPOH+CsbYCq/k5ESoBv4owwqgNuUNU32qrXOgJjjElcWx1ByoaPqurrgHjscy9wb6pi6Kii8m0+CBXVFSzbsozivsUMLvC/lrAxJjipnEdgUiAqcwCCMPu52dy7/ND3gJLiEu459540RmRMdrKkcxkkKnMAglBRXdGsEwC4d9m9VFRXpCkiY7KXdQQZJCpzAIKwbMuyhMqNMaljHUEGicocgCAU9y1OqNwYkzrWEWSQqMwBCMLggsGUFJc0KyspLrEbxsakgaWhzkA2asgYk6i0DB81qVNwZEHGdwCNBhcMtg7AmDSzS0PGGJPlrCNIVHU1LF/uPEZYVBae8ZIpcYbB2sKki3UEiSgthX79YNIk57G0NN0RxVW6ppR+d/Vj0qOT6HdXP0rXWpxRZ21h0sluFvtVXe18+NfF5GfPz4dNmyBCqbGr91TT765+1NUfijO/cz6brt8UqfsKmRJnGKwtTBjSsmZxh1NZCV2aT+YiN9cpj5BMmXSWKXGGwdrCpJt1BH4VFcH+5pO5OHDAKY+QTJl0lilxhsHawqSbdQR+FRTA3LnO5aAePZzHuXMjdVkIMmfSWabEGQZrC5Nudo8gUdXVzuWgoqLIdQKxMmXSWabEGQZrC5NKNqEsSAUFke4AGmXKpLNMiTMM1hYmXezSkDE+bNi+ldIVb7Bh+9Z2HW9zBEyU2RmBMR7mLPwT897IAQ4CHzF9wkFu//JFvo/vSIsJmY7JzgiMacOG7VuZ90YOQleEIxC6Mm9Jju8zg460mJDpuKwjMKYN5VWVOGcChygH3XJvNkfAZALrCIxpw+jCIiCnWZmQ45Z7szkCJhNYR2BMGwYecxzTJxxE2UcDn6LsY/qEgww85jhfx9scAZMJbB6BMT5s2L6V8qpKRhcW+e4EYtkcAZNuNo/AmCQNPOa4dnUAjWyOgIkyuzRkjDFZzjoCY4zJctYRGGNMlrOOwBhjspx1BMYYk+WsIzDGmCxnHYExxmQ56wiMMSbLpawjEJHjReRVEakQkXdE5Ntx9hERuVtENorIahEZlap4so3lvzfG+JXKmcX1wHdUdYWIdAfKReQlVV0Xs8+5wOfdn1OA37qPJgmW/94Yk4iUnRGo6oequsL9fRdQAfRtsduFwB/V8SbQU0T6pCqmbGD5740xiQrlHoGIFAEjgbdabOoLbI55XsXhnQUicrWIlIlIWXW1faC1xfLfG2MSlfKOQES6AQuA61X1Xy03xznksHSoqnq/qo5R1TEFGbBwfDpZ/ntjTKJS2hGISC5OJ/C4qj4dZ5cq4PiY54VA+1YHN4DlvzfGJC5lN4tFRIC5QIWq/qqV3RYCJSIyD+cmca2qfpiqmLLFJUMuYWL/iZb/3hjjSypHDU0ALgfWiMhKt+wHwAkAqvo74DngPGAj8CkwM4XxZBXLf2+M8StlHYGqvk78ewCx+yjwrVTFYIwxxpvNLDbGmCxnHYExxmQ56wiMMSbLWUdgjDFZzjoCY4zJctYRGGNMlhNnBGfmEJFqYFOawzga+DjNMfhhcQbL4gyWxRkcPzH2U9W4k4syriOIAhEpU9Ux6Y7Di8UZLIszWBZncJKN0S4NGWNMlrOOwBhjspx1BO1zf7oD8MniDJbFGSyLMzhJxWj3CIwxJsvZGYExxmQ56wiMMSbLWUfQBhHJEZG3ReSvcbbNEJFqEVnp/lyVjhjdWCpFZI0bR1mc7SIid4vIRhFZLSKjIhrnmSJSG9OmN6chxp4iMl9E1otIhYiMb7E9Km3pFWcU2vLEmNdfKSL/EpHrW+yT9vb0GWfa29ON4z9F5B0RWSsipSKS12J7VxF50m3Pt9z14j2lcmGajuDbQAXQo5XtT6pqSYjxtOUsVW1tQsm5wOfdn1OA37qP6dBWnAD/p6pTQovmcL8GXlDVaSLSBTiixfaotKVXnJDmtlTVd4ER4HypArYAf26xW9rb02eckOb2FJG+wHXASapaJyJPAdOBh2N2mwV8oqoDRGQ6cDtwsVfddkbQChEpBM4HHkx3LAG4EPijOt4EeopIn3QHFTUi0gM4HWeJVVR1v6rubLFb2tvSZ5xRcw7wvqq2zAqQ9vZsobU4o6IzkC8inXE6/5ZrvF8IPOL+Ph84x102uE3WEbTuLuB7QEMb+0x1T2fni8jxIcUVjwKLRKRcRK6Os70vsDnmeZVbFjavOAHGi8gqEXleRE4OMzjgc0A18Af3kuCDInJki32i0JZ+4oT0tmVL04HSOOVRaM9YrcUJaW5PVd0C/AL4J/Ahzhrvi1rs1tSeqloP1AK9veq2jiAOEZkCbFfV8jZ2+wtQpKrDgJc51AunwwRVHYVzmv0tETm9xfZ43wjSMW7YK84VOPlQhgP3AM+EHF9nYBTwW1UdCewBvt9inyi0pZ84092WTdxLVxcAf4q3OU5ZWsa0e8SZ9vYUkV443/j7A8cBR4rIZS13i3OoZ3taRxDfBOACEakE5gFni8hjsTuoao2q7nOfPgCMDjfEZrFsdR+341zbLG6xSxUQe8ZSyOGnlCnnFaeq/ktVd7u/PwfkisjRIYZYBVSp6lvu8/k4H7gt90l3W3rGGYG2jHUusEJVt8XZFoX2bNRqnBFpz4nAB6paraoHgKeBU1vs09Se7uWjo4AdXhVbRxCHqt6kqoWqWoRzqviKqjbreVtcx7wA56Zy6ETkSBHp3vg7MBlY22K3hcAV7giNcTinlB9GLU4RObbxeqaIFOP8fdaEFaOqfgRsFpET3aJzgHUtdkt7W/qJM91t2cIltH65Je3tGaPVOCPSnv8ExonIEW4s53D4585C4Er392k4n12eZwQ2aigBInIbUKaqC4HrROQCoB6nx52RprA+C/zZ/RvtDDyhqi+IyDUAqvo74DngPGAj8CkwM6JxTgO+KSL1QB0w3c8fccBmA4+7lwn+AcyMYFv6iTMKbYmIHAFMAr4RUxa59vQRZ9rbU1XfEpH5OJep6oG3gftbfC7NBR4VkY04n0vT/dRtKSaMMSbL2aUhY4zJctYRGGNMlrOOwBhjspx1BMYYk+WsIzDGmCxnHYGJJBH5oZtlcbWb7THQRGTiZJOMl1U2bnkAr/cVETkp5vliEWlzsXEROc4dLmhMStk8AhM54qRUngKMUtV97gzOLmkOK1lfAf7K4RPUWuXOxJ6WsoiMcdkZgYmiPsDHjSk8VPXjxvQUIjJaRP7uJq57sXGGt/sN+y4ReUOcXO3FbnmxW/a2+3hiq6/agjsb+iERWe4ef6FbPkNEnhaRF0TkPRG5I+aYWSKywY3nARG5V0ROxZl9/nP37Obf3N0vEpFl7v5fiPP6RSKy1us1Wxwz1n2fq9y6u7vHPiMifxGRD0SkRERucN/TmyLyGb9tYjom6whMFC0Cjnc/IH8jImcAiEguTsKvaao6GngI+EnMcUeq6qnAte42gPXA6W5ytpuBnyYQxw9xpuiPBc7C+SBvzPI5AifP+1DgYhE5XkSOA34EjMOZpToIQFXfwJn6/11VHaGq77t1dFbVYuB64BYf8Rz2mrEb3VnGTwLfdpOjTcSZBQswBPgPnPxOPwE+ddtkKXBFAm1iOiC7NGQiR1V3i8ho4As4H8BPisj3gTKcD7SX3FQVOTjpeBuVuse/JiI9RKQn0B14REQ+j5OFMTeBUCbjJB+80X2eB5zg/v43Va0FEJF1QD/gaODvqrrDLf8TMLCN+p92H8uBIh/xxHvN2BTOJwIfqupycBKlufsCvKqqu4BdIlKLkz0XYA0wzMdrmw7MOgITSap6EFgMLBaRNTiJtMqBd1R1fGuHxXn+Y5wPwa+Ks2zf4gTCEGCqu4LVoULnxvW+mKKDOP8veS4A0kJjHY3H+92/tWOE1lMOxx7bEPO8wedrmw7MLg2ZyBFnDdnPxxSNADYB7wIF7s1kRCRXmi8QcrFbfhpOFstanDS8W9ztMxIM5UVgtkhT1smRHvsvA84QkV7ipACeGrNtF87ZSSqtB44TkbEA7v0B+5A3nuyPxERRN+Ae99JOPU5myqtVdb+ITAPuFpGjcP5+7wLecY/7RETewFlj+utu2R04l4ZuAF5JMI4fu/WvdjuDSpzRTHGp6hYR+SnwFk5O/XU4K0SBs67FAyJyHSkaCeS2z8U4bZePc39gYipey3Qsln3UdAgishi4UVXL0hxHN/ceR2ecxXceUtV4C6EbExl2aciYYN0qIitxFt35gDQuEWmMX3ZGYIwxWc7OCIwxJstZR2CMMVnOOgJjjMly1hEYY0yWs47AGGOy3P8HW5P8PmyhWmwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scatter plot using pandas\n",
    "\n",
    "ax = df[df.Class=='Iris-setosa'].plot.scatter(x='Sepal length in cm', y='Sepal width in cm', color='red', label='setosa')\n",
    "df[df.Class=='Iris-versicolor'].plot.scatter(x='Sepal length in cm', y='Sepal width in cm', color='green', label='versicolor', ax=ax)\n",
    "df[df.Class=='Iris-virginica'].plot.scatter(x='Sepal length in cm', y='Sepal width in cm', label='virginica', ax=ax)\n",
    "ax.set_title(\"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing:  Feature selection/extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "145    2\n",
       "146    2\n",
       "147    2\n",
       "148    2\n",
       "149    2\n",
       "Name: Class, Length: 150, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convert Categorical features to numerical values\n",
    "di = {'Iris-setosa' : 0, 'Iris-versicolor' : 1, 'Iris-virginica' : '2'}\n",
    "df['Class'] = df['Class'].apply(lambda x: di.get(x,x))\n",
    "\n",
    "df.Class = df.Class.astype('int64')\n",
    "df.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal length in cm</th>\n",
       "      <th>Sepal width in cm</th>\n",
       "      <th>Petal length in cm</th>\n",
       "      <th>Petal width in cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal length in cm  Sepal width in cm  Petal length in cm  \\\n",
       "0                 5.1                3.5                 1.4   \n",
       "1                 4.9                3.0                 1.4   \n",
       "2                 4.7                3.2                 1.3   \n",
       "3                 4.6                3.1                 1.5   \n",
       "4                 5.0                3.6                 1.4   \n",
       "\n",
       "   Petal width in cm  \n",
       "0                0.2  \n",
       "1                0.2  \n",
       "2                0.2  \n",
       "3                0.2  \n",
       "4                0.2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Feature = df[['Sepal length in cm','Sepal width in cm','Petal length in cm','Petal width in cm']]\n",
    "Feature.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal length in cm</th>\n",
       "      <th>Sepal width in cm</th>\n",
       "      <th>Petal length in cm</th>\n",
       "      <th>Petal width in cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal length in cm  Sepal width in cm  Petal length in cm  \\\n",
       "0                 5.1                3.5                 1.4   \n",
       "1                 4.9                3.0                 1.4   \n",
       "2                 4.7                3.2                 1.3   \n",
       "3                 4.6                3.1                 1.5   \n",
       "4                 5.0                3.6                 1.4   \n",
       "\n",
       "   Petal width in cm  \n",
       "0                0.2  \n",
       "1                0.2  \n",
       "2                0.2  \n",
       "3                0.2  \n",
       "4                0.2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Feature\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Class']\n",
    "y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Normalize Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.90068117,  1.03205722, -1.3412724 , -1.31297673],\n",
       "       [-1.14301691, -0.1249576 , -1.3412724 , -1.31297673],\n",
       "       [-1.38535265,  0.33784833, -1.39813811, -1.31297673],\n",
       "       [-1.50652052,  0.10644536, -1.2844067 , -1.31297673],\n",
       "       [-1.02184904,  1.26346019, -1.3412724 , -1.31297673]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "- K Nearest Neighbor(KNN)\n",
    "- Decision Tree\n",
    "- Support Vector Machine\n",
    "- Logistic Regression\n",
    "- Naive Bayes\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide the dataset into Training and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbor(KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted values using K =  1 is  [2 0 2 2 2]\n",
      "The predicted values using K =  2 is  [2 0 2 2 2]\n",
      "The predicted values using K =  3 is  [2 0 2 2 2]\n",
      "The predicted values using K =  4 is  [2 0 2 2 2]\n",
      "The predicted values using K =  5 is  [2 0 2 2 2]\n",
      "The predicted values using K =  6 is  [2 0 2 2 2]\n",
      "The predicted values using K =  7 is  [2 0 2 2 2]\n",
      "The predicted values using K =  8 is  [2 0 2 2 2]\n",
      "The predicted values using K =  9 is  [2 0 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "Ks = 10\n",
    "for n in range(1,Ks):\n",
    "    #Train Model and Predict  \n",
    "    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n",
    "    yhat_KNN=neigh.predict(X_test)\n",
    "    print(\"The predicted values using K = \", n, \"is \", yhat_KNN[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values predicted by Decision Tree using criterion =  entropy  is  [2 0 2 2 2]\n",
      "The values predicted by Decision Tree using criterion =  gini  is  [2 0 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree_criterions = ['entropy', 'gini']\n",
    "for i in dtree_criterions:\n",
    "    drugTree = DecisionTreeClassifier(criterion=i)\n",
    "    drugTree.fit(X_train, y_train)\n",
    "    predTree = drugTree.predict(X_test)\n",
    "    print (\"The values predicted by Decision Tree using criterion = \",i,\" is \", predTree [0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values predicted by SVM using kernels =  rbf  is  [2 0 2 2 2]\n",
      "The values predicted by SVM using kernels =  linear  is  [2 0 2 2 2]\n",
      "The values predicted by SVM using kernels =  poly  is  [2 0 2 2 2]\n",
      "The values predicted by SVM using kernels =  sigmoid  is  [2 0 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_kernels = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "for i in svm_kernels:\n",
    "    clf = svm.SVC(kernel=i)\n",
    "    clf.fit(X_train, y_train) \n",
    "    yhat_SVM = clf.predict(X_test)\n",
    "    print(\"The values predicted by SVM using kernels = \", i, \" is \", yhat_SVM [0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values predicted by Logistic Regression using c =  0.001  and solver =  liblinear  is  [2 0 2 2 2]\n",
      "The values predicted by Logistic Regression using c =  0.01  and solver =  liblinear  is  [2 0 2 2 2]\n",
      "The values predicted by Logistic Regression using c =  0.1  and solver =  liblinear  is  [2 0 2 2 2]\n",
      "The values predicted by Logistic Regression using c =  0.001  and solver =  newton-cg  is  [1 1 1 2 1]\n",
      "The values predicted by Logistic Regression using c =  0.01  and solver =  newton-cg  is  [2 0 2 2 2]\n",
      "The values predicted by Logistic Regression using c =  0.1  and solver =  newton-cg  is  [2 0 2 2 2]\n",
      "The values predicted by Logistic Regression using c =  0.001  and solver =  lbfgs  is  [1 1 1 2 1]\n",
      "The values predicted by Logistic Regression using c =  0.01  and solver =  lbfgs  is  [2 0 2 2 2]\n",
      "The values predicted by Logistic Regression using c =  0.1  and solver =  lbfgs  is  [2 0 2 2 2]\n",
      "The values predicted by Logistic Regression using c =  0.001  and solver =  sag  is  [1 1 1 2 1]\n",
      "The values predicted by Logistic Regression using c =  0.01  and solver =  sag  is  [2 0 2 2 2]\n",
      "The values predicted by Logistic Regression using c =  0.1  and solver =  sag  is  [2 0 2 2 2]\n",
      "The values predicted by Logistic Regression using c =  0.001  and solver =  saga  is  [1 1 1 2 1]\n",
      "The values predicted by Logistic Regression using c =  0.01  and solver =  saga  is  [2 0 2 2 2]\n",
      "The values predicted by Logistic Regression using c =  0.1  and solver =  saga  is  [2 0 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "c_param_range=[0.001,0.01,0.1]\n",
    "lr_solvers=['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "for i in lr_solvers:\n",
    "    for f in c_param_range:\n",
    "        LR = LogisticRegression(C=f, solver=i).fit(X_train,y_train)\n",
    "        yhat_LR = LR.predict(X_test)\n",
    "        print(\"The values predicted by Logistic Regression using c = \",f,\" and solver = \",i, \" is \",yhat_LR[0:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values predicted by Naive Bayes is  [2 0 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred_NB = gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"The values predicted by Naive Bayes is \", y_pred_NB[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values predicted by Random Forest using criterion =  entropy  is  [2 0 2 2 2]\n",
      "The values predicted by Random Forest using criterion =  gini  is  [2 0 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_criterion=['entropy', 'gini']\n",
    "for i in rf_criterion:\n",
    "    clf=RandomForestClassifier(criterion=i)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred_RF=clf.predict(X_test)\n",
    "    print(\"The values predicted by Random Forest using criterion = \", i,\" is \",y_pred_RF[0:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation using Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score with k =  1 is  0.9333333333333333\n",
      "The f1 score with k =  1 is  0.9327283726557775\n",
      "The accuracy score with k =  2 is  0.9555555555555556\n",
      "The f1 score with k =  2 is  0.9555555555555556\n",
      "The accuracy score with k =  3 is  0.9555555555555556\n",
      "The f1 score with k =  3 is  0.9555555555555556\n",
      "The accuracy score with k =  4 is  0.9555555555555556\n",
      "The f1 score with k =  4 is  0.9555555555555556\n",
      "The accuracy score with k =  5 is  0.9555555555555556\n",
      "The f1 score with k =  5 is  0.9555555555555556\n",
      "The accuracy score with k =  6 is  0.9555555555555556\n",
      "The f1 score with k =  6 is  0.9555555555555556\n",
      "The accuracy score with k =  7 is  0.9555555555555556\n",
      "The f1 score with k =  7 is  0.9555555555555556\n",
      "The accuracy score with k =  8 is  0.9555555555555556\n",
      "The f1 score with k =  8 is  0.9555555555555556\n",
      "The accuracy score with k =  9 is  0.9555555555555556\n",
      "The f1 score with k =  9 is  0.9555555555555556\n",
      "\n",
      "The best accuracy score for KNN was  0.9555555555555556 with k= 2\n",
      "The best f1 score for KNN was  0.9555555555555556 with k= 2\n"
     ]
    }
   ],
   "source": [
    "Ks = 10\n",
    "accuracy_scor = np.zeros((Ks-1))\n",
    "f1_scor = np.zeros((Ks-1))\n",
    "\n",
    "\n",
    "for n in range(1,Ks):\n",
    "    \n",
    "    #Train Model and Predict  \n",
    "    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n",
    "    yhat_KNN=neigh.predict(X_test)\n",
    "    accuracy_scor[n-1] = accuracy_score(y_test, yhat_KNN)\n",
    "    f1_scor[n-1] = f1_score(y_test, yhat_KNN, average = 'weighted')\n",
    "    print(\"The accuracy score with k = \",n, \"is \",accuracy_scor[n-1])\n",
    "    print(\"The f1 score with k = \",n, \"is \",f1_scor[n-1])\n",
    "    \n",
    "\n",
    "print( \"\\nThe best accuracy score for KNN was \", accuracy_scor.max(), \"with k=\", accuracy_scor.argmax()+1) \n",
    "print( \"The best f1 score for KNN was \", f1_scor.max(), \"with k=\", f1_scor.argmax()+1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report of KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        21\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       0.93      0.93      0.93        14\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.94      0.94      0.94        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors = accuracy_scor.argmax()+1).fit(X_train,y_train)\n",
    "yhat_KNN=neigh.predict(X_test)\n",
    "print (classification_report(y_test, yhat_KNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTrees's Accuracy with criterion =  entropy  using Accuracy Score:  0.9777777777777777\n",
      "DecisionTrees's Accuracy with criterion =  entropy  using F1 Score:  0.9775761242185925\n",
      "DecisionTrees's Accuracy with criterion =  gini  using Accuracy Score:  0.9777777777777777\n",
      "DecisionTrees's Accuracy with criterion =  gini  using F1 Score:  0.9775761242185925\n",
      "\n",
      "The best accuracy score using Decision Tree is  0.9777777777777777\n",
      "The best f1 score using Decision Tree is  0.9775761242185925\n"
     ]
    }
   ],
   "source": [
    "f = 0\n",
    "ascore_dtree = np.zeros(2)\n",
    "fscore_dtree = np.zeros(2)\n",
    "dtree_criterions = ['entropy', 'gini']\n",
    "for i in dtree_criterions:\n",
    "    drugTree = DecisionTreeClassifier(criterion=i)\n",
    "    drugTree.fit(X_train, y_train)\n",
    "    predTree = drugTree.predict(X_test)\n",
    "    ascore_dtree[f] = accuracy_score(y_test, predTree)\n",
    "    fscore_dtree[f] = f1_score(y_test, predTree, average = 'weighted')\n",
    "    print(\"DecisionTrees's Accuracy with criterion = \", i,\" using Accuracy Score: \", accuracy_score(y_test, predTree))\n",
    "    print(\"DecisionTrees's Accuracy with criterion = \", i,\" using F1 Score: \", f1_score(y_test, predTree, average = 'weighted'))\n",
    "    f += 1\n",
    "print(\"\\nThe best accuracy score using Decision Tree is \",ascore_dtree.max())\n",
    "print(\"The best f1 score using Decision Tree is \",fscore_dtree.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for criterion =  entropy \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        21\n",
      "           1       1.00      0.90      0.95        10\n",
      "           2       0.93      1.00      0.97        14\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "Classification report for criterion =  gini \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        21\n",
      "           1       1.00      0.90      0.95        10\n",
      "           2       0.93      1.00      0.97        14\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = ['entropy','gini']\n",
    "for i in k:\n",
    "    drugTree = DecisionTreeClassifier(criterion=i)\n",
    "    drugTree.fit(X_train, y_train)\n",
    "    predTree = drugTree.predict(X_test)\n",
    "    print(\"Classification report for criterion = \",i,\"\\n\\n\",classification_report(y_test, predTree))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for SVM with kernel =  rbf  is :  0.9555555555555556\n",
      "The f1 score for SVM with kernel =  rbf  is:  0.9555555555555556\n",
      "The accuracy score for SVM with kernel =  linear  is :  0.9555555555555556\n",
      "The f1 score for SVM with kernel =  linear  is:  0.9555555555555556\n",
      "The accuracy score for SVM with kernel =  poly  is :  0.9777777777777777\n",
      "The f1 score for SVM with kernel =  poly  is:  0.9778953556731335\n",
      "The accuracy score for SVM with kernel =  sigmoid  is :  0.8888888888888888\n",
      "The f1 score for SVM with kernel =  sigmoid  is:  0.8912633888243644\n",
      "\n",
      "The best accuracy score using SVM is  0.9777777777777777\n",
      "The best f1 score using SVM is  0.9778953556731335\n"
     ]
    }
   ],
   "source": [
    "f=0\n",
    "ascore_svm = np.zeros(4)\n",
    "fscore_svm = np.zeros(4)\n",
    "svm_kernels = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "\n",
    "for i in svm_kernels:\n",
    "    clf = svm.SVC(kernel=i)\n",
    "    clf.fit(X_train, y_train) \n",
    "    yhat_SVM = clf.predict(X_test)\n",
    "    ascore_svm[f] = accuracy_score(y_test, yhat_SVM)\n",
    "    fscore_svm[f] = f1_score(y_test, yhat_SVM, average='weighted')\n",
    "    print(\"The accuracy score for SVM with kernel = \", i,\" is : \", accuracy_score(y_test, yhat_SVM))\n",
    "    print(\"The f1 score for SVM with kernel = \", i,\" is: \", f1_score(y_test, yhat_SVM, average='weighted'))\n",
    "    f += 1\n",
    "print(\"\\nThe best accuracy score using SVM is \",ascore_svm.max())\n",
    "print(\"The best f1 score using SVM is \",fscore_svm.max())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report of SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for kernel =  rbf  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        21\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       0.93      0.93      0.93        14\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.94      0.94      0.94        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "Classification report for kernel =  linear  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        21\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       0.93      0.93      0.93        14\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.94      0.94      0.94        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "Classification report for kernel =  poly  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        21\n",
      "           1       0.91      1.00      0.95        10\n",
      "           2       1.00      0.93      0.96        14\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "Classification report for kernel =  sigmoid  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        21\n",
      "           1       0.73      0.80      0.76        10\n",
      "           2       0.86      0.86      0.86        14\n",
      "\n",
      "    accuracy                           0.89        45\n",
      "   macro avg       0.86      0.87      0.86        45\n",
      "weighted avg       0.89      0.89      0.89        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "for i in k:\n",
    "    clf = svm.SVC(kernel=i)\n",
    "    clf.fit(X_train, y_train) \n",
    "    yhat_SVM = clf.predict(X_test)\n",
    "    print (\"Classification report for kernel = \",i,\" \\n\\n\",classification_report(y_test, yhat_SVM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for Logistic Regression with solver =  0.001  and kernel =  liblinear  is :  0.8666666666666667\n",
      "The f1 score for Logistic Regression with solver =  0.001  and kernel =  liblinear  is :  0.8498599439775911\n",
      "The accuracy score for Logistic Regression with solver =  0.01  and kernel =  liblinear  is :  0.8666666666666667\n",
      "The f1 score for Logistic Regression with solver =  0.01  and kernel =  liblinear  is :  0.8498599439775911\n",
      "The accuracy score for Logistic Regression with solver =  0.1  and kernel =  liblinear  is :  0.8666666666666667\n",
      "The f1 score for Logistic Regression with solver =  0.1  and kernel =  liblinear  is :  0.8683113727689001\n",
      "The accuracy score for Logistic Regression with solver =  0.001  and kernel =  newton-cg  is :  0.28888888888888886\n",
      "The f1 score for Logistic Regression with solver =  0.001  and kernel =  newton-cg  is :  0.19527400703871295\n",
      "The accuracy score for Logistic Regression with solver =  0.01  and kernel =  newton-cg  is :  0.8444444444444444\n",
      "The f1 score for Logistic Regression with solver =  0.01  and kernel =  newton-cg  is :  0.849190164142444\n",
      "The accuracy score for Logistic Regression with solver =  0.1  and kernel =  newton-cg  is :  0.9555555555555556\n",
      "The f1 score for Logistic Regression with solver =  0.1  and kernel =  newton-cg  is :  0.9568932322319856\n",
      "The accuracy score for Logistic Regression with solver =  0.001  and kernel =  lbfgs  is :  0.28888888888888886\n",
      "The f1 score for Logistic Regression with solver =  0.001  and kernel =  lbfgs  is :  0.19527400703871295\n",
      "The accuracy score for Logistic Regression with solver =  0.01  and kernel =  lbfgs  is :  0.8444444444444444\n",
      "The f1 score for Logistic Regression with solver =  0.01  and kernel =  lbfgs  is :  0.849190164142444\n",
      "The accuracy score for Logistic Regression with solver =  0.1  and kernel =  lbfgs  is :  0.9555555555555556\n",
      "The f1 score for Logistic Regression with solver =  0.1  and kernel =  lbfgs  is :  0.9568932322319856\n",
      "The accuracy score for Logistic Regression with solver =  0.001  and kernel =  sag  is :  0.28888888888888886\n",
      "The f1 score for Logistic Regression with solver =  0.001  and kernel =  sag  is :  0.19527400703871295\n",
      "The accuracy score for Logistic Regression with solver =  0.01  and kernel =  sag  is :  0.8444444444444444\n",
      "The f1 score for Logistic Regression with solver =  0.01  and kernel =  sag  is :  0.849190164142444\n",
      "The accuracy score for Logistic Regression with solver =  0.1  and kernel =  sag  is :  0.9555555555555556\n",
      "The f1 score for Logistic Regression with solver =  0.1  and kernel =  sag  is :  0.9568932322319856\n",
      "The accuracy score for Logistic Regression with solver =  0.001  and kernel =  saga  is :  0.28888888888888886\n",
      "The f1 score for Logistic Regression with solver =  0.001  and kernel =  saga  is :  0.19527400703871295\n",
      "The accuracy score for Logistic Regression with solver =  0.01  and kernel =  saga  is :  0.8444444444444444\n",
      "The f1 score for Logistic Regression with solver =  0.01  and kernel =  saga  is :  0.849190164142444\n",
      "The accuracy score for Logistic Regression with solver =  0.1  and kernel =  saga  is :  0.9555555555555556\n",
      "The f1 score for Logistic Regression with solver =  0.1  and kernel =  saga  is :  0.9568932322319856\n",
      "\n",
      "The best accuracy score using Logistic Regression is  0.9555555555555556\n",
      "The best f1 score using Logistic Regression is  0.9568932322319856\n"
     ]
    }
   ],
   "source": [
    "g = 0\n",
    "ascore_lr = np.zeros(15)\n",
    "fscore_lr = np.zeros(15)\n",
    "c_param_range=[0.001,0.01,0.1]\n",
    "lr_solvers=['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "for i in lr_solvers:\n",
    "    for f in c_param_range:\n",
    "        LR = LogisticRegression(C=f, solver=i).fit(X_train,y_train)\n",
    "        yhat_LR = LR.predict(X_test)\n",
    "        ascore_lr[g] = accuracy_score(y_test, yhat_LR)\n",
    "        fscore_lr[g] = f1_score(y_test, yhat_LR, average='weighted')\n",
    "        print(\"The accuracy score for Logistic Regression with solver = \", f, \" and kernel = \", i,\" is : \", accuracy_score(y_test, yhat_LR))\n",
    "        print(\"The f1 score for Logistic Regression with solver = \", f, \" and kernel = \", i,\" is : \", f1_score(y_test, yhat_LR, average='weighted'))\n",
    "        g += 1\n",
    "print(\"\\nThe best accuracy score using Logistic Regression is \",ascore_lr.max())\n",
    "print(\"The best f1 score using Logistic Regression is \",fscore_lr.max())              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for solver =  liblinear  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        21\n",
      "           1       1.00      0.40      0.57        10\n",
      "           2       0.70      1.00      0.82        14\n",
      "\n",
      "    accuracy                           0.87        45\n",
      "   macro avg       0.90      0.80      0.80        45\n",
      "weighted avg       0.91      0.87      0.85        45\n",
      "\n",
      "Classification report for solver =  newton-cg  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        21\n",
      "           1       0.62      0.80      0.70        10\n",
      "           2       0.83      0.71      0.77        14\n",
      "\n",
      "    accuracy                           0.84        45\n",
      "   macro avg       0.82      0.82      0.81        45\n",
      "weighted avg       0.86      0.84      0.85        45\n",
      "\n",
      "Classification report for solver =  lbfgs  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        21\n",
      "           1       0.62      0.80      0.70        10\n",
      "           2       0.83      0.71      0.77        14\n",
      "\n",
      "    accuracy                           0.84        45\n",
      "   macro avg       0.82      0.82      0.81        45\n",
      "weighted avg       0.86      0.84      0.85        45\n",
      "\n",
      "Classification report for solver =  sag  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        21\n",
      "           1       0.62      0.80      0.70        10\n",
      "           2       0.83      0.71      0.77        14\n",
      "\n",
      "    accuracy                           0.84        45\n",
      "   macro avg       0.82      0.82      0.81        45\n",
      "weighted avg       0.86      0.84      0.85        45\n",
      "\n",
      "Classification report for solver =  sag  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        21\n",
      "           1       0.62      0.80      0.70        10\n",
      "           2       0.83      0.71      0.77        14\n",
      "\n",
      "    accuracy                           0.84        45\n",
      "   macro avg       0.82      0.82      0.81        45\n",
      "weighted avg       0.86      0.84      0.85        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'sag']\n",
    "for i in k:\n",
    "    LR = LogisticRegression(C=0.01, solver=i).fit(X_train,y_train)\n",
    "    yhat_LR = LR.predict(X_test)\n",
    "    print(\"Classification report for solver = \",i,\" \\n\\n\",classification_report(y_test, yhat_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for Naive Bayes is :  0.9777777777777777\n",
      "The f1 score for Naive Bayes is:  0.9778953556731335\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred_NB = gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"The accuracy score for Naive Bayes is : \", accuracy_score(y_test, y_pred_NB))\n",
    "print(\"The f1 score for Naive Bayes is: \", f1_score(y_test, y_pred_NB, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report of Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        21\n",
      "           1       0.91      1.00      0.95        10\n",
      "           2       1.00      0.93      0.96        14\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_NB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for Random Forest with criterion =  entropy  is  0.9777777777777777\n",
      "The f1 score for Random Forest with criterion =  entropy  is  0.9775761242185925\n",
      "The accuracy score for Random Forest with criterion =  gini  is  0.9777777777777777\n",
      "The f1 score for Random Forest with criterion =  gini  is  0.9775761242185925\n",
      "\n",
      "The best accuracy score using Random Forest is  0.9777777777777777\n",
      "The best f1 score using Random Forest is  0.9775761242185925\n"
     ]
    }
   ],
   "source": [
    "f=0\n",
    "ascore_rf = np.zeros(2)\n",
    "fscore_rf = np.zeros(2)\n",
    "rf_criterion=['entropy', 'gini']\n",
    "for i in rf_criterion:\n",
    "    clf=RandomForestClassifier(criterion=i)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred_RF=clf.predict(X_test)\n",
    "    ascore_rf[f] = accuracy_score(y_test, y_pred_RF)\n",
    "    fscore_rf[f] = f1_score(y_test, y_pred_RF, average='weighted')\n",
    "    print(\"The accuracy score for Random Forest with criterion = \",i,\" is \", accuracy_score(y_test, y_pred_RF))\n",
    "    print(\"The f1 score for Random Forest with criterion = \",i,\" is \", f1_score(y_test, y_pred_RF, average='weighted'))\n",
    "    f += 1\n",
    "    \n",
    "print(\"\\nThe best accuracy score using Random Forest is \",ascore_rf.max())\n",
    "print(\"The best f1 score using Random Forest is \",fscore_rf.max())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report of Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for criterion =  entropy  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        21\n",
      "           1       1.00      0.90      0.95        10\n",
      "           2       0.93      1.00      0.97        14\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "Classification report for criterion =  gini  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        21\n",
      "           1       1.00      0.90      0.95        10\n",
      "           2       0.93      1.00      0.97        14\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = ['entropy', 'gini']\n",
    "for i in k:\n",
    "    clf=RandomForestClassifier(criterion=i)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred_RF=clf.predict(X_test)\n",
    "    print(\"Classification report for criterion = \",i,\" \\n\\n\",classification_report(y_test, y_pred_RF))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report on accuracy of different algorithms using F1 score and Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# js = jaccard score.......fs = F1-Score\n",
    "# KNN\n",
    "knnas = accuracy_scor.max()\n",
    "knnfs = f1_scor.max()\n",
    "# DTree with max accuracy\n",
    "dtreeas = ascore_dtree.max()\n",
    "dtreefs = fscore_dtree.max()\n",
    "\n",
    "# SVM with max accuracy\n",
    "svmas = ascore_svm.max()\n",
    "svmfs = fscore_svm.max()\n",
    "\n",
    "# Logistic regression with max accuracy\n",
    "lras = ascore_lr.max()\n",
    "lrfs = fscore_lr.max()\n",
    "\n",
    "# Naive Bayes\n",
    "nbas = accuracy_score(y_test, y_pred_NB)\n",
    "nbfs = f1_score(y_test, y_pred_NB, average='weighted')\n",
    "\n",
    "# Random Forest\n",
    "rfas = ascore_rf.max()\n",
    "rffs = fscore_rf.max()\n",
    "\n",
    "#max of all\n",
    "max_as = [knnas,dtreeas,svmas,lras,nbas,rfas]\n",
    "max_fs = [knnfs,dtreefs,svmfs,lrfs,nbfs,rffs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy_Score</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-Nearest Neighor</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.977576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.977895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.956893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.977895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.977576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Algorithm  Accuracy_Score  F1-Score\n",
       "1       K-Nearest Neighor        0.955556  0.955556\n",
       "2           Decision tree        0.977778  0.977576\n",
       "3  Support Vector Machine        0.977778  0.977895\n",
       "4     Logistic regression        0.955556  0.956893\n",
       "5             Naive Bayes        0.977778  0.977895\n",
       "6           Random Forest        0.977778  0.977576"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Algorithm':['K-Nearest Neighor', 'Decision tree', 'Support Vector Machine', 'Logistic regression', 'Naive Bayes', 'Random Forest'], \n",
    "        'Accuracy_Score':max_as, 'F1-Score':max_fs}\n",
    "s = pd.DataFrame(data, index = [1,2,3,4,5,6])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
