{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<h1 align=\"center\"><font size=\"5\">Predicting Customer Category Of Telecommunication Users</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div id=\"about_dataset\">\n",
    "    <h2>About the dataset</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Imagine a telecommunications provider has segmented its customer base by service usage patterns, categorizing the customers into four groups. If demographic data can be used to predict group membership, the company can customize offers for individual prospective customers. It is a classification problem. That is, given the dataset,  with predefined labels, we need to build a model to be used to predict class of a new or unknown case. \n",
    "\n",
    "The example focuses on using demographic data, such as region, age, and marital, to predict usage patterns. \n",
    "\n",
    "The target field, called __custcat__, has four possible values that correspond to the four customer groups, as follows:\n",
    "  1- Basic Service\n",
    "  2- E-Service\n",
    "  3- Plus Service\n",
    "  4- Total Service\n",
    "\n",
    "Our objective is to build a classifier, to predict the class of unknown cases. We will use a specific type of classification called K nearest neighbour.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data From CSV File  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>tenure</th>\n",
       "      <th>age</th>\n",
       "      <th>marital</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>retire</th>\n",
       "      <th>gender</th>\n",
       "      <th>reside</th>\n",
       "      <th>custcat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>136</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    region  tenure  age  marital  address  income  ed  employ  retire  gender  \\\n",
       "0        2      13   44        1        9      64   4       5       0       0   \n",
       "1        3      11   33        1        7     136   5       5       0       0   \n",
       "2        3      68   52        1       24     116   1      29       0       1   \n",
       "3        2      33   33        0       12      33   2       0       0       1   \n",
       "4        2      23   30        1        9      30   1       2       0       0   \n",
       "..     ...     ...  ...      ...      ...     ...  ..     ...     ...     ...   \n",
       "95       2      17   33        0        9      23   5       3       0       0   \n",
       "96       1      55   53        1       21      34   1       8       0       0   \n",
       "97       3      43   36        1        5     107   1      19       0       1   \n",
       "98       2      47   25        1        5      21   1       1       0       1   \n",
       "99       3      65   58        0       30      83   2      16       0       1   \n",
       "\n",
       "    reside  custcat  \n",
       "0        2        1  \n",
       "1        6        4  \n",
       "2        2        3  \n",
       "3        1        1  \n",
       "4        4        3  \n",
       "..     ...      ...  \n",
       "95       1        4  \n",
       "96       2        3  \n",
       "97       3        2  \n",
       "98       2        3  \n",
       "99       1        2  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'E:\\Datasets\\teleCustCat.csv', encoding= 'unicode_escape')   \n",
    "df.head(100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>tenure</th>\n",
       "      <th>age</th>\n",
       "      <th>marital</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>retire</th>\n",
       "      <th>gender</th>\n",
       "      <th>reside</th>\n",
       "      <th>custcat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     region  tenure    age  marital  address  income     ed  employ  retire  \\\n",
       "0     False   False  False    False    False   False  False   False   False   \n",
       "1     False   False  False    False    False   False  False   False   False   \n",
       "2     False   False  False    False    False   False  False   False   False   \n",
       "3     False   False  False    False    False   False  False   False   False   \n",
       "4     False   False  False    False    False   False  False   False   False   \n",
       "..      ...     ...    ...      ...      ...     ...    ...     ...     ...   \n",
       "995   False   False  False    False    False   False  False   False   False   \n",
       "996   False   False  False    False    False   False  False   False   False   \n",
       "997   False   False  False    False    False   False  False   False   False   \n",
       "998   False   False  False    False    False   False  False   False   False   \n",
       "999   False   False  False    False    False   False  False   False   False   \n",
       "\n",
       "     gender  reside  custcat  \n",
       "0     False   False    False  \n",
       "1     False   False    False  \n",
       "2     False   False    False  \n",
       "3     False   False    False  \n",
       "4     False   False    False  \n",
       "..      ...     ...      ...  \n",
       "995   False   False    False  \n",
       "996   False   False    False  \n",
       "997   False   False    False  \n",
       "998   False   False    False  \n",
       "999   False   False    False  \n",
       "\n",
       "[1000 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>tenure</th>\n",
       "      <th>age</th>\n",
       "      <th>marital</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>retire</th>\n",
       "      <th>gender</th>\n",
       "      <th>reside</th>\n",
       "      <th>custcat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.0000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.0220</td>\n",
       "      <td>35.526000</td>\n",
       "      <td>41.684000</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>11.551000</td>\n",
       "      <td>77.535000</td>\n",
       "      <td>2.671000</td>\n",
       "      <td>10.987000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.517000</td>\n",
       "      <td>2.331000</td>\n",
       "      <td>2.487000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.8162</td>\n",
       "      <td>21.359812</td>\n",
       "      <td>12.558816</td>\n",
       "      <td>0.500225</td>\n",
       "      <td>10.086681</td>\n",
       "      <td>107.044165</td>\n",
       "      <td>1.222397</td>\n",
       "      <td>10.082087</td>\n",
       "      <td>0.211745</td>\n",
       "      <td>0.499961</td>\n",
       "      <td>1.435793</td>\n",
       "      <td>1.120306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.0000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.0000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.0000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1668.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          region       tenure          age      marital      address  \\\n",
       "count  1000.0000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      2.0220    35.526000    41.684000     0.495000    11.551000   \n",
       "std       0.8162    21.359812    12.558816     0.500225    10.086681   \n",
       "min       1.0000     1.000000    18.000000     0.000000     0.000000   \n",
       "25%       1.0000    17.000000    32.000000     0.000000     3.000000   \n",
       "50%       2.0000    34.000000    40.000000     0.000000     9.000000   \n",
       "75%       3.0000    54.000000    51.000000     1.000000    18.000000   \n",
       "max       3.0000    72.000000    77.000000     1.000000    55.000000   \n",
       "\n",
       "            income           ed       employ       retire       gender  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean     77.535000     2.671000    10.987000     0.047000     0.517000   \n",
       "std     107.044165     1.222397    10.082087     0.211745     0.499961   \n",
       "min       9.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "25%      29.000000     2.000000     3.000000     0.000000     0.000000   \n",
       "50%      47.000000     3.000000     8.000000     0.000000     1.000000   \n",
       "75%      83.000000     4.000000    17.000000     0.000000     1.000000   \n",
       "max    1668.000000     5.000000    47.000000     1.000000     1.000000   \n",
       "\n",
       "            reside      custcat  \n",
       "count  1000.000000  1000.000000  \n",
       "mean      2.331000     2.487000  \n",
       "std       1.435793     1.120306  \n",
       "min       1.000000     1.000000  \n",
       "25%       1.000000     1.000000  \n",
       "50%       2.000000     3.000000  \n",
       "75%       3.000000     3.000000  \n",
       "max       8.000000     4.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div id=\"visualization_analysis\">\n",
    "    <h2>Data Visualization and Analysis</h2> \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    281\n",
       "1    266\n",
       "4    236\n",
       "2    217\n",
       "Name: custcat, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['custcat'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### 281 Plus Service, 266 Basic-service, 236 Total Service, and 217 E-Service customers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x0000022D9311A1C8>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(column='income', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'scatter')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = df[df.custcat==1].plot.scatter(x='income', y='age', color='red', label='Basic Service')\n",
    "df[df.custcat==2].plot.scatter(x='income', y='age', color='green', label='E Service', ax=ax)\n",
    "df[df.custcat==3].plot.scatter(x='income', y='age', color='blue', label='Plus Service', ax=ax)\n",
    "df[df.custcat==4].plot.scatter(x='income', y='age', color='yellow', label='Total Service', ax=ax)\n",
    "ax.set_title(\"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing:  Feature selection/extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2,  13,  44,   1,   9,  64,   4,   5,   0,   0,   2],\n",
       "       [  3,  11,  33,   1,   7, 136,   5,   5,   0,   0,   6],\n",
       "       [  3,  68,  52,   1,  24, 116,   1,  29,   0,   1,   2],\n",
       "       [  2,  33,  33,   0,  12,  33,   2,   0,   0,   1,   1],\n",
       "       [  2,  23,  30,   1,   9,  30,   1,   2,   0,   0,   4]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['region', 'tenure','age', 'marital', 'address', 'income', 'ed', 'employ','retire', 'gender', 'reside']] .values  #.astype(float)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 3, 1, 3], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['custcat'].values\n",
    "y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Normalize Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02696767, -1.055125  ,  0.18450456,  1.0100505 , -0.25303431,\n",
       "        -0.12650641,  1.0877526 , -0.5941226 , -0.22207644, -1.03459817,\n",
       "        -0.23065004],\n",
       "       [ 1.19883553, -1.14880563, -0.69181243,  1.0100505 , -0.4514148 ,\n",
       "         0.54644972,  1.9062271 , -0.5941226 , -0.22207644, -1.03459817,\n",
       "         2.55666158],\n",
       "       [ 1.19883553,  1.52109247,  0.82182601,  1.0100505 ,  1.23481934,\n",
       "         0.35951747, -1.36767088,  1.78752803, -0.22207644,  0.96655883,\n",
       "        -0.23065004],\n",
       "       [-0.02696767, -0.11831864, -0.69181243, -0.9900495 ,  0.04453642,\n",
       "        -0.41625141, -0.54919639, -1.09029981, -0.22207644,  0.96655883,\n",
       "        -0.92747794],\n",
       "       [-0.02696767, -0.58672182, -0.93080797,  1.0100505 , -0.25303431,\n",
       "        -0.44429125, -1.36767088, -0.89182893, -0.22207644, -1.03459817,\n",
       "         1.16300577]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide the dataset into Training and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "- K Nearest Neighbor(KNN)\n",
    "- Decision Tree\n",
    "- Support Vector Machine\n",
    "- Logistic Regression\n",
    "- Naive Bayes\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbor(KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted values using K =  1 is  [3 3 1 4 4]\n",
      "The predicted values using K =  2 is  [3 1 1 2 2]\n",
      "The predicted values using K =  3 is  [3 3 1 4 4]\n",
      "The predicted values using K =  4 is  [3 1 3 2 4]\n",
      "The predicted values using K =  5 is  [3 3 3 2 4]\n",
      "The predicted values using K =  6 is  [3 3 3 2 4]\n",
      "The predicted values using K =  7 is  [3 3 4 2 4]\n",
      "The predicted values using K =  8 is  [3 2 4 2 4]\n",
      "The predicted values using K =  9 is  [3 1 4 2 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "Ks = 10\n",
    "for n in range(1,Ks):\n",
    "    #Train Model and Predict  \n",
    "    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n",
    "    yhat_KNN=neigh.predict(X_test)\n",
    "    print(\"The predicted values using K = \", n, \"is \", yhat_KNN[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values predicted by Decision Tree using criterion =  entropy  is  [3 3 4 4 4]\n",
      "The values predicted by Decision Tree using criterion =  gini  is  [3 4 2 4 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree_criterions = ['entropy', 'gini']\n",
    "for i in dtree_criterions:\n",
    "    drugTree = DecisionTreeClassifier(criterion=i)\n",
    "    drugTree.fit(X_train, y_train)\n",
    "    predTree = drugTree.predict(X_test)\n",
    "    print (\"The values predicted by Decision Tree using criterion = \",i,\" is \", predTree [0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values predicted by SVM using kernels =  rbf  is  [3 1 4 4 4]\n",
      "The values predicted by SVM using kernels =  linear  is  [3 1 4 4 4]\n",
      "The values predicted by SVM using kernels =  poly  is  [3 1 2 4 4]\n",
      "The values predicted by SVM using kernels =  sigmoid  is  [1 1 4 1 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_kernels = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "for i in svm_kernels:\n",
    "    clf = svm.SVC(kernel=i)\n",
    "    clf.fit(X_train, y_train) \n",
    "    yhat_SVM = clf.predict(X_test)\n",
    "    print(\"The values predicted by SVM using kernels = \", i, \" is \", yhat_SVM [0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values predicted by Logistic Regression using c =  0.001  and solver =  liblinear  is  [1 1 4 4 4]\n",
      "The values predicted by Logistic Regression using c =  0.01  and solver =  liblinear  is  [3 1 4 4 4]\n",
      "The values predicted by Logistic Regression using c =  0.1  and solver =  liblinear  is  [3 1 4 4 4]\n",
      "The values predicted by Logistic Regression using c =  0.001  and solver =  newton-cg  is  [3 1 4 1 4]\n",
      "The values predicted by Logistic Regression using c =  0.01  and solver =  newton-cg  is  [3 1 4 4 4]\n",
      "The values predicted by Logistic Regression using c =  0.1  and solver =  newton-cg  is  [3 1 4 4 4]\n",
      "The values predicted by Logistic Regression using c =  0.001  and solver =  lbfgs  is  [3 1 4 1 4]\n",
      "The values predicted by Logistic Regression using c =  0.01  and solver =  lbfgs  is  [3 1 4 4 4]\n",
      "The values predicted by Logistic Regression using c =  0.1  and solver =  lbfgs  is  [3 1 4 4 4]\n",
      "The values predicted by Logistic Regression using c =  0.001  and solver =  sag  is  [3 1 4 1 4]\n",
      "The values predicted by Logistic Regression using c =  0.01  and solver =  sag  is  [3 1 4 4 4]\n",
      "The values predicted by Logistic Regression using c =  0.1  and solver =  sag  is  [3 1 4 4 4]\n",
      "The values predicted by Logistic Regression using c =  0.001  and solver =  saga  is  [3 1 4 1 4]\n",
      "The values predicted by Logistic Regression using c =  0.01  and solver =  saga  is  [3 1 4 4 4]\n",
      "The values predicted by Logistic Regression using c =  0.1  and solver =  saga  is  [3 1 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "c_param_range=[0.001,0.01,0.1]\n",
    "lr_solvers=['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "for i in lr_solvers:\n",
    "    for f in c_param_range:\n",
    "        LR = LogisticRegression(C=f, solver=i).fit(X_train,y_train)\n",
    "        yhat_LR = LR.predict(X_test)\n",
    "        print(\"The values predicted by Logistic Regression using c = \",f,\" and solver = \",i, \" is \",yhat_LR[0:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values predicted by Naive Bayes is  [1 1 4 1 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred_NB = gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"The values predicted by Naive Bayes is \", y_pred_NB[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values predicted by Random Forest using criterion =  entropy  is  [1 1 4 4 4]\n",
      "The values predicted by Random Forest using criterion =  gini  is  [1 1 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_criterion=['entropy', 'gini']\n",
    "for i in rf_criterion:\n",
    "    clf=RandomForestClassifier(criterion=i)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred_RF=clf.predict(X_test)\n",
    "    print(\"The values predicted by Random Forest using criterion = \", i,\" is \",y_pred_RF[0:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation using Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score with k =  1 is  0.28\n",
      "The f1 score with k =  1 is  0.2802232381373485\n",
      "The accuracy score with k =  2 is  0.2733333333333333\n",
      "The f1 score with k =  2 is  0.2375438379466512\n",
      "The accuracy score with k =  3 is  0.30666666666666664\n",
      "The f1 score with k =  3 is  0.29636075152265373\n",
      "The accuracy score with k =  4 is  0.33\n",
      "The f1 score with k =  4 is  0.32184319699462793\n",
      "The accuracy score with k =  5 is  0.34\n",
      "The f1 score with k =  5 is  0.332524617158891\n",
      "The accuracy score with k =  6 is  0.31666666666666665\n",
      "The f1 score with k =  6 is  0.31129871928136155\n",
      "The accuracy score with k =  7 is  0.34\n",
      "The f1 score with k =  7 is  0.3376389176769396\n",
      "The accuracy score with k =  8 is  0.31666666666666665\n",
      "The f1 score with k =  8 is  0.3104490811341972\n",
      "The accuracy score with k =  9 is  0.32666666666666666\n",
      "The f1 score with k =  9 is  0.32043510992298024\n",
      "\n",
      "The best accuracy score for KNN was  0.34 with k= 5\n",
      "The best f1 score for KNN was  0.3376389176769396 with k= 7\n"
     ]
    }
   ],
   "source": [
    "Ks = 10\n",
    "accuracy_scor = np.zeros((Ks-1))\n",
    "f1_scor = np.zeros((Ks-1))\n",
    "\n",
    "\n",
    "for n in range(1,Ks):\n",
    "    \n",
    "    #Train Model and Predict  \n",
    "    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n",
    "    yhat_KNN=neigh.predict(X_test)\n",
    "    accuracy_scor[n-1] = accuracy_score(y_test, yhat_KNN)\n",
    "    f1_scor[n-1] = f1_score(y_test, yhat_KNN, average = 'weighted')\n",
    "    print(\"The accuracy score with k = \",n, \"is \",accuracy_scor[n-1])\n",
    "    print(\"The f1 score with k = \",n, \"is \",f1_scor[n-1])\n",
    "    \n",
    "\n",
    "print( \"\\nThe best accuracy score for KNN was \", accuracy_scor.max(), \"with k=\", accuracy_scor.argmax()+1) \n",
    "print( \"The best f1 score for KNN was \", f1_scor.max(), \"with k=\", f1_scor.argmax()+1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report of KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.46      0.41        81\n",
      "           2       0.33      0.42      0.37        57\n",
      "           3       0.34      0.30      0.32        86\n",
      "           4       0.29      0.20      0.23        76\n",
      "\n",
      "    accuracy                           0.34       300\n",
      "   macro avg       0.33      0.34      0.33       300\n",
      "weighted avg       0.33      0.34      0.33       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors = accuracy_scor.argmax()+1).fit(X_train,y_train)\n",
    "yhat_KNN=neigh.predict(X_test)\n",
    "print (classification_report(y_test, yhat_KNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTrees's Accuracy with criterion =  entropy  using Accuracy Score:  0.29333333333333333\n",
      "DecisionTrees's Accuracy with criterion =  entropy  using F1 Score:  0.2930596692591738\n",
      "DecisionTrees's Accuracy with criterion =  gini  using Accuracy Score:  0.31333333333333335\n",
      "DecisionTrees's Accuracy with criterion =  gini  using F1 Score:  0.31317978112687894\n",
      "\n",
      "The best accuracy score using Decision Tree is  0.31333333333333335\n",
      "The best f1 score using Decision Tree is  0.31317978112687894\n"
     ]
    }
   ],
   "source": [
    "f = 0\n",
    "ascore_dtree = np.zeros(2)\n",
    "fscore_dtree = np.zeros(2)\n",
    "dtree_criterions = ['entropy', 'gini']\n",
    "for i in dtree_criterions:\n",
    "    drugTree = DecisionTreeClassifier(criterion=i)\n",
    "    drugTree.fit(X_train, y_train)\n",
    "    predTree = drugTree.predict(X_test)\n",
    "    ascore_dtree[f] = accuracy_score(y_test, predTree)\n",
    "    fscore_dtree[f] = f1_score(y_test, predTree, average = 'weighted')\n",
    "    print(\"DecisionTrees's Accuracy with criterion = \", i,\" using Accuracy Score: \", accuracy_score(y_test, predTree))\n",
    "    print(\"DecisionTrees's Accuracy with criterion = \", i,\" using F1 Score: \", f1_score(y_test, predTree, average = 'weighted'))\n",
    "    f += 1\n",
    "print(\"\\nThe best accuracy score using Decision Tree is \",ascore_dtree.max())\n",
    "print(\"The best f1 score using Decision Tree is \",fscore_dtree.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for criterion =  entropy \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.33      0.34        81\n",
      "           2       0.30      0.35      0.33        57\n",
      "           3       0.31      0.31      0.31        86\n",
      "           4       0.28      0.25      0.26        76\n",
      "\n",
      "    accuracy                           0.31       300\n",
      "   macro avg       0.31      0.31      0.31       300\n",
      "weighted avg       0.31      0.31      0.31       300\n",
      "\n",
      "Classification report for criterion =  gini \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.44      0.42        81\n",
      "           2       0.22      0.23      0.22        57\n",
      "           3       0.37      0.33      0.35        86\n",
      "           4       0.31      0.30      0.30        76\n",
      "\n",
      "    accuracy                           0.33       300\n",
      "   macro avg       0.32      0.33      0.32       300\n",
      "weighted avg       0.33      0.33      0.33       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = ['entropy','gini']\n",
    "for i in k:\n",
    "    drugTree = DecisionTreeClassifier(criterion=i)\n",
    "    drugTree.fit(X_train, y_train)\n",
    "    predTree = drugTree.predict(X_test)\n",
    "    print(\"Classification report for criterion = \",i,\"\\n\\n\",classification_report(y_test, predTree))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for SVM with kernel =  rbf  is :  0.36666666666666664\n",
      "The f1 score for SVM with kernel =  rbf  is:  0.36008658258444315\n",
      "The accuracy score for SVM with kernel =  linear  is :  0.41\n",
      "The f1 score for SVM with kernel =  linear  is:  0.4049072713296851\n",
      "The accuracy score for SVM with kernel =  poly  is :  0.35\n",
      "The f1 score for SVM with kernel =  poly  is:  0.3374689864356919\n",
      "The accuracy score for SVM with kernel =  sigmoid  is :  0.3566666666666667\n",
      "The f1 score for SVM with kernel =  sigmoid  is:  0.34480548153787594\n",
      "\n",
      "The best accuracy score using SVM is  0.41\n",
      "The best f1 score using SVM is  0.4049072713296851\n"
     ]
    }
   ],
   "source": [
    "f=0\n",
    "ascore_svm = np.zeros(4)\n",
    "fscore_svm = np.zeros(4)\n",
    "svm_kernels = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "\n",
    "for i in svm_kernels:\n",
    "    clf = svm.SVC(kernel=i)\n",
    "    clf.fit(X_train, y_train) \n",
    "    yhat_SVM = clf.predict(X_test)\n",
    "    ascore_svm[f] = accuracy_score(y_test, yhat_SVM)\n",
    "    fscore_svm[f] = f1_score(y_test, yhat_SVM, average='weighted')\n",
    "    print(\"The accuracy score for SVM with kernel = \", i,\" is : \", accuracy_score(y_test, yhat_SVM))\n",
    "    print(\"The f1 score for SVM with kernel = \", i,\" is: \", f1_score(y_test, yhat_SVM, average='weighted'))\n",
    "    f += 1\n",
    "print(\"\\nThe best accuracy score using SVM is \",ascore_svm.max())\n",
    "print(\"The best f1 score using SVM is \",fscore_svm.max())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report of SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for kernel =  rbf  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.53      0.46        81\n",
      "           2       0.34      0.28      0.31        57\n",
      "           3       0.35      0.36      0.36        86\n",
      "           4       0.33      0.26      0.29        76\n",
      "\n",
      "    accuracy                           0.37       300\n",
      "   macro avg       0.36      0.36      0.36       300\n",
      "weighted avg       0.36      0.37      0.36       300\n",
      "\n",
      "Classification report for kernel =  linear  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.52      0.46        81\n",
      "           2       0.36      0.25      0.29        57\n",
      "           3       0.40      0.41      0.40        86\n",
      "           4       0.44      0.42      0.43        76\n",
      "\n",
      "    accuracy                           0.41       300\n",
      "   macro avg       0.40      0.40      0.40       300\n",
      "weighted avg       0.41      0.41      0.40       300\n",
      "\n",
      "Classification report for kernel =  poly  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.58      0.47        81\n",
      "           2       0.26      0.30      0.28        57\n",
      "           3       0.36      0.30      0.33        86\n",
      "           4       0.35      0.20      0.25        76\n",
      "\n",
      "    accuracy                           0.35       300\n",
      "   macro avg       0.34      0.34      0.33       300\n",
      "weighted avg       0.35      0.35      0.34       300\n",
      "\n",
      "Classification report for kernel =  sigmoid  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.51      0.43        81\n",
      "           2       0.30      0.14      0.19        57\n",
      "           3       0.33      0.38      0.36        86\n",
      "           4       0.38      0.33      0.35        76\n",
      "\n",
      "    accuracy                           0.36       300\n",
      "   macro avg       0.35      0.34      0.33       300\n",
      "weighted avg       0.35      0.36      0.34       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "for i in k:\n",
    "    clf = svm.SVC(kernel=i)\n",
    "    clf.fit(X_train, y_train) \n",
    "    yhat_SVM = clf.predict(X_test)\n",
    "    print (\"Classification report for kernel = \",i,\" \\n\\n\",classification_report(y_test, yhat_SVM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for Logistic Regression with solver =  0.001  and kernel =  liblinear  is :  0.3933333333333333\n",
      "The f1 score for Logistic Regression with solver =  0.001  and kernel =  liblinear  is :  0.37040241327701173\n",
      "The accuracy score for Logistic Regression with solver =  0.01  and kernel =  liblinear  is :  0.41333333333333333\n",
      "The f1 score for Logistic Regression with solver =  0.01  and kernel =  liblinear  is :  0.3997173792908379\n",
      "The accuracy score for Logistic Regression with solver =  0.1  and kernel =  liblinear  is :  0.41\n",
      "The f1 score for Logistic Regression with solver =  0.1  and kernel =  liblinear  is :  0.4057602869060709\n",
      "The accuracy score for Logistic Regression with solver =  0.001  and kernel =  newton-cg  is :  0.36666666666666664\n",
      "The f1 score for Logistic Regression with solver =  0.001  and kernel =  newton-cg  is :  0.30277657046491124\n",
      "The accuracy score for Logistic Regression with solver =  0.01  and kernel =  newton-cg  is :  0.4166666666666667\n",
      "The f1 score for Logistic Regression with solver =  0.01  and kernel =  newton-cg  is :  0.4032523272640878\n",
      "The accuracy score for Logistic Regression with solver =  0.1  and kernel =  newton-cg  is :  0.4033333333333333\n",
      "The f1 score for Logistic Regression with solver =  0.1  and kernel =  newton-cg  is :  0.39987853990275296\n",
      "The accuracy score for Logistic Regression with solver =  0.001  and kernel =  lbfgs  is :  0.36666666666666664\n",
      "The f1 score for Logistic Regression with solver =  0.001  and kernel =  lbfgs  is :  0.30277657046491124\n",
      "The accuracy score for Logistic Regression with solver =  0.01  and kernel =  lbfgs  is :  0.4166666666666667\n",
      "The f1 score for Logistic Regression with solver =  0.01  and kernel =  lbfgs  is :  0.4032523272640878\n",
      "The accuracy score for Logistic Regression with solver =  0.1  and kernel =  lbfgs  is :  0.4033333333333333\n",
      "The f1 score for Logistic Regression with solver =  0.1  and kernel =  lbfgs  is :  0.39987853990275296\n",
      "The accuracy score for Logistic Regression with solver =  0.001  and kernel =  sag  is :  0.36333333333333334\n",
      "The f1 score for Logistic Regression with solver =  0.001  and kernel =  sag  is :  0.3003145743145743\n",
      "The accuracy score for Logistic Regression with solver =  0.01  and kernel =  sag  is :  0.4166666666666667\n",
      "The f1 score for Logistic Regression with solver =  0.01  and kernel =  sag  is :  0.4032523272640878\n",
      "The accuracy score for Logistic Regression with solver =  0.1  and kernel =  sag  is :  0.4033333333333333\n",
      "The f1 score for Logistic Regression with solver =  0.1  and kernel =  sag  is :  0.39987853990275296\n",
      "The accuracy score for Logistic Regression with solver =  0.001  and kernel =  saga  is :  0.36666666666666664\n",
      "The f1 score for Logistic Regression with solver =  0.001  and kernel =  saga  is :  0.30277657046491124\n",
      "The accuracy score for Logistic Regression with solver =  0.01  and kernel =  saga  is :  0.4166666666666667\n",
      "The f1 score for Logistic Regression with solver =  0.01  and kernel =  saga  is :  0.4032523272640878\n",
      "The accuracy score for Logistic Regression with solver =  0.1  and kernel =  saga  is :  0.4033333333333333\n",
      "The f1 score for Logistic Regression with solver =  0.1  and kernel =  saga  is :  0.39987853990275296\n",
      "\n",
      "The best accuracy score using Logistic Regression is  0.4166666666666667\n",
      "The best f1 score using Logistic Regression is  0.4057602869060709\n"
     ]
    }
   ],
   "source": [
    "g = 0\n",
    "ascore_lr = np.zeros(15)\n",
    "fscore_lr = np.zeros(15)\n",
    "c_param_range=[0.001,0.01,0.1]\n",
    "lr_solvers=['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "for i in lr_solvers:\n",
    "    for f in c_param_range:\n",
    "        LR = LogisticRegression(C=f, solver=i).fit(X_train,y_train)\n",
    "        yhat_LR = LR.predict(X_test)\n",
    "        ascore_lr[g] = accuracy_score(y_test, yhat_LR)\n",
    "        fscore_lr[g] = f1_score(y_test, yhat_LR, average='weighted')\n",
    "        print(\"The accuracy score for Logistic Regression with solver = \", f, \" and kernel = \", i,\" is : \", accuracy_score(y_test, yhat_LR))\n",
    "        print(\"The f1 score for Logistic Regression with solver = \", f, \" and kernel = \", i,\" is : \", f1_score(y_test, yhat_LR, average='weighted'))\n",
    "        g += 1\n",
    "print(\"\\nThe best accuracy score using Logistic Regression is \",ascore_lr.max())\n",
    "print(\"The best f1 score using Logistic Regression is \",fscore_lr.max())              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for solver =  liblinear  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.60      0.52        81\n",
      "           2       0.29      0.16      0.20        57\n",
      "           3       0.39      0.42      0.40        86\n",
      "           4       0.42      0.39      0.41        76\n",
      "\n",
      "    accuracy                           0.41       300\n",
      "   macro avg       0.39      0.39      0.39       300\n",
      "weighted avg       0.40      0.41      0.40       300\n",
      "\n",
      "Classification report for solver =  newton-cg  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.59      0.52        81\n",
      "           2       0.29      0.16      0.20        57\n",
      "           3       0.40      0.45      0.43        86\n",
      "           4       0.42      0.38      0.40        76\n",
      "\n",
      "    accuracy                           0.42       300\n",
      "   macro avg       0.39      0.40      0.39       300\n",
      "weighted avg       0.40      0.42      0.40       300\n",
      "\n",
      "Classification report for solver =  lbfgs  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.59      0.52        81\n",
      "           2       0.29      0.16      0.20        57\n",
      "           3       0.40      0.45      0.43        86\n",
      "           4       0.42      0.38      0.40        76\n",
      "\n",
      "    accuracy                           0.42       300\n",
      "   macro avg       0.39      0.40      0.39       300\n",
      "weighted avg       0.40      0.42      0.40       300\n",
      "\n",
      "Classification report for solver =  sag  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.59      0.52        81\n",
      "           2       0.29      0.16      0.20        57\n",
      "           3       0.40      0.45      0.43        86\n",
      "           4       0.42      0.38      0.40        76\n",
      "\n",
      "    accuracy                           0.42       300\n",
      "   macro avg       0.39      0.40      0.39       300\n",
      "weighted avg       0.40      0.42      0.40       300\n",
      "\n",
      "Classification report for solver =  sag  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.59      0.52        81\n",
      "           2       0.29      0.16      0.20        57\n",
      "           3       0.40      0.45      0.43        86\n",
      "           4       0.42      0.38      0.40        76\n",
      "\n",
      "    accuracy                           0.42       300\n",
      "   macro avg       0.39      0.40      0.39       300\n",
      "weighted avg       0.40      0.42      0.40       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'sag']\n",
    "for i in k:\n",
    "    LR = LogisticRegression(C=0.01, solver=i).fit(X_train,y_train)\n",
    "    yhat_LR = LR.predict(X_test)\n",
    "    print(\"Classification report for solver = \",i,\" \\n\\n\",classification_report(y_test, yhat_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for Naive Bayes is :  0.36333333333333334\n",
      "The f1 score for Naive Bayes is:  0.3303519745850129\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred_NB = gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"The accuracy score for Naive Bayes is : \", accuracy_score(y_test, y_pred_NB))\n",
    "print(\"The f1 score for Naive Bayes is: \", f1_score(y_test, y_pred_NB, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report of Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.73      0.47        81\n",
      "           2       0.21      0.09      0.12        57\n",
      "           3       0.41      0.33      0.36        86\n",
      "           4       0.46      0.22      0.30        76\n",
      "\n",
      "    accuracy                           0.36       300\n",
      "   macro avg       0.36      0.34      0.31       300\n",
      "weighted avg       0.37      0.36      0.33       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_NB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for Random Forest with criterion =  entropy  is  0.33666666666666667\n",
      "The f1 score for Random Forest with criterion =  entropy  is  0.33100995962820023\n",
      "The accuracy score for Random Forest with criterion =  gini  is  0.3333333333333333\n",
      "The f1 score for Random Forest with criterion =  gini  is  0.32629813664596274\n",
      "\n",
      "The best accuracy score using Random Forest is  0.33666666666666667\n",
      "The best f1 score using Random Forest is  0.33100995962820023\n"
     ]
    }
   ],
   "source": [
    "f=0\n",
    "ascore_rf = np.zeros(2)\n",
    "fscore_rf = np.zeros(2)\n",
    "rf_criterion=['entropy', 'gini']\n",
    "for i in rf_criterion:\n",
    "    clf=RandomForestClassifier(criterion=i)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred_RF=clf.predict(X_test)\n",
    "    ascore_rf[f] = accuracy_score(y_test, y_pred_RF)\n",
    "    fscore_rf[f] = f1_score(y_test, y_pred_RF, average='weighted')\n",
    "    print(\"The accuracy score for Random Forest with criterion = \",i,\" is \", accuracy_score(y_test, y_pred_RF))\n",
    "    print(\"The f1 score for Random Forest with criterion = \",i,\" is \", f1_score(y_test, y_pred_RF, average='weighted'))\n",
    "    f += 1\n",
    "    \n",
    "print(\"\\nThe best accuracy score using Random Forest is \",ascore_rf.max())\n",
    "print(\"The best f1 score using Random Forest is \",fscore_rf.max())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report of Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for criterion =  entropy  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.49      0.44        81\n",
      "           2       0.31      0.30      0.30        57\n",
      "           3       0.37      0.36      0.37        86\n",
      "           4       0.27      0.21      0.24        76\n",
      "\n",
      "    accuracy                           0.35       300\n",
      "   macro avg       0.34      0.34      0.34       300\n",
      "weighted avg       0.34      0.35      0.34       300\n",
      "\n",
      "Classification report for criterion =  gini  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.49      0.43        81\n",
      "           2       0.36      0.30      0.33        57\n",
      "           3       0.35      0.34      0.34        86\n",
      "           4       0.29      0.24      0.26        76\n",
      "\n",
      "    accuracy                           0.35       300\n",
      "   macro avg       0.34      0.34      0.34       300\n",
      "weighted avg       0.34      0.35      0.34       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = ['entropy', 'gini']\n",
    "for i in k:\n",
    "    clf=RandomForestClassifier(criterion=i)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred_RF=clf.predict(X_test)\n",
    "    print(\"Classification report for criterion = \",i,\" \\n\\n\",classification_report(y_test, y_pred_RF))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report on accuracy of different algorithms using F1 score and Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# js = jaccard score.......fs = F1-Score\n",
    "# KNN\n",
    "knnas = accuracy_scor.max()\n",
    "knnfs = f1_scor.max()\n",
    "# DTree with max accuracy\n",
    "dtreeas = ascore_dtree.max()\n",
    "dtreefs = fscore_dtree.max()\n",
    "\n",
    "# SVM with max accuracy\n",
    "svmas = ascore_svm.max()\n",
    "svmfs = fscore_svm.max()\n",
    "\n",
    "# Logistic regression with max accuracy\n",
    "lras = ascore_lr.max()\n",
    "lrfs = fscore_lr.max()\n",
    "\n",
    "# Naive Bayes\n",
    "nbas = accuracy_score(y_test, y_pred_NB)\n",
    "nbfs = f1_score(y_test, y_pred_NB, average='weighted')\n",
    "\n",
    "# Random Forest\n",
    "rfas = ascore_rf.max()\n",
    "rffs = fscore_rf.max()\n",
    "\n",
    "#max of all\n",
    "max_as = [knnas,dtreeas,svmas,lras,nbas,rfas]\n",
    "max_fs = [knnfs,dtreefs,svmfs,lrfs,nbfs,rffs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy_Score</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-Nearest Neighor</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.337639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>0.313333</td>\n",
       "      <td>0.313180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.404907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.405760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.363333</td>\n",
       "      <td>0.330352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.336667</td>\n",
       "      <td>0.331010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Algorithm  Accuracy_Score  F1-Score\n",
       "1       K-Nearest Neighor        0.340000  0.337639\n",
       "2           Decision tree        0.313333  0.313180\n",
       "3  Support Vector Machine        0.410000  0.404907\n",
       "4     Logistic regression        0.416667  0.405760\n",
       "5             Naive Bayes        0.363333  0.330352\n",
       "6           Random Forest        0.336667  0.331010"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Algorithm':['K-Nearest Neighor', 'Decision tree', 'Support Vector Machine', 'Logistic regression', 'Naive Bayes', 'Random Forest'], \n",
    "        'Accuracy_Score':max_as, 'F1-Score':max_fs}\n",
    "s = pd.DataFrame(data, index = [1,2,3,4,5,6])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
