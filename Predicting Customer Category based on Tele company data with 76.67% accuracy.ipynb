{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<h1 align=\"center\"><font size=\"5\">Predicting Customer Category based on Tele company data</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "###  Load the Telco Churn data \n",
    "Telco Churn is a hypothetical data file that concerns a telecommunications company's efforts to reduce turnover in its customer base. Each case corresponds to a separate customer and it records various demographic and service usage information. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Load Data From CSV File  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>equip</th>\n",
       "      <th>callcard</th>\n",
       "      <th>wireless</th>\n",
       "      <th>longmon</th>\n",
       "      <th>...</th>\n",
       "      <th>pager</th>\n",
       "      <th>internet</th>\n",
       "      <th>callwait</th>\n",
       "      <th>confer</th>\n",
       "      <th>ebill</th>\n",
       "      <th>loglong</th>\n",
       "      <th>logtoll</th>\n",
       "      <th>lninc</th>\n",
       "      <th>custcat</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.40</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.482</td>\n",
       "      <td>3.033</td>\n",
       "      <td>4.913</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.246</td>\n",
       "      <td>3.240</td>\n",
       "      <td>3.497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.841</td>\n",
       "      <td>3.240</td>\n",
       "      <td>3.401</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.800</td>\n",
       "      <td>3.807</td>\n",
       "      <td>4.331</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.960</td>\n",
       "      <td>3.091</td>\n",
       "      <td>4.382</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>11.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.423</td>\n",
       "      <td>3.240</td>\n",
       "      <td>3.714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>51.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.955</td>\n",
       "      <td>3.248</td>\n",
       "      <td>4.060</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>25.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.30</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.116</td>\n",
       "      <td>2.691</td>\n",
       "      <td>3.332</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>62.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.848</td>\n",
       "      <td>3.240</td>\n",
       "      <td>3.555</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>53.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.65</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.871</td>\n",
       "      <td>3.350</td>\n",
       "      <td>4.094</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    tenure   age  address  income   ed  employ  equip  callcard  wireless  \\\n",
       "0     11.0  33.0      7.0   136.0  5.0     5.0    0.0       1.0       1.0   \n",
       "1     33.0  33.0     12.0    33.0  2.0     0.0    0.0       0.0       0.0   \n",
       "2     23.0  30.0      9.0    30.0  1.0     2.0    0.0       0.0       0.0   \n",
       "3     38.0  35.0      5.0    76.0  2.0    10.0    1.0       1.0       1.0   \n",
       "4      7.0  35.0     14.0    80.0  2.0    15.0    0.0       1.0       0.0   \n",
       "..     ...   ...      ...     ...  ...     ...    ...       ...       ...   \n",
       "95    11.0  63.0      9.0    41.0  3.0     3.0    1.0       0.0       0.0   \n",
       "96    51.0  48.0     27.0    58.0  1.0    18.0    0.0       1.0       0.0   \n",
       "97    25.0  62.0     27.0    28.0  4.0    33.0    1.0       1.0       1.0   \n",
       "98    62.0  76.0     20.0    35.0  3.0    18.0    0.0       1.0       0.0   \n",
       "99    53.0  33.0      1.0    60.0  1.0     6.0    0.0       1.0       1.0   \n",
       "\n",
       "    longmon  ...  pager  internet  callwait  confer  ebill  loglong  logtoll  \\\n",
       "0      4.40  ...    1.0       0.0       1.0     1.0    0.0    1.482    3.033   \n",
       "1      9.45  ...    0.0       0.0       0.0     0.0    0.0    2.246    3.240   \n",
       "2      6.30  ...    0.0       0.0       0.0     1.0    0.0    1.841    3.240   \n",
       "3      6.05  ...    1.0       1.0       1.0     1.0    1.0    1.800    3.807   \n",
       "4      7.10  ...    0.0       0.0       1.0     1.0    0.0    1.960    3.091   \n",
       "..      ...  ...    ...       ...       ...     ...    ...      ...      ...   \n",
       "95     4.15  ...    0.0       1.0       0.0     0.0    1.0    1.423    3.240   \n",
       "96    19.20  ...    0.0       0.0       0.0     1.0    0.0    2.955    3.248   \n",
       "97     8.30  ...    1.0       0.0       1.0     1.0    1.0    2.116    2.691   \n",
       "98    17.25  ...    0.0       0.0       0.0     0.0    1.0    2.848    3.240   \n",
       "99    17.65  ...    1.0       0.0       1.0     1.0    0.0    2.871    3.350   \n",
       "\n",
       "    lninc  custcat  churn  \n",
       "0   4.913      4.0    1.0  \n",
       "1   3.497      1.0    1.0  \n",
       "2   3.401      3.0    0.0  \n",
       "3   4.331      4.0    0.0  \n",
       "4   4.382      3.0    0.0  \n",
       "..    ...      ...    ...  \n",
       "95  3.714      1.0    1.0  \n",
       "96  4.060      3.0    1.0  \n",
       "97  3.332      4.0    1.0  \n",
       "98  3.555      2.0    0.0  \n",
       "99  4.094      4.0    0.0  \n",
       "\n",
       "[100 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('E:\\Datasets\\ChurnData.csv')   \n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>equip</th>\n",
       "      <th>callcard</th>\n",
       "      <th>wireless</th>\n",
       "      <th>longmon</th>\n",
       "      <th>...</th>\n",
       "      <th>pager</th>\n",
       "      <th>internet</th>\n",
       "      <th>callwait</th>\n",
       "      <th>confer</th>\n",
       "      <th>ebill</th>\n",
       "      <th>loglong</th>\n",
       "      <th>logtoll</th>\n",
       "      <th>lninc</th>\n",
       "      <th>custcat</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tenure    age  address  income     ed  employ  equip  callcard  wireless  \\\n",
       "0     False  False    False   False  False   False  False     False     False   \n",
       "1     False  False    False   False  False   False  False     False     False   \n",
       "2     False  False    False   False  False   False  False     False     False   \n",
       "3     False  False    False   False  False   False  False     False     False   \n",
       "4     False  False    False   False  False   False  False     False     False   \n",
       "..      ...    ...      ...     ...    ...     ...    ...       ...       ...   \n",
       "195   False  False    False   False  False   False  False     False     False   \n",
       "196   False  False    False   False  False   False  False     False     False   \n",
       "197   False  False    False   False  False   False  False     False     False   \n",
       "198   False  False    False   False  False   False  False     False     False   \n",
       "199   False  False    False   False  False   False  False     False     False   \n",
       "\n",
       "     longmon  ...  pager  internet  callwait  confer  ebill  loglong  logtoll  \\\n",
       "0      False  ...  False     False     False   False  False    False    False   \n",
       "1      False  ...  False     False     False   False  False    False    False   \n",
       "2      False  ...  False     False     False   False  False    False    False   \n",
       "3      False  ...  False     False     False   False  False    False    False   \n",
       "4      False  ...  False     False     False   False  False    False    False   \n",
       "..       ...  ...    ...       ...       ...     ...    ...      ...      ...   \n",
       "195    False  ...  False     False     False   False  False    False    False   \n",
       "196    False  ...  False     False     False   False  False    False    False   \n",
       "197    False  ...  False     False     False   False  False    False    False   \n",
       "198    False  ...  False     False     False   False  False    False    False   \n",
       "199    False  ...  False     False     False   False  False    False    False   \n",
       "\n",
       "     lninc  custcat  churn  \n",
       "0    False    False  False  \n",
       "1    False    False  False  \n",
       "2    False    False  False  \n",
       "3    False    False  False  \n",
       "4    False    False  False  \n",
       "..     ...      ...    ...  \n",
       "195  False    False  False  \n",
       "196  False    False  False  \n",
       "197  False    False  False  \n",
       "198  False    False  False  \n",
       "199  False    False  False  \n",
       "\n",
       "[200 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>equip</th>\n",
       "      <th>callcard</th>\n",
       "      <th>wireless</th>\n",
       "      <th>longmon</th>\n",
       "      <th>...</th>\n",
       "      <th>pager</th>\n",
       "      <th>internet</th>\n",
       "      <th>callwait</th>\n",
       "      <th>confer</th>\n",
       "      <th>ebill</th>\n",
       "      <th>loglong</th>\n",
       "      <th>logtoll</th>\n",
       "      <th>lninc</th>\n",
       "      <th>custcat</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.00000</td>\n",
       "      <td>200.00000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.00000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>35.505000</td>\n",
       "      <td>41.165000</td>\n",
       "      <td>11.650000</td>\n",
       "      <td>75.130000</td>\n",
       "      <td>2.82500</td>\n",
       "      <td>10.22500</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>11.78925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.45500</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>2.193285</td>\n",
       "      <td>3.229185</td>\n",
       "      <td>3.951015</td>\n",
       "      <td>2.475000</td>\n",
       "      <td>0.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21.640971</td>\n",
       "      <td>13.076803</td>\n",
       "      <td>10.158419</td>\n",
       "      <td>128.430468</td>\n",
       "      <td>1.28555</td>\n",
       "      <td>8.95743</td>\n",
       "      <td>0.495584</td>\n",
       "      <td>0.457187</td>\n",
       "      <td>0.454901</td>\n",
       "      <td>9.88725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447635</td>\n",
       "      <td>0.497633</td>\n",
       "      <td>0.49922</td>\n",
       "      <td>0.499648</td>\n",
       "      <td>0.497633</td>\n",
       "      <td>0.731282</td>\n",
       "      <td>0.281019</td>\n",
       "      <td>0.752553</td>\n",
       "      <td>1.079445</td>\n",
       "      <td>0.454901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.10000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095000</td>\n",
       "      <td>1.749000</td>\n",
       "      <td>2.197000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.750000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.53750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.711750</td>\n",
       "      <td>3.226500</td>\n",
       "      <td>3.434000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33.500000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>7.50000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.25000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.110000</td>\n",
       "      <td>3.240000</td>\n",
       "      <td>3.871000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55.250000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.30000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.660000</td>\n",
       "      <td>3.240000</td>\n",
       "      <td>4.382000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>72.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1668.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>44.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>62.30000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.132000</td>\n",
       "      <td>4.227000</td>\n",
       "      <td>7.419000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           tenure         age     address       income         ed     employ  \\\n",
       "count  200.000000  200.000000  200.000000   200.000000  200.00000  200.00000   \n",
       "mean    35.505000   41.165000   11.650000    75.130000    2.82500   10.22500   \n",
       "std     21.640971   13.076803   10.158419   128.430468    1.28555    8.95743   \n",
       "min      1.000000   19.000000    0.000000     9.000000    1.00000    0.00000   \n",
       "25%     16.750000   31.000000    3.000000    31.000000    2.00000    3.00000   \n",
       "50%     33.500000   40.000000    9.000000    48.000000    3.00000    7.50000   \n",
       "75%     55.250000   51.000000   18.000000    80.000000    4.00000   17.00000   \n",
       "max     72.000000   76.000000   48.000000  1668.000000    5.00000   44.00000   \n",
       "\n",
       "            equip    callcard    wireless    longmon  ...       pager  \\\n",
       "count  200.000000  200.000000  200.000000  200.00000  ...  200.000000   \n",
       "mean     0.425000    0.705000    0.290000   11.78925  ...    0.275000   \n",
       "std      0.495584    0.457187    0.454901    9.88725  ...    0.447635   \n",
       "min      0.000000    0.000000    0.000000    1.10000  ...    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    5.53750  ...    0.000000   \n",
       "50%      0.000000    1.000000    0.000000    8.25000  ...    0.000000   \n",
       "75%      1.000000    1.000000    1.000000   14.30000  ...    1.000000   \n",
       "max      1.000000    1.000000    1.000000   62.30000  ...    1.000000   \n",
       "\n",
       "         internet   callwait      confer       ebill     loglong     logtoll  \\\n",
       "count  200.000000  200.00000  200.000000  200.000000  200.000000  200.000000   \n",
       "mean     0.440000    0.45500    0.460000    0.440000    2.193285    3.229185   \n",
       "std      0.497633    0.49922    0.499648    0.497633    0.731282    0.281019   \n",
       "min      0.000000    0.00000    0.000000    0.000000    0.095000    1.749000   \n",
       "25%      0.000000    0.00000    0.000000    0.000000    1.711750    3.226500   \n",
       "50%      0.000000    0.00000    0.000000    0.000000    2.110000    3.240000   \n",
       "75%      1.000000    1.00000    1.000000    1.000000    2.660000    3.240000   \n",
       "max      1.000000    1.00000    1.000000    1.000000    4.132000    4.227000   \n",
       "\n",
       "            lninc     custcat       churn  \n",
       "count  200.000000  200.000000  200.000000  \n",
       "mean     3.951015    2.475000    0.290000  \n",
       "std      0.752553    1.079445    0.454901  \n",
       "min      2.197000    1.000000    0.000000  \n",
       "25%      3.434000    2.000000    0.000000  \n",
       "50%      3.871000    2.000000    0.000000  \n",
       "75%      4.382000    3.000000    1.000000  \n",
       "max      7.419000    4.000000    1.000000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing:  Feature selection/extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>equip</th>\n",
       "      <th>callcard</th>\n",
       "      <th>wireless</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tenure   age  address  income   ed  employ  equip  callcard  wireless  \\\n",
       "0    11.0  33.0      7.0   136.0  5.0     5.0    0.0       1.0       1.0   \n",
       "1    33.0  33.0     12.0    33.0  2.0     0.0    0.0       0.0       0.0   \n",
       "2    23.0  30.0      9.0    30.0  1.0     2.0    0.0       0.0       0.0   \n",
       "3    38.0  35.0      5.0    76.0  2.0    10.0    1.0       1.0       1.0   \n",
       "4     7.0  35.0     14.0    80.0  2.0    15.0    0.0       1.0       0.0   \n",
       "\n",
       "   churn  \n",
       "0      1  \n",
       "1      1  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_df = df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip',   'callcard', 'wireless','churn']]\n",
    "churn_df['churn'] = churn_df['churn'].astype('int')\n",
    "churn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 11.,  33.,   7., 136.,   5.,   5.,   0.],\n",
       "       [ 33.,  33.,  12.,  33.,   2.,   0.,   0.],\n",
       "       [ 23.,  30.,   9.,  30.,   1.,   2.,   0.],\n",
       "       [ 38.,  35.,   5.,  76.,   2.,  10.,   1.],\n",
       "       [  7.,  35.,  14.,  80.,   2.,  15.,   0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.asarray(churn_df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip']])\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.asarray(churn_df['churn'])\n",
    "y [0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    142\n",
       "1     58\n",
       "Name: churn, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_df['churn'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Normalize Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.13518441, -0.62595491, -0.4588971 ,  0.4751423 ,  1.6961288 ,\n",
       "        -0.58477841, -0.85972695],\n",
       "       [-0.11604313, -0.62595491,  0.03454064, -0.32886061, -0.6433592 ,\n",
       "        -1.14437497, -0.85972695],\n",
       "       [-0.57928917, -0.85594447, -0.261522  , -0.35227817, -1.42318853,\n",
       "        -0.92053635, -0.85972695],\n",
       "       [ 0.11557989, -0.47262854, -0.65627219,  0.00679109, -0.6433592 ,\n",
       "        -0.02518185,  1.16316   ],\n",
       "       [-1.32048283, -0.47262854,  0.23191574,  0.03801451, -0.6433592 ,\n",
       "         0.53441472, -0.85972695]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide the dataset into Training and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "- K Nearest Neighbor(KNN)\n",
    "- Decision Tree\n",
    "- Support Vector Machine\n",
    "- Logistic Regression\n",
    "- Naive Bayes\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbor(KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted values using K =  1 is  [0 1 0 0 0]\n",
      "The predicted values using K =  2 is  [0 0 0 0 0]\n",
      "The predicted values using K =  3 is  [0 0 0 0 0]\n",
      "The predicted values using K =  4 is  [0 0 0 0 0]\n",
      "The predicted values using K =  5 is  [0 0 0 0 0]\n",
      "The predicted values using K =  6 is  [0 0 0 0 0]\n",
      "The predicted values using K =  7 is  [0 0 0 0 0]\n",
      "The predicted values using K =  8 is  [0 0 0 0 0]\n",
      "The predicted values using K =  9 is  [0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "Ks = 10\n",
    "for n in range(1,Ks):\n",
    "    #Train Model and Predict  \n",
    "    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n",
    "    yhat_KNN=neigh.predict(X_test)\n",
    "    print(\"The predicted values using K = \", n, \"is \", yhat_KNN[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values predicted by Decision Tree using criterion =  entropy  is  [0 1 0 1 0]\n",
      "The values predicted by Decision Tree using criterion =  gini  is  [0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree_criterions = ['entropy', 'gini']\n",
    "for i in dtree_criterions:\n",
    "    drugTree = DecisionTreeClassifier(criterion=i)\n",
    "    drugTree.fit(X_train, y_train)\n",
    "    predTree = drugTree.predict(X_test)\n",
    "    print (\"The values predicted by Decision Tree using criterion = \",i,\" is \", predTree [0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values predicted by SVM using kernels =  rbf  is  [0 0 0 0 0]\n",
      "The values predicted by SVM using kernels =  linear  is  [0 0 0 0 0]\n",
      "The values predicted by SVM using kernels =  poly  is  [0 0 0 0 0]\n",
      "The values predicted by SVM using kernels =  sigmoid  is  [0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_kernels = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "for i in svm_kernels:\n",
    "    clf = svm.SVC(kernel=i)\n",
    "    clf.fit(X_train, y_train) \n",
    "    yhat_SVM = clf.predict(X_test)\n",
    "    print(\"The values predicted by SVM using kernels = \", i, \" is \", yhat_SVM [0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values predicted by Logistic Regression using c =  0.001  and solver =  liblinear  is  [0 0 0 0 0]\n",
      "The values predicted by Logistic Regression using c =  0.01  and solver =  liblinear  is  [0 0 0 0 0]\n",
      "The values predicted by Logistic Regression using c =  0.1  and solver =  liblinear  is  [0 0 0 0 0]\n",
      "The values predicted by Logistic Regression using c =  0.001  and solver =  newton-cg  is  [0 0 0 0 0]\n",
      "The values predicted by Logistic Regression using c =  0.01  and solver =  newton-cg  is  [0 0 0 0 0]\n",
      "The values predicted by Logistic Regression using c =  0.1  and solver =  newton-cg  is  [0 0 0 0 0]\n",
      "The values predicted by Logistic Regression using c =  0.001  and solver =  lbfgs  is  [0 0 0 0 0]\n",
      "The values predicted by Logistic Regression using c =  0.01  and solver =  lbfgs  is  [0 0 0 0 0]\n",
      "The values predicted by Logistic Regression using c =  0.1  and solver =  lbfgs  is  [0 0 0 0 0]\n",
      "The values predicted by Logistic Regression using c =  0.001  and solver =  sag  is  [0 0 0 0 0]\n",
      "The values predicted by Logistic Regression using c =  0.01  and solver =  sag  is  [0 0 0 0 0]\n",
      "The values predicted by Logistic Regression using c =  0.1  and solver =  sag  is  [0 0 0 0 0]\n",
      "The values predicted by Logistic Regression using c =  0.001  and solver =  saga  is  [0 0 0 0 0]\n",
      "The values predicted by Logistic Regression using c =  0.01  and solver =  saga  is  [0 0 0 0 0]\n",
      "The values predicted by Logistic Regression using c =  0.1  and solver =  saga  is  [0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "c_param_range=[0.001,0.01,0.1]\n",
    "lr_solvers=['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "for i in lr_solvers:\n",
    "    for f in c_param_range:\n",
    "        LR = LogisticRegression(C=f, solver=i).fit(X_train,y_train)\n",
    "        yhat_LR = LR.predict(X_test)\n",
    "        print(\"The values predicted by Logistic Regression using c = \",f,\" and solver = \",i, \" is \",yhat_LR[0:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values predicted by Naive Bayes is  [0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred_NB = gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"The values predicted by Naive Bayes is \", y_pred_NB[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values predicted by Random Forest using criterion =  entropy  is  [0 0 0 0 0]\n",
      "The values predicted by Random Forest using criterion =  gini  is  [0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_criterion=['entropy', 'gini']\n",
    "for i in rf_criterion:\n",
    "    clf=RandomForestClassifier(criterion=i)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred_RF=clf.predict(X_test)\n",
    "    print(\"The values predicted by Random Forest using criterion = \", i,\" is \",y_pred_RF[0:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation using Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score with k =  1 is  0.6666666666666666\n",
      "The f1 score with k =  1 is  0.6719576719576721\n",
      "The accuracy score with k =  2 is  0.7333333333333333\n",
      "The f1 score with k =  2 is  0.6769325912183055\n",
      "The accuracy score with k =  3 is  0.75\n",
      "The f1 score with k =  3 is  0.7476489028213167\n",
      "The accuracy score with k =  4 is  0.75\n",
      "The f1 score with k =  4 is  0.7270011947431302\n",
      "The accuracy score with k =  5 is  0.7333333333333333\n",
      "The f1 score with k =  5 is  0.7280303030303031\n",
      "The accuracy score with k =  6 is  0.7666666666666667\n",
      "The f1 score with k =  6 is  0.7406983087834151\n",
      "The accuracy score with k =  7 is  0.7\n",
      "The f1 score with k =  7 is  0.6866666666666668\n",
      "The accuracy score with k =  8 is  0.75\n",
      "The f1 score with k =  8 is  0.716842105263158\n",
      "The accuracy score with k =  9 is  0.7333333333333333\n",
      "The f1 score with k =  9 is  0.7036552100381888\n",
      "\n",
      "The best accuracy score for KNN was  0.7666666666666667 with k= 6\n",
      "The best f1 score for KNN was  0.7476489028213167 with k= 3\n"
     ]
    }
   ],
   "source": [
    "Ks = 10\n",
    "accuracy_scor = np.zeros((Ks-1))\n",
    "f1_scor = np.zeros((Ks-1))\n",
    "\n",
    "\n",
    "for n in range(1,Ks):\n",
    "    \n",
    "    #Train Model and Predict  \n",
    "    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n",
    "    yhat_KNN=neigh.predict(X_test)\n",
    "    accuracy_scor[n-1] = accuracy_score(y_test, yhat_KNN)\n",
    "    f1_scor[n-1] = f1_score(y_test, yhat_KNN, average = 'weighted')\n",
    "    print(\"The accuracy score with k = \",n, \"is \",accuracy_scor[n-1])\n",
    "    print(\"The f1 score with k = \",n, \"is \",f1_scor[n-1])\n",
    "    \n",
    "\n",
    "print( \"\\nThe best accuracy score for KNN was \", accuracy_scor.max(), \"with k=\", accuracy_scor.argmax()+1) \n",
    "print( \"The best f1 score for KNN was \", f1_scor.max(), \"with k=\", f1_scor.argmax()+1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report of KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.93      0.85        43\n",
      "           1       0.67      0.35      0.46        17\n",
      "\n",
      "    accuracy                           0.77        60\n",
      "   macro avg       0.73      0.64      0.66        60\n",
      "weighted avg       0.75      0.77      0.74        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors = accuracy_scor.argmax()+1).fit(X_train,y_train)\n",
    "yhat_KNN=neigh.predict(X_test)\n",
    "print (classification_report(y_test, yhat_KNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTrees's Accuracy with criterion =  entropy  using Accuracy Score:  0.5333333333333333\n",
      "DecisionTrees's Accuracy with criterion =  entropy  using F1 Score:  0.546512623020967\n",
      "DecisionTrees's Accuracy with criterion =  gini  using Accuracy Score:  0.5833333333333334\n",
      "DecisionTrees's Accuracy with criterion =  gini  using F1 Score:  0.600442523412576\n",
      "\n",
      "The best accuracy score using Decision Tree is  0.5833333333333334\n",
      "The best f1 score using Decision Tree is  0.600442523412576\n"
     ]
    }
   ],
   "source": [
    "f = 0\n",
    "ascore_dtree = np.zeros(2)\n",
    "fscore_dtree = np.zeros(2)\n",
    "dtree_criterions = ['entropy', 'gini']\n",
    "for i in dtree_criterions:\n",
    "    drugTree = DecisionTreeClassifier(criterion=i)\n",
    "    drugTree.fit(X_train, y_train)\n",
    "    predTree = drugTree.predict(X_test)\n",
    "    ascore_dtree[f] = accuracy_score(y_test, predTree)\n",
    "    fscore_dtree[f] = f1_score(y_test, predTree, average = 'weighted')\n",
    "    print(\"DecisionTrees's Accuracy with criterion = \", i,\" using Accuracy Score: \", accuracy_score(y_test, predTree))\n",
    "    print(\"DecisionTrees's Accuracy with criterion = \", i,\" using F1 Score: \", f1_score(y_test, predTree, average = 'weighted'))\n",
    "    f += 1\n",
    "print(\"\\nThe best accuracy score using Decision Tree is \",ascore_dtree.max())\n",
    "print(\"The best f1 score using Decision Tree is \",fscore_dtree.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for criterion =  entropy \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.63      0.66        43\n",
      "           1       0.24      0.29      0.26        17\n",
      "\n",
      "    accuracy                           0.53        60\n",
      "   macro avg       0.47      0.46      0.46        60\n",
      "weighted avg       0.56      0.53      0.55        60\n",
      "\n",
      "Classification report for criterion =  gini \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.63      0.68        43\n",
      "           1       0.30      0.41      0.35        17\n",
      "\n",
      "    accuracy                           0.57        60\n",
      "   macro avg       0.52      0.52      0.51        60\n",
      "weighted avg       0.61      0.57      0.58        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = ['entropy','gini']\n",
    "for i in k:\n",
    "    drugTree = DecisionTreeClassifier(criterion=i)\n",
    "    drugTree.fit(X_train, y_train)\n",
    "    predTree = drugTree.predict(X_test)\n",
    "    print(\"Classification report for criterion = \",i,\"\\n\\n\",classification_report(y_test, predTree))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for SVM with kernel =  rbf  is :  0.7666666666666667\n",
      "The f1 score for SVM with kernel =  rbf  is:  0.7173160173160172\n",
      "The accuracy score for SVM with kernel =  linear  is :  0.6833333333333333\n",
      "The f1 score for SVM with kernel =  linear  is:  0.6647341164582544\n",
      "The accuracy score for SVM with kernel =  poly  is :  0.7666666666666667\n",
      "The f1 score for SVM with kernel =  poly  is:  0.7013333333333333\n",
      "The accuracy score for SVM with kernel =  sigmoid  is :  0.75\n",
      "The f1 score for SVM with kernel =  sigmoid  is:  0.7270011947431302\n",
      "\n",
      "The best accuracy score using SVM is  0.7666666666666667\n",
      "The best f1 score using SVM is  0.7270011947431302\n"
     ]
    }
   ],
   "source": [
    "f=0\n",
    "ascore_svm = np.zeros(4)\n",
    "fscore_svm = np.zeros(4)\n",
    "svm_kernels = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "\n",
    "for i in svm_kernels:\n",
    "    clf = svm.SVC(kernel=i)\n",
    "    clf.fit(X_train, y_train) \n",
    "    yhat_SVM = clf.predict(X_test)\n",
    "    ascore_svm[f] = accuracy_score(y_test, yhat_SVM)\n",
    "    fscore_svm[f] = f1_score(y_test, yhat_SVM, average='weighted')\n",
    "    print(\"The accuracy score for SVM with kernel = \", i,\" is : \", accuracy_score(y_test, yhat_SVM))\n",
    "    print(\"The f1 score for SVM with kernel = \", i,\" is: \", f1_score(y_test, yhat_SVM, average='weighted'))\n",
    "    f += 1\n",
    "print(\"\\nThe best accuracy score using SVM is \",ascore_svm.max())\n",
    "print(\"The best f1 score using SVM is \",fscore_svm.max())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report of SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for kernel =  rbf  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.98      0.86        43\n",
      "           1       0.80      0.24      0.36        17\n",
      "\n",
      "    accuracy                           0.77        60\n",
      "   macro avg       0.78      0.61      0.61        60\n",
      "weighted avg       0.77      0.77      0.72        60\n",
      "\n",
      "Classification report for kernel =  linear  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.84      0.79        43\n",
      "           1       0.42      0.29      0.34        17\n",
      "\n",
      "    accuracy                           0.68        60\n",
      "   macro avg       0.58      0.57      0.57        60\n",
      "weighted avg       0.66      0.68      0.66        60\n",
      "\n",
      "Classification report for kernel =  poly  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86        43\n",
      "           1       1.00      0.18      0.30        17\n",
      "\n",
      "    accuracy                           0.77        60\n",
      "   macro avg       0.88      0.59      0.58        60\n",
      "weighted avg       0.82      0.77      0.70        60\n",
      "\n",
      "Classification report for kernel =  sigmoid  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84        43\n",
      "           1       0.60      0.35      0.44        17\n",
      "\n",
      "    accuracy                           0.75        60\n",
      "   macro avg       0.69      0.63      0.64        60\n",
      "weighted avg       0.73      0.75      0.73        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "for i in k:\n",
    "    clf = svm.SVC(kernel=i)\n",
    "    clf.fit(X_train, y_train) \n",
    "    yhat_SVM = clf.predict(X_test)\n",
    "    print (\"Classification report for kernel = \",i,\" \\n\\n\",classification_report(y_test, yhat_SVM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for Logistic Regression with solver =  0.001  and kernel =  liblinear  is :  0.7\n",
      "The f1 score for Logistic Regression with solver =  0.001  and kernel =  liblinear  is :  0.7112499999999999\n",
      "The accuracy score for Logistic Regression with solver =  0.01  and kernel =  liblinear  is :  0.7\n",
      "The f1 score for Logistic Regression with solver =  0.01  and kernel =  liblinear  is :  0.694034090909091\n",
      "The accuracy score for Logistic Regression with solver =  0.1  and kernel =  liblinear  is :  0.7333333333333333\n",
      "The f1 score for Logistic Regression with solver =  0.1  and kernel =  liblinear  is :  0.6916666666666667\n",
      "The accuracy score for Logistic Regression with solver =  0.001  and kernel =  newton-cg  is :  0.7166666666666667\n",
      "The f1 score for Logistic Regression with solver =  0.001  and kernel =  newton-cg  is :  0.5983818770226537\n",
      "The accuracy score for Logistic Regression with solver =  0.01  and kernel =  newton-cg  is :  0.7166666666666667\n",
      "The f1 score for Logistic Regression with solver =  0.01  and kernel =  newton-cg  is :  0.5983818770226537\n",
      "The accuracy score for Logistic Regression with solver =  0.1  and kernel =  newton-cg  is :  0.7666666666666667\n",
      "The f1 score for Logistic Regression with solver =  0.1  and kernel =  newton-cg  is :  0.7173160173160172\n",
      "The accuracy score for Logistic Regression with solver =  0.001  and kernel =  lbfgs  is :  0.7166666666666667\n",
      "The f1 score for Logistic Regression with solver =  0.001  and kernel =  lbfgs  is :  0.5983818770226537\n",
      "The accuracy score for Logistic Regression with solver =  0.01  and kernel =  lbfgs  is :  0.7166666666666667\n",
      "The f1 score for Logistic Regression with solver =  0.01  and kernel =  lbfgs  is :  0.5983818770226537\n",
      "The accuracy score for Logistic Regression with solver =  0.1  and kernel =  lbfgs  is :  0.7666666666666667\n",
      "The f1 score for Logistic Regression with solver =  0.1  and kernel =  lbfgs  is :  0.7173160173160172\n",
      "The accuracy score for Logistic Regression with solver =  0.001  and kernel =  sag  is :  0.7166666666666667\n",
      "The f1 score for Logistic Regression with solver =  0.001  and kernel =  sag  is :  0.5983818770226537\n",
      "The accuracy score for Logistic Regression with solver =  0.01  and kernel =  sag  is :  0.7166666666666667\n",
      "The f1 score for Logistic Regression with solver =  0.01  and kernel =  sag  is :  0.5983818770226537\n",
      "The accuracy score for Logistic Regression with solver =  0.1  and kernel =  sag  is :  0.7666666666666667\n",
      "The f1 score for Logistic Regression with solver =  0.1  and kernel =  sag  is :  0.7173160173160172\n",
      "The accuracy score for Logistic Regression with solver =  0.001  and kernel =  saga  is :  0.7166666666666667\n",
      "The f1 score for Logistic Regression with solver =  0.001  and kernel =  saga  is :  0.5983818770226537\n",
      "The accuracy score for Logistic Regression with solver =  0.01  and kernel =  saga  is :  0.7166666666666667\n",
      "The f1 score for Logistic Regression with solver =  0.01  and kernel =  saga  is :  0.5983818770226537\n",
      "The accuracy score for Logistic Regression with solver =  0.1  and kernel =  saga  is :  0.7666666666666667\n",
      "The f1 score for Logistic Regression with solver =  0.1  and kernel =  saga  is :  0.7173160173160172\n",
      "\n",
      "The best accuracy score using Logistic Regression is  0.7666666666666667\n",
      "The best f1 score using Logistic Regression is  0.7173160173160172\n"
     ]
    }
   ],
   "source": [
    "g = 0\n",
    "ascore_lr = np.zeros(15)\n",
    "fscore_lr = np.zeros(15)\n",
    "c_param_range=[0.001,0.01,0.1]\n",
    "lr_solvers=['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "for i in lr_solvers:\n",
    "    for f in c_param_range:\n",
    "        LR = LogisticRegression(C=f, solver=i).fit(X_train,y_train)\n",
    "        yhat_LR = LR.predict(X_test)\n",
    "        ascore_lr[g] = accuracy_score(y_test, yhat_LR)\n",
    "        fscore_lr[g] = f1_score(y_test, yhat_LR, average='weighted')\n",
    "        print(\"The accuracy score for Logistic Regression with solver = \", f, \" and kernel = \", i,\" is : \", accuracy_score(y_test, yhat_LR))\n",
    "        print(\"The f1 score for Logistic Regression with solver = \", f, \" and kernel = \", i,\" is : \", f1_score(y_test, yhat_LR, average='weighted'))\n",
    "        g += 1\n",
    "print(\"\\nThe best accuracy score using Logistic Regression is \",ascore_lr.max())\n",
    "print(\"The best f1 score using Logistic Regression is \",fscore_lr.max())              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for solver =  liblinear  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80        43\n",
      "           1       0.47      0.41      0.44        17\n",
      "\n",
      "    accuracy                           0.70        60\n",
      "   macro avg       0.62      0.61      0.62        60\n",
      "weighted avg       0.69      0.70      0.69        60\n",
      "\n",
      "Classification report for solver =  newton-cg  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.83        43\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.72        60\n",
      "   macro avg       0.36      0.50      0.42        60\n",
      "weighted avg       0.51      0.72      0.60        60\n",
      "\n",
      "Classification report for solver =  lbfgs  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.83        43\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.72        60\n",
      "   macro avg       0.36      0.50      0.42        60\n",
      "weighted avg       0.51      0.72      0.60        60\n",
      "\n",
      "Classification report for solver =  sag  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.83        43\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.72        60\n",
      "   macro avg       0.36      0.50      0.42        60\n",
      "weighted avg       0.51      0.72      0.60        60\n",
      "\n",
      "Classification report for solver =  sag  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.83        43\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.72        60\n",
      "   macro avg       0.36      0.50      0.42        60\n",
      "weighted avg       0.51      0.72      0.60        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "k = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'sag']\n",
    "for i in k:\n",
    "    LR = LogisticRegression(C=0.01, solver=i).fit(X_train,y_train)\n",
    "    yhat_LR = LR.predict(X_test)\n",
    "    print(\"Classification report for solver = \",i,\" \\n\\n\",classification_report(y_test, yhat_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for Naive Bayes is :  0.75\n",
      "The f1 score for Naive Bayes is:  0.7622222222222224\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred_NB = gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"The accuracy score for Naive Bayes is : \", accuracy_score(y_test, y_pred_NB))\n",
    "print(\"The f1 score for Naive Bayes is: \", f1_score(y_test, y_pred_NB, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report of Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.70      0.80        43\n",
      "           1       0.54      0.88      0.67        17\n",
      "\n",
      "    accuracy                           0.75        60\n",
      "   macro avg       0.74      0.79      0.73        60\n",
      "weighted avg       0.82      0.75      0.76        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_NB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for Random Forest with criterion =  entropy  is  0.6833333333333333\n",
      "The f1 score for Random Forest with criterion =  entropy  is  0.6413333333333333\n",
      "The accuracy score for Random Forest with criterion =  gini  is  0.7166666666666667\n",
      "The f1 score for Random Forest with criterion =  gini  is  0.6790877192982456\n",
      "\n",
      "The best accuracy score using Random Forest is  0.7166666666666667\n",
      "The best f1 score using Random Forest is  0.6790877192982456\n"
     ]
    }
   ],
   "source": [
    "f=0\n",
    "ascore_rf = np.zeros(2)\n",
    "fscore_rf = np.zeros(2)\n",
    "rf_criterion=['entropy', 'gini']\n",
    "for i in rf_criterion:\n",
    "    clf=RandomForestClassifier(criterion=i)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred_RF=clf.predict(X_test)\n",
    "    ascore_rf[f] = accuracy_score(y_test, y_pred_RF)\n",
    "    fscore_rf[f] = f1_score(y_test, y_pred_RF, average='weighted')\n",
    "    print(\"The accuracy score for Random Forest with criterion = \",i,\" is \", accuracy_score(y_test, y_pred_RF))\n",
    "    print(\"The f1 score for Random Forest with criterion = \",i,\" is \", f1_score(y_test, y_pred_RF, average='weighted'))\n",
    "    f += 1\n",
    "    \n",
    "print(\"\\nThe best accuracy score using Random Forest is \",ascore_rf.max())\n",
    "print(\"The best f1 score using Random Forest is \",fscore_rf.max())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report of Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for criterion =  entropy  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.88      0.81        43\n",
      "           1       0.44      0.24      0.31        17\n",
      "\n",
      "    accuracy                           0.70        60\n",
      "   macro avg       0.59      0.56      0.56        60\n",
      "weighted avg       0.66      0.70      0.67        60\n",
      "\n",
      "Classification report for criterion =  gini  \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.88      0.81        43\n",
      "           1       0.44      0.24      0.31        17\n",
      "\n",
      "    accuracy                           0.70        60\n",
      "   macro avg       0.59      0.56      0.56        60\n",
      "weighted avg       0.66      0.70      0.67        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = ['entropy', 'gini']\n",
    "for i in k:\n",
    "    clf=RandomForestClassifier(criterion=i)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred_RF=clf.predict(X_test)\n",
    "    print(\"Classification report for criterion = \",i,\" \\n\\n\",classification_report(y_test, y_pred_RF))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report on accuracy of different algorithms using F1 score and Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# js = jaccard score.......fs = F1-Score\n",
    "# KNN\n",
    "knnas = accuracy_scor.max()\n",
    "knnfs = f1_scor.max()\n",
    "# DTree with max accuracy\n",
    "dtreeas = ascore_dtree.max()\n",
    "dtreefs = fscore_dtree.max()\n",
    "\n",
    "# SVM with max accuracy\n",
    "svmas = ascore_svm.max()\n",
    "svmfs = fscore_svm.max()\n",
    "\n",
    "# Logistic regression with max accuracy\n",
    "lras = ascore_lr.max()\n",
    "lrfs = fscore_lr.max()\n",
    "\n",
    "# Naive Bayes\n",
    "nbas = accuracy_score(y_test, y_pred_NB)\n",
    "nbfs = f1_score(y_test, y_pred_NB, average='weighted')\n",
    "\n",
    "# Random Forest\n",
    "rfas = ascore_rf.max()\n",
    "rffs = fscore_rf.max()\n",
    "\n",
    "#max of all\n",
    "max_as = [knnas,dtreeas,svmas,lras,nbas,rfas]\n",
    "max_fs = [knnfs,dtreefs,svmfs,lrfs,nbfs,rffs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy_Score</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-Nearest Neighor</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.747649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.600443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.727001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.717316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.762222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.679088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Algorithm  Accuracy_Score  F1-Score\n",
       "1       K-Nearest Neighor        0.766667  0.747649\n",
       "2           Decision tree        0.583333  0.600443\n",
       "3  Support Vector Machine        0.766667  0.727001\n",
       "4     Logistic regression        0.766667  0.717316\n",
       "5             Naive Bayes        0.750000  0.762222\n",
       "6           Random Forest        0.716667  0.679088"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Algorithm':['K-Nearest Neighor', 'Decision tree', 'Support Vector Machine', 'Logistic regression', 'Naive Bayes', 'Random Forest'], \n",
    "        'Accuracy_Score':max_as, 'F1-Score':max_fs}\n",
    "s = pd.DataFrame(data, index = [1,2,3,4,5,6])\n",
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
